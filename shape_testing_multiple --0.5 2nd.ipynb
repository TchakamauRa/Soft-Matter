{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Currently works on a single frame. Later, will add a loop that can work on all frames.'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import av\n",
    "import numpy as np\n",
    "import math\n",
    "from skimage.morphology import *\n",
    "from skimage.feature import *\n",
    "import matplotlib.pyplot as plt #for maknig plots inside the notebook\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from operator import attrgetter\n",
    "import seaborn as sns\n",
    "from operator import attrgetter\n",
    "from itertools import chain\n",
    "from skimage import measure\n",
    "from skimage import morphology\n",
    "from skimage.util import invert\n",
    "from skimage.filters import *\n",
    "from scipy import ndimage\n",
    "from glob import glob\n",
    "from skvideo.io import vreader\n",
    "\"\"\"Currently works on a single frame. Later, will add a loop that can work on all frames.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, [0.1, 0.1414213562373095, 0.0, 0.4242640687119285], 19.97056274847714, [([3, 0], 3.0), ([0, 0], 0.0)]) [5.0, 10.0] hello\n"
     ]
    }
   ],
   "source": [
    "connect_test = connect((0, 0),2, [(0, 3, 1), (3, 3, 1.1), (0, 0, 5), (9, 9, 100)]) #2\n",
    "vector_dist_test = [vector_dist((-3, 0), (0, 4)), vector_dist((1,1,0), (1,7,8))]\n",
    "third_item_test = third_item([0, \"99\", \"hello\", [55, 67]])\n",
    "print(connect_test, vector_dist_test , third_item_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, [95, 67], 2, 2, [9.0], 13]\n",
      "[3, [95, 67, 9.0], 15]\n"
     ]
    }
   ],
   "source": [
    "grp1 = [1, [95, 67], 2]\n",
    "grp2 = [2, [9.0], 13]\n",
    "print(grp1+grp2)\n",
    "print([grp1[i]+grp2[i] for i in range(len(grp1))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./tchakamau\\\\0.5 2nd\\\\45660_10Vpp_0.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_1.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_7.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_10.avi']\n"
     ]
    }
   ],
   "source": [
    "filenames = filename = glob(\"./tchakamau/0.5*/*[1][0]v*_[0,1,7].avi\")+glob(\"./tchakamau/0.5*/*[1][0]v*_10.avi\")#[1,3,4,5]glob(\"./tchakamau/New_setup/*.avi\")# glob(\"./tchakamau/New_setup/45681_10Vpp_25.avi\") #filenames = \n",
    "print(filenames)\n",
    "num_shape_cats = 5\n",
    "Pass_ratios = np.zeros((len(filenames), num_shape_cats))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"TEST FRAME RANGES FROM VIDEOs\"\"\"\n",
    "phantom_frames = {\"p\" : [],#list(range(16312, 15312, -5)),\n",
    "                  \"g\" :[], \n",
    "                  \"b\" :[],#list(range(21149, 19100, -10)),\n",
    "                 \"broken\" :[] ,\n",
    "                 \"odd_s\" :[]}#list(range(17192,17102,-1)) }\n",
    "phantom_frames_2 = {\"p\" :[],# list(range(77374, 71894, -25)),\n",
    "                  \"g\" :list(chain(range(85588,81588, -20), range(35547,33657, -10))), \n",
    "                  \"b\" :[],\n",
    "                 \"broken\" :[],#list(range(78379, 77919,-3)),\n",
    "                 \"odd_s\" :[]}#list(range(77911,77712,-1)) }\n",
    "phantom_frames_3 = {\"p\" :[],#list(range(48359,45359, -20)),\n",
    "                  \"g\" :[], \n",
    "                  \"b\" :[],#list(range(44732, 43731, -5)),\n",
    "                 \"broken\" :[] ,\n",
    "                 \"odd_s\" :[]}\n",
    "phantom_frames_4 = {\"p\" :list(range(33701,31701, -10)) ,\n",
    "                  \"g\" :[], \n",
    "                  \"b\" :list(range(60916,60193, -3)),\n",
    "                 \"broken\" :list(range(34555,34288,-1)) ,\n",
    "                 \"odd_s\" :list(range(61113,61059,-1)) }\n",
    "\n",
    "\n",
    "phantom_frame_sets = [phantom_frames,phantom_frames_2,phantom_frames_3, phantom_frames_4]\n",
    "trigger_frames = [21149, 85588,48500,61240]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<generator object vreader at 0x00000204E5F5BC78>\n",
      "<generator object vreader at 0x00000204E0CA30C0>\n",
      "<generator object vreader at 0x00000204E0CA31B0>\n",
      "<generator object vreader at 0x00000204E5F5BC78>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' for i in range(len(framesetnames)):\\n        typevals = phantom_frame_sets[vidnum].get(framesetnames[i])\\n        \\n        frames = \\n        #print(len(typevals), trigger_frames[vidnum], typevals[-1], typevals[-1]-trigger_frames[vidnum])\\n        framesets[i].extend([(frame_vid[trigger_frames[vidnum]-x], x) for x in typevals])\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_frames = []\n",
    "\n",
    "g_frames = []\n",
    "\n",
    "b_frames = []\n",
    "\n",
    "odd_s_frames = []\n",
    "\n",
    "broken_frames = []\n",
    "\n",
    "\n",
    "framesets = [p_frames, g_frames, b_frames,  odd_s_frames, \n",
    "             broken_frames]\n",
    "framesetnames = [\"p\", \"g\", \"b\", \"odd_s\", \"broken\"]\n",
    "filtrates_props = []\n",
    "passes = []\n",
    "i_props = []\n",
    "t_props = []    \n",
    "for vidnum in range(len(filenames)):\n",
    "    framegen = vreader(filenames[vidnum])\n",
    "    #frame_vid = frames[:, :, :, 2]# making videos ino a frame list\n",
    "    print(framegen)\n",
    "    pvals  = []\n",
    "    gvals = []\n",
    "    bvals = []\n",
    "    oddsvals = []\n",
    "    brokenvals = []\n",
    "    frametypevals = [pvals, gvals, bvals, oddsvals, brokenvals]\n",
    "    \n",
    "    for framesetind in range(len(framesetnames)):\n",
    "        typevals = (phantom_frame_sets[vidnum].get(framesetnames[framesetind]))\n",
    "        frametypevals[framesetind].extend(typevals)\n",
    "    frameindex = 0\n",
    "    tf = trigger_frames[vidnum]\n",
    "    for frame in framegen:\n",
    "        for framesetind in range(len(framesetnames)):            \n",
    "            if tf-frameindex in frametypevals[framesetind]:\n",
    "                framesets[framesetind].append((frame[:,:,2], tf-frameindex))\n",
    "           \n",
    "        frameindex += 1\n",
    "    \n",
    "    \n",
    "\"\"\" for i in range(len(framesetnames)):\n",
    "        typevals = phantom_frame_sets[vidnum].get(framesetnames[i])\n",
    "        \n",
    "        frames = \n",
    "        #print(len(typevals), trigger_frames[vidnum], typevals[-1], typevals[-1]-trigger_frames[vidnum])\n",
    "        framesets[i].extend([(frame_vid[trigger_frames[vidnum]-x], x) for x in typevals])\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take largest isodata image region, and return aclassification\n",
    "def sideify(ptotallengths,gtotallengths,mtotallengths,\n",
    "                num_pconnections, num_gconnections, num_mconnections, mixedlen, mixed_prod, mixed_dotprod):    \n",
    "    if num_pconnections == 0: #gtotallengths>48\n",
    "        return \"g\"\n",
    "    elif mixedlen != 2:\n",
    "        return \"ucf\"\n",
    "    elif mixed_dotprod > mixedprod/2:\n",
    "        return \"b\"\n",
    "    elif mixed_dotprod < mixedprod/2:\n",
    "        return \"p\"\n",
    "    else:\n",
    "        return 'ucf'\n",
    "    \n",
    "def connect(cv, radius, bloblist): # center of blob2, radius of all blobs, list of other blobs\n",
    "    num_connections = 0\n",
    "    norm_radius = 15\n",
    "    total_separations = 0\n",
    "    normalized_dists = []\n",
    "    mixedvecs = [] #2 mixed connection vectors\n",
    "    for blob2 in bloblist:\n",
    "        cv2 = (blob2[1], blob2[0]) # center of blob2\n",
    "        vector_d = vector_dist(cv, cv2)\n",
    "        total_separations += vector_d\n",
    "        if vector_d <= 2*radius: # blob centers closer than diameter of one blob\n",
    "            num_connections += 1\n",
    "            mixedvecs.append((vector_sub(cv2,cv), vector_d))\n",
    "        else:\n",
    "            pass\n",
    "        normalized_dists.append(vector_d/(2*norm_radius))\n",
    "    return (num_connections, normalized_dists, total_separations, mixedvecs)\n",
    "\n",
    "def vector_sub(b, a):\n",
    "    sub = [b[i]-a[i] for i in range(min(len(b), len(a)))]\n",
    "    return sub\n",
    "def dot_prod(a,b):\n",
    "    dot = [a[i]*b[i] for i in range(min(len(a), len(b)))]\n",
    "    return dot\n",
    "\n",
    "def vector_dist(v1, v2): # euclidean distance between 2 points\n",
    "    return math.sqrt(np.sum([(v1[i] - v2[i])**2 for i in range(min(len(v1), len(v2)))]))\n",
    "\n",
    "def third_item(l1):\n",
    "        return l1[2]        \n",
    "\n",
    "#from pair of labelled, thresholded images, return an image category (of three)\n",
    "\n",
    "#from pair of labelled,thresholded images, return the x/y sign or x/y magnitude for the transparent dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Filtering broken ad oddframes\"\n",
    "\"USING LI THRESHOLD\"\n",
    "# apply total thresholding to each of a list of frames; filter slides with wrong number\n",
    "def total_threshold_filter(framelist, framesetname): \n",
    "    # returns a new list, different from the orginal\n",
    "    fll = len(framelist)\n",
    "    m_lab = measure.label\n",
    "    m_rop = measure.regionprops\n",
    "    expected_blobs = 4\n",
    "    expected_connections = 5\n",
    "    p_bond = 15*1.3\n",
    "    g_bond = 15*1\n",
    "    m_bond = 15*1.5\n",
    "    \n",
    "    filtrate_prop =[]\n",
    "    passes = []\n",
    "    all_props = []\n",
    "    blobset = [] #labelled imgs\n",
    "    for i in range(fll):\n",
    "       # ---setup image and detect blobs ----------------\n",
    "        if framesetname == 'broken' or framesetname == 'odd_s':\n",
    "            framesetname = 'ucf'\n",
    "        frame = framelist[i]\n",
    "        thresh_img = frame > threshold_li(frame)# binary image\n",
    "        \n",
    "        phighlight = morphology.binary_opening(thresh_img, disk(8))\n",
    "        img = np.copy(frame)\n",
    "        img[phighlight==0] = 0\n",
    "        pblobs =skimage.feature.blob_doh(img, min_sigma =8, max_sigma = 17, threshold = 0.007, num_sigma= 15, overlap=0.6)\n",
    "        \n",
    "        ghighlight = gaussian(\n",
    "        morphology.binary_opening(\n",
    "             phighlight\n",
    "                           , square(4)), sigma = 0.65)\n",
    "        img = np.copy(frame)\n",
    "        img[ghighlight==0] = 0\n",
    "        gblobs =skimage.feature.blob_doh(img, min_sigma =9, max_sigma = 16, threshold = 0.007, num_sigma= 15, overlap=0.5)\n",
    "    \n",
    "        \n",
    "        blobset.append([pblobs, gblobs])\n",
    "        ngblobs = len(gblobs)\n",
    "        npblobs = len(pblobs) \n",
    "        num_blobs = ngblobs + npblobs  \n",
    "        \n",
    "        def reducer(connections):\n",
    "            return [sum([con[0] for con in connections]), \n",
    "                              list(chain(*[con[1] for con in connections])),\n",
    "                             sum([con[2] for con in connections]),\n",
    "                             list(chain(*[con[3] for con in connections]))]\n",
    "            \n",
    "        plas_on_glas_dists =[connect((pblob[1], pblob[0]),m_bond, gblobs) for pblob in pblobs]\n",
    "        plas_on_glas_dists = reducer(plas_on_glas_dists)\n",
    "        \n",
    "        num_mconnections = plas_on_glas_dists[0]\n",
    "        mdistances = plas_on_glas_dists[1]\n",
    "        mtotallengths = plas_on_glas_dists[2]\n",
    "        \n",
    "        glas_on_glas_dists =[connect((gblobs[i][1], gblobs[i][0]),g_bond, gblobs[i+1:]) for i in range(ngblobs-1)]\n",
    "        glas_on_glas_dists = reducer(glas_on_glas_dists)\n",
    "        \n",
    "        num_gconnections = glas_on_glas_dists[0]\n",
    "        gdistances = glas_on_glas_dists[1]\n",
    "        gtotallengths = glas_on_glas_dists[2]\n",
    "        \n",
    "        plas_on_plas_dists = [connect((pblobs[i][1], pblobs[i][0]),p_bond, pblobs[i+1:]) for i in range(npblobs-1)]\n",
    "        plas_on_plas_dists = reducer(plas_on_plas_dists)\n",
    "        \"\"\"[sum([pop[0] for pop in plas_on_plas_dists]), \n",
    "                              list(chain(*[pop[1] for pop in plas_on_plas_dists])),\n",
    "                             sum([pop[2] for pop in plas_on_plas_dists]),\n",
    "                             list(chain(*[pop[3] for pop in plas_on_plas_dists]))]\"\"\"\n",
    "        num_pconnections = plas_on_plas_dists[0]\n",
    "        pdistances = plas_on_plas_dists[1]\n",
    "        ptotallengths = plas_on_plas_dists[2]\n",
    "        mixedvecs = plas_on_plas_dists[3]\n",
    "        \n",
    "        \n",
    "        num_connections = sum([num_pconnections, num_gconnections,num_mconnections])\n",
    "        distances = list(chain(pdistances, gdistances, mdistances))       \n",
    "        totallengths = sum([ptotallengths, gtotallengths, mtotallengths])\n",
    "        \n",
    "        mixedlen = len(mixedvecs)\n",
    "        mixed_prod = abs(np.prod(mixedvecs[:,1]))\n",
    "        if mixedlen > 2:            \n",
    "            mixed_dotprod = abs(dot_prod(mixedvecs[:,0]))\n",
    "        else:\n",
    "            mixed_dotprod =mixed_prod/2\n",
    "        #----------------------filter------------------------- can use actual filter\n",
    "        properties = {'num_blobs':num_blobs,\n",
    "                      'num_pblobs':npblobs,\n",
    "                      'num_gblobs':ngblobs,\n",
    "                      'num_connections': num_connections,\n",
    "                      'num_pconnections':num_pconnections, \n",
    "                      'num_gconnections':num_gconnections, \n",
    "                      'num_mconnections':num_mconnections,\n",
    "                     'totallengths':totallengths, \n",
    "                      'ptotallengths':ptotallengths, \n",
    "                      'gtotallengths':gtotallengths, \n",
    "                      'mtotallengths':mtotallengths,\n",
    "                     'distances':distances, \n",
    "                      'pdistances':pdistances, \n",
    "                      'gdistances':gdistances, \n",
    "                      'mdistances':mdistances,\n",
    "                     'mixed_dotprod':mixed_dotprod}\n",
    "        #print(properties)\n",
    "        all_props.append(properties)\n",
    "        \n",
    "        #print('blobs, max_blob, max_rad, num_connections, cons_of_max:', (blobs, max_blob, max_rad, num_connections, cons_of_max))    \n",
    "        test = (num_connectios == expected_connections and num_blobs==expected_blobs)\n",
    "        if test: \n",
    "            #-----------------------------classify pt 1---------------------------------------\n",
    "            \n",
    "            clas = sideify(ptotallengths,gtotallengths,mtotallengths,\n",
    "                num_pconnections,num_gconnections, num_mconnections,mixedlen, mixed_prod, mixed_dotprod)\n",
    "            filtrate_prop.append(properties)\n",
    "        else:\n",
    "            clas = 'ucf'\n",
    "        if clas == framesetname:\n",
    "            passes.append(properties)\n",
    "            \n",
    "    return [filtrate_prop, passes, all_props, blobset]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "list indices must be integers or slices, not tuple",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-d2d074970e54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mlimgs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframesetnames\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtotal_threshold_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mframesets\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframesetnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mfiltrates_props\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mpasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-9-0bd9843522bb>\u001b[0m in \u001b[0;36mtotal_threshold_filter\u001b[1;34m(framelist, framesetname)\u001b[0m\n\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m         \u001b[0mmixedlen\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmixedvecs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 82\u001b[1;33m         \u001b[0mmixed_prod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmixedvecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     83\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mmixedlen\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m             \u001b[0mmixed_dotprod\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdot_prod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmixedvecs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: list indices must be integers or slices, not tuple"
     ]
    }
   ],
   "source": [
    "filtrates_props = []\n",
    "passes = []\n",
    "a_props = []\n",
    "p_rats = []\n",
    "limgs = []\n",
    "for i in range(len(framesetnames)):\n",
    "    x = total_threshold_filter([y[0] for y in framesets[i]], framesetnames[i])\n",
    "    filtrates_props.append(x[0])\n",
    "    passes.append(x[1])\n",
    "    #all_props.append(x[2])\n",
    "    #print(framesets[i])\n",
    "\n",
    "    orig = len(framesets[i])\n",
    "    fil = len(x[0])\n",
    "    pas = len(x[1])\n",
    "    print(orig, fil, pas)\n",
    "    print(framesetnames[i], \"_vid\")\n",
    "    print(\"original_vid: \", orig)\n",
    "    print(\"filtrate: \", fil)\n",
    "    if orig != 0:\n",
    "        print(\"pass ratio: \", pas*100/orig)\n",
    "        p_rats.append(pas*100/orig)\n",
    "    print(\"\\n\")\n",
    "        \n",
    "\n",
    "    a_props.append(x[2])\n",
    "    limgs.append(x[3])\n",
    "Pass_ratios = p_rats\n",
    "Filtrates_props = filtrates_props\n",
    "st = framesets\n",
    "np.save('shape_testing.npy',st)\n",
    "print(len(a_props), len(filtrates_props), len(passes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {'num_blobs':[],\n",
    "                      'num_pblobs':[],\n",
    "                      'num_gblobs':[],\n",
    "                      'num_connections': [],\n",
    "                      'num_pconnections':[], \n",
    "                      'num_gconnections':[], \n",
    "                      'num_mconnections':[],\n",
    "                     'totallengths':[], \n",
    "                      'ptotallengths':[], \n",
    "                      'gtotallengths':[], \n",
    "                      'mtotallengths':[],\n",
    "                     'distances':[], \n",
    "                      'pdistances':[], \n",
    "                      'gdistances':[], \n",
    "                      'mdistances':[]}\n",
    "strings = names.keys()\n",
    "distances = [string for string in strings if 'distances' in string]\n",
    "simplenames = strings - distances\n",
    "print(distances, simplenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Everything\"\"\"\n",
    "\n",
    "# use area information from properties\n",
    "\n",
    "\n",
    "for name in simplenames:\n",
    "    klist = []\n",
    "    for i in range(num_shape_cats):\n",
    "        x = [h[name] for h in a_props[i]]\n",
    "        klist.append(x) #list of areas for every category\n",
    "    print(\"%s averages: \" %name)\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.average(klist[i]))) for i in range(num_shape_cats)]\n",
    "    print(\"%s variances: \" %name)\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.var(klist[i]))) for i in range(num_shape_cats)]    \n",
    "    fig, ax = plt.subplots(figsize=(18,8))\n",
    "    #plt.xticks(np.arange(0, 2501, 75))\n",
    "    plt.title(\"Frequency distribution: \" + name)\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    for j in range(0, num_shape_cats-1):\n",
    "        x = klist[j]\n",
    "        sns.distplot(x, hist = True, kde=False,rug=False, label = framesetnames[j])\n",
    "    plt.legend() \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "print(len(klist[0]))\n",
    "for name in distances:\n",
    "    klist = []\n",
    "    for i in range(num_shape_cats):\n",
    "        x = [d for lis in [h[name] for h in a_props[i]] for d in lis]\n",
    "        klist.append(x) #list of areas for every category\n",
    "    print(len(klist[0]))\n",
    "    print(\"%s averages: \" %name)\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.average(klist[i]))) for i in range(num_shape_cats)]\n",
    "    print(\"%s variances: \"  %name)\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.var(klist[i]))) for i in range(num_shape_cats)]    \n",
    "    fig, ax = plt.subplots(figsize=(18,8))\n",
    "    #plt.xticks(np.arange(0, 2501, 75))\n",
    "    plt.title(\"Frequency distribution: \" +  name)\n",
    "    plt.xlabel( name)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    for j in range(0, num_shape_cats-2):\n",
    "        x = klist[j]\n",
    "        sns.violinplot(x)#, hist = False, norm_hist=False,rug=True, label = framesetnames[j])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"After first tests\"\"\"\n",
    "# use area information from properties\n",
    "\n",
    "\n",
    "for name in simplenames:\n",
    "    klist = []\n",
    "    for i in range(num_shape_cats):\n",
    "        x = [h[name] for h in filtrates_props[i]]\n",
    "        klist.append(x) #list of areas for every category\n",
    "    print(\"%s averages: \" %name)\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.average(klist[i]))) for i in range(num_shape_cats)]\n",
    "    print(\"%s variances: \" %name)\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.var(klist[i]))) for i in range(num_shape_cats)]    \n",
    "    fig, ax = plt.subplots(figsize=(18,8))\n",
    "    #plt.xticks(np.arange(0, 2501, 75))\n",
    "    plt.title(\"Frequency distribution: \" + name)\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    for j in range(0, num_shape_cats):\n",
    "        x = klist[j]\n",
    "        sns.distplot(x, hist = True, kde=False,rug=False, label = framesetnames[j])\n",
    "    plt.legend() \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "print(len(klist[0]))\n",
    "for name in distances:\n",
    "    klist = []\n",
    "    for i in range(num_shape_cats):\n",
    "        x = [d for lis in [h[name] for h in filtrates_props[i]] for d in lis]\n",
    "        klist.append(x) #list of areas for every category\n",
    "    print(len(klist[0]))\n",
    "    print(\"%s averages: \" %name)\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.average(klist[i]))) for i in range(num_shape_cats)]\n",
    "    print(\"%s variances: \"  %name)\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.var(klist[i]))) for i in range(num_shape_cats)]    \n",
    "    fig, ax = plt.subplots(figsize=(18,8))\n",
    "    #plt.xticks(np.arange(0, 2501, 75))\n",
    "    plt.title(\"Frequency distribution: \" +  name)\n",
    "    plt.xlabel( name)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    for j in range(0, num_shape_cats-1):\n",
    "        x = klist[j]\n",
    "        sns.distplot(x, hist = False, rug=True, label = framesetnames[j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"Correctly classified\"\"\"\n",
    "# use area information from properties\n",
    "\n",
    "\n",
    "for name in simplenames:\n",
    "    klist = []\n",
    "    for i in range(num_shape_cats):\n",
    "        x = [h[name] for h in passes[i]]\n",
    "        klist.append(x) #list of areas for every category\n",
    "    print(\"%s averages: \" %name)\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.average(klist[i]))) for i in range(num_shape_cats)]\n",
    "    print(\"%s variances: \" %name)\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.var(klist[i]))) for i in range(num_shape_cats)]    \n",
    "    fig, ax = plt.subplots(figsize=(18,8))\n",
    "    #plt.xticks(np.arange(0, 2501, 75))\n",
    "    plt.title(\"Frequency distribution: \" + name)\n",
    "    plt.xlabel(name)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    for j in range(0, num_shape_cats-1):\n",
    "        x = klist[j]\n",
    "        sns.distplot(x, hist = True, kde=False,rug=False, label = framesetnames[j])\n",
    "    plt.legend() \n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "print(len(klist[0]))\n",
    "for name in distances:\n",
    "    klist = []\n",
    "    for i in range(num_shape_cats):\n",
    "        x = [d for lis in [h[name] for h in passes[i]] for d in lis]\n",
    "        klist.append(x) #list of areas for every category\n",
    "    print(len(klist[0]))\n",
    "    print(\"%s averages: \" %name)\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.average(klist[i]))) for i in range(num_shape_cats)]\n",
    "    print(\"%s variances: \"  %name)\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.var(klist[i]))) for i in range(num_shape_cats)]    \n",
    "    fig, ax = plt.subplots(figsize=(18,8))\n",
    "    #plt.xticks(np.arange(0, 2501, 75))\n",
    "    plt.title(\"Frequency distribution: \" +  name)\n",
    "    plt.xlabel( name)\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    for j in range(0, num_shape_cats-1):\n",
    "        x = klist[j]\n",
    "        sns.distplot(x, hist = False, rug=True, label = framesetnames[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
