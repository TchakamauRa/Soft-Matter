{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Currently works on a single frame. Later, will add a loop that can work on all frames.'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import av\n",
    "import numpy as np\n",
    "import math\n",
    "from skimage.morphology import *\n",
    "from skimage.feature import *\n",
    "import matplotlib.pyplot as plt #for maknig plots inside the notebook\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from operator import attrgetter\n",
    "import seaborn as sns\n",
    "from operator import attrgetter\n",
    "from itertools import chain\n",
    "from skimage import measure\n",
    "from skimage import morphology\n",
    "from skimage.util import invert\n",
    "from skimage.filters import *\n",
    "from scipy import ndimage\n",
    "from glob import glob\n",
    "from skvideo.io import vread\n",
    "\"\"\"Currently works on a single frame. Later, will add a loop that can work on all frames.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take largest isodata image region, and return aclassification\n",
    "def sideify(cons_of_max):    \n",
    "    if cons_of_max == 3:\n",
    "        return \"c\"\n",
    "    elif cons_of_max == 2:\n",
    "        return \"t\"\n",
    "    else:\n",
    "        return \"ucf\"\n",
    "    \n",
    "def connect(cv, radius, bloblist): # center of blob2, radius of all blobs, list of other blobs\n",
    "    connections = 0\n",
    "    for blob2 in bloblist:\n",
    "        cv2 = (blob2[0], blob2[1]) # center of blob2\n",
    "        if vector_dist(cv, cv2) <= 2*radius: # blob centers closer than diameter of one blob\n",
    "            connections += 1\n",
    "        else:\n",
    "            pass\n",
    "    return connections\n",
    "\n",
    "def vector_dist(v1, v2): # euclidean distance between 2 points\n",
    "    return math.sqrt(np.sum([(v1[i] - v2[i])**2 for i in range(len(v1))]))\n",
    "\n",
    "def third_item(l1):\n",
    "        return l1[2]        \n",
    "\n",
    "#from pair of labelled, thresholded images, return an image category (of three)\n",
    "\n",
    "#from pair of labelled,thresholded images, return the x/y sign or x/y magnitude for the transparent dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 [5.0, 10.0] hello\n"
     ]
    }
   ],
   "source": [
    "connect_test = connect((0, 0),2, [(0, 3, 1), (3, 3, 1.1), (0, 0, 5), (9, 9, 100)]) #2\n",
    "vector_dist_test = [vector_dist((0, 0), (3, 4)), vector_dist((1,1,0), (1,7,8))]\n",
    "third_item_test = third_item([0, \"99\", \"hello\", [55, 67]])\n",
    "print(connect_test, vector_dist_test , third_item_test )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"Filtering broken ad oddframes\"\n",
    "\"USING LI THRESHOLD\"\n",
    "# apply total thresholding to each of a list of frames; filter slides with wrong number\n",
    "def total_threshold_filter(framelist, framesetname): \n",
    "    # returns a new list, different from the orginal\n",
    "    fll = len(framelist)\n",
    "    m_lab = measure.label\n",
    "    m_rop = measure.regionprops\n",
    "    expected_blobs = 4\n",
    "    expected_connections = 5\n",
    "    \n",
    "    filtrate_prop =[]\n",
    "    passes = []\n",
    "    all_props = []\n",
    "    blobset = [] #labelled imgs\n",
    "    for i in range(fll):\n",
    "       # ---setup image and detect blobs ----------------\n",
    "        if framesetname == 'broken' or framesetname == 'odd_s':\n",
    "            framesetname = 'ucf'\n",
    "        frame = framelist[i]\n",
    "        thresh_img = frame > threshold_isodata(frame)# binary image\n",
    "        highlight = morphology.erosion(morphology.opening(thresh_img, square(7)),\n",
    "                                        square(2))\n",
    "        img = np.copy(frame)\n",
    "        img[highlight==0] = 0\n",
    "        blobs =skimage.feature.blob_doh(img, min_sigma = 6, max_sigma = 16, threshold = 0.007, num_sigma= 15, overlap=0.75)\n",
    "        blobset.append(blobs)\n",
    "        \n",
    "        num_connections = 0\n",
    "        num_blobs = len(blobs)\n",
    "        \n",
    "        for i in range(num_blobs-1):\n",
    "            blob = blobs[i]\n",
    "            radius = blob[2]\n",
    "            center_vec = (blob[0], blob[1])\n",
    "            num_connections += connect(center_vec, radius, blobs[i+1::])\n",
    "        #----------------------filter------------------------- can use actual filter\n",
    "        \n",
    "        properties = []\n",
    "        max_blob = max(blobs, key = third_item)\n",
    "        cons_of_max = connect((max_blob[0],max_blob[1]),max_blob[2], blobs)\n",
    "        properties = [num_blobs, num_connections, cons_of_max]\n",
    "        all_props.append(properties)\n",
    "            \n",
    "        test = (num_blobs == expected_blobs\n",
    "                and num_connections == expected_connections \n",
    "               )\n",
    "        if test:  \n",
    "            if (cons_of_max == 3 or cons_of_max == 2):\n",
    "                #-----------------------------classify pt 1---------------------------------------\n",
    "                clas = sideify(cons_of_max)\n",
    "                filtrate_prop.append(properties)\n",
    "            else:\n",
    "                clas = 'ucf'\n",
    "        else:\n",
    "            clas = 'ucf'\n",
    "        if clas == framesetname:\n",
    "            passes.append(properties)\n",
    "            \n",
    "    return [filtrate_prop, passes, all_props, blobset]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./tchakamau\\\\Trnansparentd\\\\45400_10Vpp_0.avi', './tchakamau\\\\Trnansparentd\\\\45403_10Vpp_6.avi', './tchakamau\\\\Trnansparentd\\\\45405_10Vpp_2.avi']\n"
     ]
    }
   ],
   "source": [
    "filenames = filename = glob(\"./tchakamau/trn*/*[1][0]v*[0,6,2].avi\")#glob(\"./tchakamau/New_setup/*.avi\")# glob(\"./tchakamau/New_setup/45681_10Vpp_25.avi\") #filenames = \n",
    "print(filenames)\n",
    "num_shape_cats = 4\n",
    "Pass_ratios = np.zeros((len(filenames), num_shape_cats))\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"TEST FRAME RANGES FROM VIDEOs\"\"\"\n",
    "phantom_frames = {\"t\" : list(range(37949, 30697, -25)),\n",
    "                  \"c\" :list(range(20951, 20172, -3)), \n",
    "                 \"broken\" :list(range(21927, 21593, -1)) ,\n",
    "                 \"odd_s\" :list(range(21593,21577, -1)) }\n",
    "phantom_frames_2 = {\"t\" : list(range(26391, 22129, -25)),\n",
    "                  \"c\" :list(range(21152, 20607, -1 )), \n",
    "                 \"broken\" :list(range(21979, 21309, -2)) ,\n",
    "                 \"odd_s\" :list(chain(range(22115, 22080, -1), range(22017,21980, -1), range(21302, 21272, -1))) }\n",
    "phantom_frames_3 = {\"t\" :list(range(30104, 29591, -1)),\n",
    "                  \"c\" :list(range(30816, 30375, -2)), \n",
    "                 \"broken\" :list(range(30340, 30288, -1)) ,\n",
    "                 \"odd_s\" :[]}\n",
    "\n",
    "\"\"\"phantom_frames = {\"t\" : list(range(13268, 13529)),\n",
    "                  \"c\" :list(range(16740, 16951)), \n",
    "                 \"broken\" :list(range(14224, 14623, 2)) ,\n",
    "                 \"odd_s\" :list(range(14001,14044)) }\n",
    "phantom_frames_2 = {\"t\" : list(range(21985, 22175)),\n",
    "                  \"c\" :list(range(18192, 18400)), \n",
    "                 \"broken\" :list(range(20904, 21625, 4)) ,\n",
    "                 \"odd_s\" :list(chain(range(20360, 20381), range(20386, 20420))) }\n",
    "phantom_frames_3 = {\"t\" :list(range(3266, 3491)),\n",
    "                  \"c\" :list(range(3574, 3597)), \n",
    "                 \"broken\" :list(range(3686, 4209, 3)) ,\n",
    "                 \"odd_s\" :list(chain(range(3521, 3538), range(3668, 3680))) }\n",
    "phantom_frames_4 = {\"t\" :list(range(9361, 9709, 2)),\n",
    "                  \"c\" :list(range(12800,13578, 3)), \n",
    "                 \"broken\" :list(range(11057, 11482, 2)) ,\n",
    "                 \"odd_s\" :[] }\"\"\"\n",
    "phantom_frame_sets = [phantom_frames,phantom_frames_2,phantom_frames_3]\n",
    "trigger_frames = [37949, 26391,30816]#[13268, 18192, 2964, 8535]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "37950\n",
      "22303\n",
      "26935\n"
     ]
    }
   ],
   "source": [
    "t_frames = []\n",
    "tvals  = []\n",
    "c_frames = []\n",
    "cvals = []\n",
    "\n",
    "odd_s_frames = []\n",
    "oddsvals = []\n",
    "broken_frames = []\n",
    "brokenvals = []\n",
    "\n",
    "\n",
    "framesets = [t_frames, c_frames,  odd_s_frames, \n",
    "             broken_frames]\n",
    "frametypevals = [tvals, cvals,  oddsvals, brokenvals]\n",
    "framesetnames = [\"t\", \"c\", \"odd_s\", \"broken\"]\n",
    "filtrates_props = []\n",
    "passes = []\n",
    "i_props = []\n",
    "t_props = []\n",
    "    \n",
    "for vidnum in range(len(filenames)):\n",
    "    frames = vread(filenames[vidnum])\n",
    "    frame_vid = frames[:, :, :, 2]# making videos ino a frame list\n",
    "    print(len(frame_vid))\n",
    "    \n",
    "    \n",
    "    for i in range(len(framesetnames)):\n",
    "        typevals = phantom_frame_sets[vidnum].get(framesetnames[i])\n",
    "        frametypevals[i].extend(typevals)\n",
    "        #print(len(typevals), trigger_frames[vidnum], typevals[-1], typevals[-1]-trigger_frames[vidnum])\n",
    "        framesets[i].extend([(frame_vid[trigger_frames[vidnum]-x], x) for x in typevals])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "975 0 0\n",
      "t _vid\n",
      "original_vid:  975\n",
      "filtrate:  0\n",
      "pass ratio:  0.0\n",
      "\n",
      "\n",
      "1026 0 0\n",
      "c _vid\n",
      "original_vid:  1026\n",
      "filtrate:  0\n",
      "pass ratio:  0.0\n",
      "\n",
      "\n",
      "118 0 118\n",
      "odd_s _vid\n",
      "original_vid:  118\n",
      "filtrate:  118\n",
      "pass ratio:  100.0\n",
      "\n",
      "\n",
      "721 0 721\n",
      "broken _vid\n",
      "original_vid:  721\n",
      "filtrate:  721\n",
      "pass ratio:  100.0\n",
      "\n",
      "\n",
      "4 4 4\n"
     ]
    }
   ],
   "source": [
    "filtrates_props = []\n",
    "passes = []\n",
    "a_props = []\n",
    "p_rats = []\n",
    "limgs = []\n",
    "for i in range(len(framesetnames)):\n",
    "    x = total_threshold_filter([y[0] for y in framesets[i]], framesetnames[i])\n",
    "    filtrates_props.append(x[0])\n",
    "    passes.append(x[2])\n",
    "    #all_props.append(x[2])\n",
    "    #print(framesets[i])\n",
    "\n",
    "    orig = len(frametypevals[i])\n",
    "    fil = len(x[1])\n",
    "    print(orig, len(filtrates_props[i]), len(x[1]))\n",
    "    print(framesetnames[i], \"_vid\")\n",
    "    print(\"original_vid: \", orig)\n",
    "    print(\"filtrate: \", fil)\n",
    "    if orig != 0:\n",
    "        print(\"pass ratio: \", fil*100/orig)\n",
    "        p_rats.append(fil*100/orig)\n",
    "    print(\"\\n\")\n",
    "        \n",
    "\n",
    "    a_props.append(x[2])\n",
    "    limgs.append(x[3])\n",
    "Pass_ratios = p_rats\n",
    "Filtrates_props = filtrates_props\n",
    "st = framesets\n",
    "np.save('shape_testing.npy',st)\n",
    "print(len(a_props), len(filtrates_props), len(passes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "\"\"\"FINDING CORRECT THRESHOLDS FOR SEPARATING BROKEN AND ODD SHAPED FRAMES\"\"\"\n",
    "\n",
    "# use area information from properties\n",
    "Inertias_list = []\n",
    "for i in range(num_shape_cats):\n",
    "    x = [h.inertia_tensor[0, 0] + h.inertia_tensor[1,1] for h in I_thresh_props[i]]\n",
    "    Inertias_list.append(x) #list of areas for every category\n",
    "print(\"Inertia averages: \")\n",
    "[print(\"%s : %.f \" %(framesetnames[i], np.average(Inertias_list[i]))) for i in range(num_shape_cats)]\n",
    "print(\"Inertia variances: \")\n",
    "[print(\"%s : %.f \" %(framesetnames[i], np.var(Inertias_list[i]))) for i in range(num_shape_cats)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "plt.title(\"Frequency distribution: inertia tensor_vid1\")\n",
    "plt.xlabel(\"inertia tensor\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "for j in range(0, len(framesets)):\n",
    "    x = Inertias_list[j]\n",
    "    sns.distplot(x, hist = False, rug=True, label = framesetnames[j])\n",
    "#--------\n",
    "\n",
    "#------------------------\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "plt.title(\"Frequency distribution: inertia tensor_vid1\")\n",
    "plt.xlabel(\"inertia tensor\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "for j in range(0, len(framesets)):\n",
    "    x = Inertias_list[j]\n",
    "    sns.distplot(x, hist = False, rug=True, label = framesetnames[j])\n",
    "\n",
    "propnames = [\"convex_area\", \"minor_axis_length\", \"major_axis_length\", \"solidity\", \"eccentricity\"]\n",
    "for k in range(0, len(propnames)):\n",
    "    klist = []\n",
    "    for i in range(num_shape_cats):\n",
    "        x = [getattr(h, propnames[k]) for h in I_thresh_props[i]]\n",
    "        klist.append(x) #list of areas for every category\n",
    "    print(\"%s averages: \" %propnames[k])\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.average(klist[i]))) for i in range(num_shape_cats)]\n",
    "    print(\"%s variances: \" %propnames[k])\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.var(klist[i]))) for i in range(num_shape_cats)]    \n",
    "    fig, ax = plt.subplots(figsize=(18,8))\n",
    "    #plt.xticks(np.arange(0, 2501, 75))\n",
    "    plt.title(\"Frequency distribution: \" + propnames[k])\n",
    "    plt.xlabel(propnames[k])\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    for j in range(0, len(framesets)):\n",
    "        x = klist[j]\n",
    "        sns.distplot(x, hist = False, rug=True, label = framesetnames[j])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"\"\"Broken objects are filtered out by their area and we then move on to identifying odd shaped objects \n",
    "    from the remaining frames\"\"\"\n",
    "framesets.remove(broken_frames)\n",
    "framesetnames.remove(\"broken\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"STILL RESULTS OF FILTERING\"\"\"\n",
    "Inertias_list = []\n",
    "for i in range(num_shape_cats):\n",
    "    x = [h[0].inertia_tensor[0, 0] + h[0].inertia_tensor[1,1] for h in Filtrates_props[i]]\n",
    "    Inertias_list.append(x) #list of areas for every category\n",
    "print(\"Inertia averages: \")\n",
    "[print(\"%s : %.f \" %(framesetnames[i], np.average(Inertias_list[i]))) for i in range(num_shape_cats)]\n",
    "print(\"Inertia variances: \")\n",
    "[print(\"%s : %.f \" %(framesetnames[i], np.var(Inertias_list[i]))) for i in range(num_shape_cats)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "plt.title(\"Frequency distribution: inertia tensor_vid\")\n",
    "plt.xlabel(\"inertia tensor\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "for j in range(0, len(framesets)):\n",
    "    x = Inertias_list[j]\n",
    "    sns.distplot(x, hist = False, rug=True, label = framesetnames[j])\n",
    "\n",
    "propnames = [\"convex_area\", \"minor_axis_length\", \"major_axis_length\", \"solidity\"]\n",
    "for k in range(0, len(propnames)):\n",
    "    klist = []\n",
    "    for i in range(num_shape_cats):\n",
    "        x = [getattr(h[0], propnames[k]) for h in Filtrates_props[i]]\n",
    "        klist.append(x) #list of areas for every category\n",
    "    print(\"%s averages: \" %propnames[k])\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.average(klist[i]))) for i in range(num_shape_cats)]\n",
    "    print(\"%s variances: \" %propnames[k])\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.var(klist[i]))) for i in range(num_shape_cats)]    \n",
    "    fig, ax = plt.subplots(figsize=(18,8))\n",
    "    #plt.xticks(np.arange(0, 2501, 75))\n",
    "    plt.title(\"Frequency distribution: \" + propnames[k])\n",
    "    plt.xlabel(propnames[k])\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    for j in range(0, len(framesets)):\n",
    "        x = klist[j]\n",
    "        sns.distplot(x, hist = False, rug=True, label = framesetnames[j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Pt3. Separating variosu shapes\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"SEE HOW THE ISODATA FILTER TREATS FRAMES - UNFILTERED\"                               "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"PTINTING ISODATA THRESHOLDS\"\"\"\n",
    "propnames = [\"area\", \"extent\"]\n",
    "for k in range(0, len(propnames)):\n",
    "    klist = []\n",
    "    for i in range(num_shape_cats):\n",
    "        x = [getattr(h[1], propnames[k]) for h in Filtrates_props[i]]\n",
    "        klist.append(x) #list of areas for every category\n",
    "    print(\"%s averages: \" %propnames[k])\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.average(klist[i]))) for i in range(num_shape_cats)]\n",
    "    print(\"%s variances: \" %propnames[k])\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.var(klist[i]))) for i in range(num_shape_cats)]    \n",
    "    fig, ax = plt.subplots(figsize=(18,8))\n",
    "    #plt.xticks(np.arange(0, 2501, 75))\n",
    "    plt.title(\"Frequency distribution: \" + propnames[k])\n",
    "    plt.xlabel(propnames[k])\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    for j in range(0, len(framesets)):\n",
    "        x = klist[j]\n",
    "        sns.distplot(x, hist = False, rug=True, label = framesetnames[j])\n",
    "        \n",
    "\n",
    "# most oddly shaped frames have elongated shapes, and the mnor axis length is below 40, except for one (of one partcular type)\n",
    "# where the pixels for a 'T' shape; this, while more rounded, has a huge convex hull. All frames wth convex hull area \n",
    "# over 2500 (very conservatve estimate) areoddly shaped (transition frames). \n",
    "# Together the criteria select for frames not in transition.\n",
    "#16766 is misclassified, but it isvery like a normally shaped t_l on most measures, so maybe it should be counted as one for this program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"FINDING CORRECT THRESHOLDS FOR SHAPE DISCRIMINATION\"\"\"\n",
    "\n",
    "\"\"\"STILL RESULTS OF FILTERING\"\"\"\n",
    "Inertias_list = []\n",
    "for i in range(num_shape_cats):\n",
    "    x = [h.inertia_tensor[0, 0] + h.inertia_tensor[1,1] for h in T_thresh_props[i]]\n",
    "    Inertias_list.append(x) #list of areas for every category\n",
    "print(\"Inertia averages: \")\n",
    "[print(\"%s : %.f \" %(framesetnames[i], np.average(Inertias_list[i]))) for i in range(num_shape_cats)]\n",
    "print(\"Inertia variances: \")\n",
    "[print(\"%s : %.f \" %(framesetnames[i], np.var(Inertias_list[i]))) for i in range(num_shape_cats)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "plt.title(\"Frequency distribution: inertia tensor_vid\")\n",
    "plt.xlabel(\"inertia tensor\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "for j in range(0, len(framesets)):\n",
    "    x = Inertias_list[j]\n",
    "    sns.distplot(x, hist = False, rug=True, label = framesetnames[j])\n",
    "\n",
    "    \n",
    "Inertias_list = []\n",
    "for i in range(num_shape_cats):\n",
    "    x = [h[1].inertia_tensor[0, 0] + h[1].inertia_tensor[1,1] for h in Filtrates_props[i]]\n",
    "    Inertias_list.append(x) #list of areas for every category\n",
    "print(\"Inertia averages: \")\n",
    "[print(\"%s : %.f \" %(framesetnames[i], np.average(Inertias_list[i]))) for i in range(num_shape_cats)]\n",
    "print(\"Inertia variances: \")\n",
    "[print(\"%s : %.f \" %(framesetnames[i], np.var(Inertias_list[i]))) for i in range(num_shape_cats)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(18,8))\n",
    "plt.title(\"Frequency distribution: inertia tensor_vid\")\n",
    "plt.xlabel(\"inertia tensor\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "for j in range(0, len(framesets)):\n",
    "    x = Inertias_list[j]\n",
    "    sns.distplot(x, hist = False, rug=True, label = framesetnames[j])\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "propnames = [\"convex_area\", \"minor_axis_length\", \"major_axis_length\", \"solidity\", \"eccentricity\"]\n",
    "for k in range(0, len(propnames)):\n",
    "    klist = []\n",
    "    for i in range(num_shape_cats):\n",
    "        x = [getattr(h, propnames[k]) for h in T_thresh_props[i]]\n",
    "        klist.append(x) #list of areas for every category\n",
    "    print(\"%s averages: \" %propnames[k])\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.average(klist[i]))) for i in range(num_shape_cats)]\n",
    "    print(\"%s variances: \" %propnames[k])\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.var(klist[i]))) for i in range(num_shape_cats)]    \n",
    "    fig, ax = plt.subplots(figsize=(18,8))\n",
    "    #plt.xticks(np.arange(0, 2501, 75))\n",
    "    plt.title(\"Frequency distribution: \" + propnames[k])\n",
    "    plt.xlabel(propnames[k])\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    for j in range(0, len(framesets)):\n",
    "        x = klist[j]\n",
    "        sns.distplot(x, hist = False, rug=True, label = framesetnames[j])\n",
    "        \n",
    "    klist = []\n",
    "    for i in range(num_shape_cats):\n",
    "        x = [getattr(h[1], propnames[k]) for h in Filtrates_props[i]]\n",
    "        klist.append(x) #list of areas for every category\n",
    "    print(\"%s averages: \" %propnames[k])\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.average(klist[i]))) for i in range(num_shape_cats)]\n",
    "    print(\"%s variances: \" %propnames[k])\n",
    "    [print(\"%s : %.f \" %(framesetnames[i], np.var(klist[i]))) for i in range(num_shape_cats)]    \n",
    "    fig, ax = plt.subplots(figsize=(18,8))\n",
    "    #plt.xticks(np.arange(0, 2501, 75))\n",
    "    plt.title(\"Frequency distribution: \" + propnames[k])\n",
    "    plt.xlabel(propnames[k])\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    for j in range(0, len(framesets)):\n",
    "        x = klist[j]\n",
    "        sns.distplot(x, hist = False, rug=True, label = framesetnames[j])\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "# don't use: extent, perimeter, minor axis lengths, solidity, eccetricity\n",
    "# inertia: 300 - 360 br/bl, 350 - 415 tr/tl, 417/412 - bm\n",
    "# mal: 56 - 63 br/bl, 63 - 70 tr/tl, 68 bm\n",
    "# ecc: .63 - .78 br/bl, .76 - .83 tr/tl, .76 bm\n",
    "\n",
    "# if solidity <= .76 and inertia > 400 => bm\n",
    "# elif inertia >=355 and mal >= 63 => tl/tr\n",
    "# elif inertia <= 355 and mal <= 63 => bl/br\n",
    "# else unclassifiable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"DO A PCA ON EACH OF THE SETS AND PLOT SEPARATION. DISPLAY PRINCIPAL AXIS LOADINGS\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
