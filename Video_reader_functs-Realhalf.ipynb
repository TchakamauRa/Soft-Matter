{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is video reader with all operations inside fnctions, so they can be called on \\n    each frame out of a set of frames, and each video out of a set of videos\\n    '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This is video reader with all operations inside fnctions, so they can be called on \n",
    "    each frame out of a set of frames, and each video out of a set of videos\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports\"\"\"\n",
    "import matplotlib.pyplot as plt #for maknig plots inside the notebook\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from skvideo.io import vreader, ffprobe\n",
    "from skimage import measure, morphology, feature, filters\n",
    "from skimage.filters import *\n",
    "from skimage.morphology import *\n",
    "from operator import attrgetter\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import chain\n",
    "#from functools import partial, update_wrapper\n",
    "from scipy import ndimage \n",
    "#from pims import pipeline, Video\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict\n",
    "from skimage.morphology import *\n",
    "from skimage.feature import *\n",
    "from skimage.filters import *\n",
    "#import antigravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions\"\"\"\n",
    "# apply total thresholding to each of a list of frames; filter slides with wrong number\n",
    "\n",
    "def total_threshold_filter(frame, frame_no, transition_threshold, class_thresh,\n",
    "                           broken_count, class_num, origin, last_class, last_whole, state_start, filtrate_len, \n",
    "                           classes, transitions, times): \n",
    "    \n",
    "   \n",
    "    \n",
    "   # ---setup image and detect blobs ----------------\n",
    "    thresh_img = frame > threshold_isodata(frame)# binary image\n",
    "        \n",
    "    phighlight = morphology.binary_opening(thresh_img, disk(9))\n",
    "    img = np.copy(frame)\n",
    "    img[phighlight==0] = 0\n",
    "    pblobs =blob_doh(img, min_sigma =8, max_sigma = 16, threshold = 0.008, num_sigma= 15, overlap=0.5)\n",
    "    \n",
    "    ghighlight = gaussian(\n",
    "        opening(\n",
    "             (thresh_img^phighlight)\n",
    "                           , disk(2)), sigma = 0.65)\n",
    "    img = np.copy(frame)\n",
    "    img[ghighlight==0] = 0\n",
    "    gblobs = blob_doh(img, min_sigma =7, max_sigma = 16, threshold = 0.012)\n",
    "    \n",
    "\n",
    "    ngblobs = len(gblobs)\n",
    "    npblobs = len(pblobs) \n",
    "    num_blobs = ngblobs + npblobs\n",
    "   \n",
    "    glas_on_glas_dists =np.array([connect((gblobs[i][1], gblobs[i][0]),(g_bond, fg_bond), gblobs[i+1:]) for i in range(ngblobs-1)])\n",
    "    num_gconnections, num_fgconnections = reducer(glas_on_glas_dists)\n",
    "\n",
    "\n",
    "    plas_on_plas_dists = np.array([connect((pblobs[i][1], pblobs[i][0]),(p_bond, fp_bond), pblobs[i+1:]) for i in range(npblobs-1)])\n",
    "    num_pconnections, num_fpconnections = reducer(plas_on_plas_dists)\n",
    "\n",
    "\n",
    "    num_connections = sum([num_pconnections, num_gconnections])\n",
    "    \n",
    "    #----------------------filter------------------------- can use actual filter\n",
    "    \"\"\"test = (num_connections >= expected_connections and num_blobs>=expected_blobs)\n",
    "    if test: # keep frames that have enough paricles, and are not transitions\"\"\"\n",
    "    clas =sideify(num_pconnections,num_gconnections, num_fpconnections, num_fgconnections )\n",
    "    #clas = side\n",
    "    #sides[side].append(frame_no)\n",
    "    classes[clas]+=1\n",
    "    #print(clas)\n",
    "\n",
    "    if clas == 'ucf':\n",
    "        broken_count += 1\n",
    "        class_num = 0\n",
    "        #print('ucf-broken')\n",
    "        #print(\"class_num: %s\" %class_num)\n",
    "        #print(\"broken_count: %s\" %broken_count)\n",
    "        pass\n",
    "    else:\n",
    "        if origin == 'ucf':\n",
    "            origin = last_class\n",
    "            #print(\"reset origin\", origin)\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        if clas == last_class:\n",
    "            class_num += 1\n",
    "            #print(\"class_num: %s\" %class_num)\n",
    "        else:\n",
    "            class_num = 0\n",
    "            #print(\"class_reset\")\n",
    "            #print(\"class_num: %s\" %class_num)\n",
    "            \n",
    "        if class_num >= class_thresh: \n",
    "            if broken_count >= transition_threshold or clas != origin:\n",
    "                transitions[origin + \"->\" + clas]+= 1#((last_whole, frame_no))\n",
    "                \n",
    "                between_time = frame_no - state_start                               \n",
    "                times[origin + \"->\" + clas][0].append(between_time)\n",
    "                \n",
    "                stable_time = last_whole - state_start\n",
    "                times[origin + \"->\" + clas][1].append(stable_time)\n",
    "                \n",
    "                unstable_time = frame_no - last_whole                      \n",
    "                times[origin + \"->\" + clas][2].append(unstable_time)\n",
    "                \n",
    "                \n",
    "                state_start = frame_no\n",
    "                \n",
    "                #print(origin + \"->\" + clas)\n",
    "                origin = clas\n",
    "                #print(\"origin: %s\" %origin)\n",
    "            broken_count = 0\n",
    "            #print(\"broken_count: %s\" %broken_count)\n",
    "            last_whole = frame_no\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "\n",
    "        \n",
    "        filtrate_len += 1 \n",
    "        last_class = clas\n",
    "            \n",
    "            \n",
    "    \"\"\"else:\n",
    "        print(\"broken\")\n",
    "        class_num = 0\n",
    "        print(\"class_num: %s\" %class_num)\n",
    "        broken_count += 1\n",
    "        print(\"broken_count: %s\" %broken_count)\"\"\"\n",
    "\n",
    "    return [broken_count, class_num, origin, last_class, last_whole,state_start, filtrate_len]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# take largest isodata image region, and return aclassification\n",
    "def sideify(num_pconnections, num_gconnections, num_fpconnections, num_fgconnections):\n",
    "    if num_fpconnections + num_fgconnections < 2:\n",
    "        return \"ucf\"\n",
    "    elif num_pconnections == 1 and num_gconnections ==0:# and num_mconnections==4: #gtotallengths>48\n",
    "        return \"p\"\n",
    "    elif num_pconnections == 0 and num_gconnections ==1:# and num_mconnections == 4:\n",
    "        return \"g\"\n",
    "    elif num_pconnections == 1 and num_gconnections ==1:# and num_mconnections ==3:\n",
    "        return \"b\"\n",
    "    else:\n",
    "        return \"ucf\"\n",
    "    \n",
    "def connect(cv, radii, bloblist): # center of blob2, radius of all blobs, list of other blobs\n",
    "    num_connections = 0\n",
    "    num_f_connections = 0\n",
    "    norm_radius = 15\n",
    "    total_separations = 0\n",
    "    normalized_dists = []\n",
    "    for blob2 in bloblist:\n",
    "        cv2 = (blob2[1], blob2[0]) # center of blob2\n",
    "        vector_d = vector_dist(cv, cv2)\n",
    "        total_separations += vector_d\n",
    "        r1,r2 = radii\n",
    "        if vector_d <= 2*r1 and vector_d > .2*r1: # blob centers closer than diameter of one blob\n",
    "            num_connections += 1\n",
    "        if vector_d <= 2*r2 and vector_d > .2*r1: # blob centers closer than diameter of one blob\n",
    "            num_f_connections += 1\n",
    "        else:\n",
    "            pass\n",
    "        if vector_d <= 4*r1: \n",
    "            normalized_dists.append(vector_d/(2*norm_radius))\n",
    "    return (num_connections, num_f_connections)\n",
    "\n",
    "def reducer(connections):\n",
    "    if len(connections)== 0:\n",
    "        return [0, 0]\n",
    "    else:\n",
    "        return(np.sum(connections, axis=0)    )\n",
    "\n",
    "\n",
    "def vector_dist(v1, v2): # euclidean distance between 2 points\n",
    "    return math.sqrt(np.sum([(v1[i] - v2[i])**2 for i in range(len(v1))]))\n",
    "\n",
    "def third_item(l1):\n",
    "    return l1[2]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\"\"\"Pipeline for lists of frames\"\"\"\n",
    "\"\"\"\"\"\"\n",
    "\"\"\"Pipeline for videos:\"\"\"\n",
    "# initialize frame lists\n",
    "filenames =glob(\"./tchakamau/W*half/*_21*a.avi\")  #[1,2,3,4,6,7,8,9][\"./tchakamau/New_setup/45681_10Vpp_25.avi\"\n",
    "filenames.sort()\n",
    "print(filenames)\n",
    "num_top_keys = 4\n",
    "num_full_keys = 4\n",
    "num_tran_keys = 3\n",
    "trans_threshes = np.linspace(25, 65, 4)#[30, 40, 50]#[5, 8, 10, 19, 27, 38, 52, 60]\n",
    "class_threshes =[20,30,40]\n",
    "trans_runs = {}\n",
    "#trans_fil = 10\n",
    "\n",
    "ave = np.average\n",
    "expected_blobs = 4\n",
    "expected_connections = 5\n",
    "p_bond = 15*1.35\n",
    "g_bond = 15*1.15\n",
    "fp_bond = 15*1.75\n",
    "fg_bond = 15*1.8\n",
    "    \n",
    "\"\"\"area_threshold = 1800   # must have enough particles\n",
    "convex_thresholds = (2000, 2800)   # convex hull area (> 2500 filtered)  # particles must be in parallelogram\n",
    "minor_thresholds = (38, 48) # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "major_thresholds = (59, 76)\"\"\"\n",
    "thresholds = [expected_blobs , expected_connections, p_bond, g_bond]\n",
    "params = [3, 115, 98, 2, 95, 80]\n",
    "print(\"Number files: \", len(filenames))\n",
    "index = 0\n",
    "for trans_fil in trans_threshes:\n",
    "    \n",
    "    for class_thresh in class_threshes:\n",
    "        \n",
    "        Top_bottoms = np.zeros((len(filenames), num_top_keys))\n",
    "        Full_classif = np.zeros((len(filenames), num_full_keys))\n",
    "        N_transitions = np.zeros((len(filenames), num_tran_keys, num_tran_keys))\n",
    "        num_total_frames = 0 \n",
    "        filtrate_len = 0\n",
    "        for vidnum in range(len(filenames)):\n",
    "            print(\"Processing vid %s : %s\" %(vidnum, filenames[vidnum]))\n",
    "            #meta = ffprobe(filenames[vidnum])\n",
    "            #print(meta)#['@nb_frames'])\n",
    "            #print(5)\n",
    "            frames = vreader(filenames[vidnum])\n",
    "            #frame_vid = frames[:, :, :, 2]# making videos ino a frame list\n",
    "            #print(frames)\n",
    "\n",
    "\n",
    "\n",
    "            sides = {\"p\":[], \"g\":[], \"b\":[], \"ucf\":[]}\n",
    "            classes = {\"p\":[], \"g\":[], \"b\":[], \"ucf\":[]}\n",
    "            transitions = [(\"p->p\",[]),(\"p->g\",[]), (\"p->b\",[]),\n",
    "                           (\"g->p\",[]),(\"g->g\",[]), (\"g->b\",[]),\n",
    "                          (\"b->p\",[]),(\"b->g\",[]), (\"b->b\",[])]\n",
    "\n",
    "            transitions = OrderedDict(transitions)\n",
    "            broken_count = 0\n",
    "            class_num = 0\n",
    "            origin = 'ucf'\n",
    "            last_class = 'ucf'\n",
    "            last_whole = 0\n",
    "            for fr in frames:\n",
    "                frame = fr[:, :, 2]\n",
    "                num_total_frames += 1\n",
    "                org = total_threshold_filter(frame, num_total_frames, trans_fil, class_thresh,\n",
    "                                             broken_count, class_num, origin, last_class, last_whole, filtrate_len, \n",
    "                                             sides, classes, transitions)\n",
    "                broken_count, class_num, origin, last_class, last_whole, filtrate_len = org\n",
    "            filtered_len = filtrate_len\n",
    "            #----------------------------------------------------------------\n",
    "            trans_len = len([y for x in transitions.values() for y in x])\n",
    "            skeys = list(sides.keys())\n",
    "            ckeys = list(classes.keys())\n",
    "            tkeys = list(transitions.keys())\n",
    "            slcs = [len(sides[x]) for x in skeys]\n",
    "            clcs = [len(classes[x]) for x in ckeys]\n",
    "            trans = [len(transitions[x]) for x in tkeys] #num of each transition\n",
    "            ucf = len(sides[\"ucf\"])\n",
    "\n",
    "\n",
    "            Top_bottoms[vidnum,:] = [slcs[i] for i in range(len(skeys))]\n",
    "            Full_classif[vidnum,:] = [clcs[i] for i in range(len(ckeys))]\n",
    "            N_transitions[vidnum,:] = np.reshape(trans, (num_tran_keys, num_tran_keys))\n",
    "            print(\"T threshold: %s\" %trans_fil)\n",
    "            print(\"C threshold: %s\" %class_thresh)\n",
    "            print(N_transitions[vidnum,:])\n",
    "            #print(\"finished vid %s\" %vidnum)\n",
    "        trans_runs[index] = [[Top_bottoms, Full_classif, N_transitions, (trans_fil, class_thresh), num_top_keys, num_full_keys,\n",
    "                                 num_tran_keys, skeys, ckeys, num_tran_keys, num_total_frames], thresholds, params]\n",
    "        index += 1\n",
    "        #---------------------------------------------------------------------------------\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "np.save('trans_runs_15.5.npy',trans_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./tchakamau\\\\Real_glass_half\\\\45672_15Vpp_0.avi', './tchakamau\\\\Real_glass_half\\\\45672_15Vpp_4.avi', './tchakamau\\\\Real_glass_half\\\\45672_15Vpp_5.avi', './tchakamau\\\\Real_glass_half\\\\45690_15Vpp_1_pushed.avi', './tchakamau\\\\Real_glass_half\\\\45690_15Vpp_2_pushed.avi', './tchakamau\\\\Real_glass_half\\\\45690_15Vpp_3.avi']\n",
      "Number files:  6\n",
      "Processing vid 0 : ./tchakamau\\Real_glass_half\\45672_15Vpp_0.avi\n",
      "T threshold: 60\n",
      "C threshold: 10\n",
      "[[22.  0.  2.]\n",
      " [ 0.  0.  0.]\n",
      " [ 3.  0.  8.]]\n",
      "[[[list([751, 372, 263, 970, 250, 834, 149, 515, 152, 910, 283, 459, 821, 258, 271, 426, 503, 380, 257, 1650, 2040, 240])\n",
      "   list([]) list([295, 2855])]\n",
      "  [list([]) list([]) list([])]\n",
      "  [list([352, 261, 67]) list([])\n",
      "   list([108, 1447, 150, 701, 1041, 1169, 409, 205])]]\n",
      "\n",
      " [[list([3, 237, 105, 803, 105, 523, 68, 119, 0, 812, 158, 354, 679, 142, 164, 174, 342, 214, 126, 1495, 1951, 111])\n",
      "   list([]) list([127, 2753])]\n",
      "  [list([]) list([]) list([])]\n",
      "  [list([201, 0, 9]) list([])\n",
      "   list([2, 1288, 3, 539, 768, 1040, 162, 12])]]\n",
      "\n",
      " [[list([748, 135, 158, 167, 145, 311, 81, 396, 152, 98, 125, 105, 142, 116, 107, 252, 161, 166, 131, 155, 89, 129])\n",
      "   list([]) list([168, 102])]\n",
      "  [list([]) list([]) list([])]\n",
      "  [list([151, 261, 58]) list([])\n",
      "   list([106, 159, 147, 162, 273, 129, 247, 193])]]]\n",
      "[1.111e+04 5.000e+00 3.625e+03 8.147e+03]\n",
      "Processing vid 1 : ./tchakamau\\Real_glass_half\\45672_15Vpp_4.avi\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Pipeline for lists of frames\"\"\"\n",
    "\"\"\"\"\"\"\n",
    "\"\"\"Pipeline for videos:\"\"\"\n",
    "# initialize frame lists\n",
    "filenames =glob(\"./tchakamau/Real*half/*.avi\")#glob(\"./tchakamau/W*half/*_21*a.avi\")  #[1,2,3,4,6,7,8,9][\"./tchakamau/New_setup/45681_10Vpp_25.avi\"\n",
    "filenames.sort()\n",
    "print(filenames)\n",
    "num_top_keys = 4\n",
    "num_full_keys = 4\n",
    "num_tran_keys = 3\n",
    "num_lengths = 3 # ways to measure the time betwen transitions, as it were\n",
    "trans_threshes = [60]#[30, 40, 50]#[5, 8, 10, 19, 27, 38, 52, 60]\n",
    "class_threshes =[10,30]\n",
    "trans_runs = {}\n",
    "#trans_fil = 10\n",
    "\n",
    "ave = np.average\n",
    "expected_blobs = 4\n",
    "expected_connections = 5\n",
    "p_bond = 15*1\n",
    "g_bond = 15*1\n",
    "fp_bond = 15*1.4\n",
    "fg_bond = 15*1.5\n",
    "    \n",
    "\"\"\"area_threshold = 1800   # must have enough particles\n",
    "convex_thresholds = (2000, 2800)   # convex hull area (> 2500 filtered)  # particles must be in parallelogram\n",
    "minor_thresholds = (38, 48) # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "major_thresholds = (59, 76)\"\"\"\n",
    "thresholds = [expected_blobs , expected_connections, p_bond, g_bond]\n",
    "params = [3, 115, 98, 2, 95, 80]\n",
    "print(\"Number files: \", len(filenames))\n",
    "index = 0\n",
    "for trans_fil in trans_threshes:\n",
    "    \n",
    "    for class_thresh in class_threshes:\n",
    "        \n",
    "        #Top_bottoms = np.zeros((len(filenames), num_top_keys))\n",
    "        Full_classif = np.zeros((len(filenames), num_full_keys))\n",
    "        N_transitions = np.zeros((len(filenames), num_tran_keys, num_tran_keys))\n",
    "        T_transitions = [[[[[] for i in range(num_tran_keys)] for j in range(num_tran_keys)] for k in range(num_lengths)] \n",
    "                          for l in range(len(filenames))]\n",
    "        num_total_frames = 0 \n",
    "        filtrate_len = 0\n",
    "        for vidnum in range(len(filenames)):\n",
    "            print(\"Processing vid %s : %s\" %(vidnum, filenames[vidnum]))\n",
    "            #meta = ffprobe(filenames[vidnum])\n",
    "            #print(meta)#['@nb_frames'])\n",
    "            #print(5)\n",
    "            frames = vreader(filenames[vidnum])\n",
    "            #frame_vid = frames[:, :, :, 2]# making videos ino a frame list\n",
    "            #print(frames)\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "            classes = [(\"p\",0), (\"g\",0), (\"b\",0), (\"ucf\",0)]\n",
    "            transitions = [(\"p->p\",0),(\"p->g\",0), (\"p->b\",0),\n",
    "                           (\"g->p\",0),(\"g->g\",0), (\"g->b\",0),\n",
    "                          (\"b->p\",0),(\"b->g\",0), (\"b->b\",0)]\n",
    "            times = [(\"p->p\",[[] for i in range(num_lengths)]),(\"p->g\",[[] for i in range(num_lengths)]), (\"p->b\",[[] for i in range(num_lengths)]),\n",
    "                           (\"g->p\",[[] for i in range(num_lengths)]),(\"g->g\",[[] for i in range(num_lengths)]), (\"g->b\",[[] for i in range(num_lengths)]),\n",
    "                          (\"b->p\",[[] for i in range(num_lengths)]),(\"b->g\",[[] for i in range(num_lengths)]), (\"b->b\",[[] for i in range(num_lengths)])]\n",
    "\n",
    "            transitions = OrderedDict(transitions)\n",
    "            times = OrderedDict(times)            \n",
    "            classes = OrderedDict(classes)\n",
    "            broken_count = 0\n",
    "            class_num = 0\n",
    "            origin = 'ucf'\n",
    "            last_class = 'ucf'\n",
    "            last_whole = 0\n",
    "            state_start = 0\n",
    "            frame_no = 0\n",
    "            for fr in frames:\n",
    "                frame = fr[:, :, 2]\n",
    "                frame_no += 1\n",
    "                num_total_frames += 1\n",
    "                org = total_threshold_filter(frame, frame_no, trans_fil, class_thresh,\n",
    "                                             broken_count, class_num, origin, last_class, last_whole, state_start, filtrate_len, \n",
    "                                              classes, transitions, times)\n",
    "                broken_count, class_num, origin, last_class, last_whole, state_start, filtrate_len = org\n",
    "            filtered_len = filtrate_len\n",
    "            #----------------------------------------------------------------\n",
    "            #trans_len = len([y for x in transitions.values() for y in x])\n",
    "            \n",
    "            ckeys = list(classes.keys())\n",
    "            clcs = [classes[x] for x in ckeys] # list of frame nums per class\n",
    "            \n",
    "            tkeys = list(times.keys())\n",
    "            tims = [times[x] for x in tkeys]\n",
    "            \n",
    "            trkeys = list(transitions.keys())\n",
    "            trans = [transitions[x] for x in trkeys] #num of each transition\n",
    "            #ucf = len(sides[\"ucf\"])\n",
    "\n",
    "            #Top_bottoms[vidnum,:] = [slcs[i] for i in range(len(skeys))]\n",
    "            Full_classif[vidnum,:] = clcs\n",
    "            N_transitions[vidnum,:] = np.reshape(trans, (num_tran_keys, num_tran_keys))            \n",
    "            T_transitions[vidnum] = np.moveaxis(np.reshape(tims, (num_tran_keys, num_tran_keys,num_lengths)),\n",
    "                                                  [0,1,2], [1,2,0])\n",
    "            print(\"T threshold: %s\" %trans_fil)\n",
    "            print(\"C threshold: %s\" %class_thresh)\n",
    "            print(N_transitions[vidnum,:])\n",
    "            print(T_transitions[vidnum])\n",
    "            print(Full_classif[vidnum,:])\n",
    "            #print(\"finished vid %s\" %vidnum)\n",
    "        trans_runs[index] = [[Full_classif, (N_transitions, T_transitions), (trans_fil, class_thresh), num_top_keys, num_full_keys,\n",
    "                                 num_tran_keys, ckeys, num_tran_keys, num_total_frames], thresholds, params]\n",
    "        index += 1\n",
    "        #---------------------------------------------------------------\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "np.save('realboth.npy',trans_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.moveaxis(np.reshape(tims, (num_tran_keys, num_tran_keys,num_lengths)),\n",
    "                                                  [0,1,2], [1,2,0]))\n",
    "\n",
    "print(vidnum)\n",
    "\n",
    "T_transitions = [[[[[] for i in range(num_tran_keys)] for j in range(num_tran_keys)] for k in range(num_lengths)] \n",
    "                          for l in range(len(filenames))]\n",
    "#print(T_transitions)\n",
    "T_transitions[vidnum] = np.moveaxis(np.reshape(tims, (num_tran_keys, num_tran_keys,num_lengths)),\n",
    "                                                  [0,1,2], [1,2,0])\n",
    "print(T_transitions, len(T_transitions), vidnum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
