{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is video reader with all operations inside fnctions, so they can be called on \\n    each frame out of a set of frames, and each video out of a set of videos\\n    '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This is video reader with all operations inside fnctions, so they can be called on \n",
    "    each frame out of a set of frames, and each video out of a set of videos\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports\"\"\"\n",
    "import matplotlib.pyplot as plt #for maknig plots inside the notebook\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from skvideo.io import vreader, ffprobe\n",
    "from skimage import measure, morphology, feature\n",
    "from skimage.filters import *\n",
    "from skimage.morphology import *\n",
    "from operator import attrgetter\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import chain\n",
    "#from functools import partial, update_wrapper\n",
    "from scipy import ndimage \n",
    "from pims import pipeline, Video\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict \n",
    "#import antigravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions\"\"\"\n",
    "# apply total thresholding to each of a list of frames; filter slides with wrong number\n",
    "\n",
    "def total_threshold_filter(frame, frame_no, transition_threshold, class_thresh,\n",
    "                           broken_count, class_num, origin, last_class, last_whole, filtrate_len, \n",
    "                           sides, classes, transitions): \n",
    "    \n",
    "   \n",
    "    \n",
    "   # ---setup image and detect blobs ----------------\n",
    "    thresh_img = frame > threshold_isodata(frame)# binary image\n",
    "        \n",
    "    phighlight = morphology.binary_opening(thresh_img, disk(8))\n",
    "    img = np.copy(frame)\n",
    "    img[phighlight==0] = 0\n",
    "    pblobs =skimage.feature.blob_doh(img, min_sigma =8, max_sigma = 17, threshold = 0.007, num_sigma= 15, overlap=0.6)\n",
    "        \n",
    "    ghighlight = gaussian(\n",
    "        morphology.binary_opening(\n",
    "             (thresh_img^phighlight)\n",
    "                           , square(4)), sigma = 0.65)\n",
    "    img = np.copy(frame)\n",
    "    img[ghighlight==0] = 0\n",
    "    gblobs =skimage.feature.blob_doh(img, min_sigma =9, max_sigma = 16, threshold = 0.005, num_sigma= 15, overlap=0.2)\n",
    "    \n",
    "\n",
    "    ngblobs = len(gblobs)\n",
    "    npblobs = len(pblobs) \n",
    "    num_blobs = ngblobs + npblobs\n",
    "            \n",
    "    plas_on_glas_dists =[connect((pblob[1], pblob[0]),m_bond, gblobs) for pblob in pblobs]\n",
    "    num_mconnections = reducer(plas_on_glas_dists)\n",
    "\n",
    "\n",
    "    glas_on_glas_dists =[connect((gblobs[i][1], gblobs[i][0]),g_bond, gblobs[i+1:]) for i in range(ngblobs-1)]\n",
    "    num_gconnections = reducer(glas_on_glas_dists)\n",
    "\n",
    "\n",
    "    plas_on_plas_dists = [connect((pblobs[i][1], pblobs[i][0]),p_bond, pblobs[i+1:]) for i in range(npblobs-1)]\n",
    "    num_pconnections = reducer(plas_on_plas_dists)\n",
    "\n",
    "\n",
    "    num_connections = sum([num_pconnections, num_gconnections,num_mconnections])\n",
    "    \n",
    "    #----------------------filter------------------------- can use actual filter\n",
    "    test = (num_connections >= expected_connections and num_blobs>=expected_blobs)\n",
    "    if test: # keep frames that have enough paricles, and are not transitions\n",
    "        side =sideify(num_pconnections,num_gconnections, num_mconnections )\n",
    "        clas = side\n",
    "        sides[side].append(frame_no)\n",
    "        classes[clas].append(frame_no)\n",
    "            #print(clas)\n",
    "        \n",
    "        if clas == 'ucf':\n",
    "            #broken_count += 1\n",
    "            #class_num = 0\n",
    "            #print('ucf')\n",
    "            pass\n",
    "        else:\n",
    "            if origin == 'ucf':\n",
    "                origin = last_class\n",
    "                #print(\"reset origin\", origin)\n",
    "            if clas == last_class:\n",
    "                class_num += 1\n",
    "                #print(\"class_num: %s\" %class_num)\n",
    "            else:\n",
    "                class_num = 0\n",
    "                #print(\"class_reset\")\n",
    "                #print(\"class_num: %s\" %class_num)\n",
    "            if class_num >= class_thresh: \n",
    "                if broken_count >= transition_threshold or clas != origin:\n",
    "                    transitions[origin + \"->\" + clas].append((last_whole, frame_no))\n",
    "                    #print(origin + \"->\" + clas)\n",
    "                    origin = clas\n",
    "                    #print(\"origin: %s\" %origin)\n",
    "                broken_count = 0\n",
    "                #print(\"broken_count: %s\" %broken_count)\n",
    "                \n",
    "            \n",
    "                \n",
    "            last_whole = frame_no\n",
    "            filtrate_len += 1 \n",
    "            last_class = clas\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        #print(\"broken\")\n",
    "        class_num = 0\n",
    "        #print(\"class_num: %s\" %class_num)\n",
    "        broken_count += 1\n",
    "        #print(\"broken_count: %s\" %broken_count)\n",
    "\n",
    "    return [broken_count, class_num, origin, last_class, last_whole, filtrate_len]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# take largest isodata image region, and return aclassification\n",
    "def sideify(num_pconnections, num_gconnections, num_mconnections):    \n",
    "    if num_gconnections == 0  and num_pconnections==1: #gtotallengths>48\n",
    "        return \"p\"\n",
    "    elif num_pconnections ==0 and num_gconnections>=1 :\n",
    "        return \"g\"\n",
    "    elif num_pconnections ==1 and num_gconnections>=1:\n",
    "        return \"b\"\n",
    "    else:\n",
    "        return 'ucf'\n",
    "\n",
    "def reducer(connections):\n",
    "    return sum(connections)    \n",
    "def connect(cv, radius, bloblist): # center of blob2, radius of all blobs, list of other blobs\n",
    "    num_connections = 0\n",
    "    norm_radius = 15\n",
    "    for blob2 in bloblist:\n",
    "        cv2 = (blob2[1], blob2[0]) # center of blob2\n",
    "        vector_d = vector_dist(cv, cv2)\n",
    "        if vector_d <= 2*radius and vector_d > .33*radius: # blob centers closer than diameter of one blob\n",
    "            num_connections += 1\n",
    "        else:\n",
    "            pass\n",
    "    return (num_connections)\n",
    "\n",
    "def vector_dist(v1, v2): # euclidean distance between 2 points\n",
    "    return math.sqrt(np.sum([(v1[i] - v2[i])**2 for i in range(len(v1))]))\n",
    "\n",
    "def third_item(l1):\n",
    "    return l1[2]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./tchakamau\\\\0.5 2nd\\\\45660_10Vpp_1.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_10.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_11.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_12.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_13.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_14_bounced.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_15.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_2.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_3.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_4_bounced.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_6.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_7.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_8.avi', './tchakamau\\\\0.5 2nd\\\\45660_10Vpp_9.avi']\n",
      "Number files:  14\n",
      "Processing vid 0 : ./tchakamau\\0.5 2nd\\45660_10Vpp_1.avi\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Pipeline for lists of frames\"\"\"\n",
    "\"\"\"\"\"\"\n",
    "\"\"\"Pipeline for videos:\"\"\"\n",
    "# initialize frame lists\n",
    "filenames = glob(\"./tchakamau/0.5*/*[1][0]v*[1,2,3,4,6,7,8,9]*.avi\")#[1,2,3,4,6,7,8,9][\"./tchakamau/New_setup/45681_10Vpp_25.avi\"\n",
    "print(filenames)\n",
    "num_top_keys = 4\n",
    "num_full_keys = 4\n",
    "num_tran_keys = 3\n",
    "trans_threshes = np.linspace(38, 62, 4)#[30, 40, 50]#[5, 8, 10, 19, 27, 38, 52, 60]\n",
    "class_threshes =[22,35]\n",
    "trans_runs = {}\n",
    "#trans_fil = 10\n",
    "\n",
    "ave = np.average\n",
    "expected_blobs = 4\n",
    "expected_connections = 5\n",
    "p_bond = 15*1.2\n",
    "g_bond = 15*1.1\n",
    "m_bond = 15*1.6\n",
    "\n",
    "\"\"\"area_threshold = 1800   # must have enough particles\n",
    "convex_thresholds = (2000, 2800)   # convex hull area (> 2500 filtered)  # particles must be in parallelogram\n",
    "minor_thresholds = (38, 48) # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "major_thresholds = (59, 76)\"\"\"\n",
    "thresholds = [expected_blobs , expected_connections, p_bond, g_bond, m_bond]\n",
    "params = [3, 115, 98, 2, 95, 80]\n",
    "print(\"Number files: \", len(filenames))\n",
    "index = 0\n",
    "for trans_fil in trans_threshes:\n",
    "    \n",
    "    for class_thresh in class_threshes:\n",
    "        \n",
    "        Top_bottoms = np.zeros((len(filenames), num_top_keys))\n",
    "        Full_classif = np.zeros((len(filenames), num_full_keys))\n",
    "        N_transitions = np.zeros((len(filenames), num_tran_keys, num_tran_keys))\n",
    "        num_total_frames = 0 \n",
    "        filtrate_len = 0\n",
    "        for vidnum in range(len(filenames)):\n",
    "            print(\"Processing vid %s : %s\" %(vidnum, filenames[vidnum]))\n",
    "            #meta = ffprobe(filenames[vidnum])\n",
    "            #print(meta)#['@nb_frames'])\n",
    "            #print(5)\n",
    "            frames = vreader(filenames[vidnum])\n",
    "            #frame_vid = frames[:, :, :, 2]# making videos ino a frame list\n",
    "            #print(frames)\n",
    "\n",
    "\n",
    "\n",
    "            sides = {\"p\":[], \"g\":[], \"b\":[], \"ucf\":[]}\n",
    "            classes = {\"p\":[], \"g\":[], \"b\":[], \"ucf\":[]}\n",
    "            transitions = [(\"p->p\",[]),(\"p->g\",[]), (\"p->b\",[]),\n",
    "                           (\"g->p\",[]),(\"g->g\",[]), (\"g->b\",[]),\n",
    "                          (\"b->p\",[]),(\"b->g\",[]), (\"b->b\",[])]\n",
    "\n",
    "            transitions = OrderedDict(transitions)\n",
    "            broken_count = 0\n",
    "            class_num = 0\n",
    "            origin = 'ucf'\n",
    "            last_class = 'ucf'\n",
    "            last_whole = 0\n",
    "            for fr in frames:\n",
    "                frame = fr[:, :, 2]\n",
    "                num_total_frames += 1\n",
    "                org = total_threshold_filter(frame, num_total_frames, trans_fil, class_thresh,\n",
    "                                             broken_count, class_num, origin, last_class, last_whole, filtrate_len, \n",
    "                                             sides, classes, transitions)\n",
    "                broken_count, class_num, origin, last_class, last_whole, filtrate_len = org\n",
    "            filtered_len = filtrate_len\n",
    "            #----------------------------------------------------------------\n",
    "            trans_len = len([y for x in transitions.values() for y in x])\n",
    "            skeys = list(sides.keys())\n",
    "            ckeys = list(classes.keys())\n",
    "            tkeys = list(transitions.keys())\n",
    "            slcs = [len(sides[x]) for x in skeys]\n",
    "            clcs = [len(classes[x]) for x in ckeys]\n",
    "            trans = [len(transitions[x]) for x in tkeys] #num of each transition\n",
    "            ucf = len(sides[\"ucf\"])\n",
    "\n",
    "\n",
    "            Top_bottoms[vidnum,:] = [slcs[i] for i in range(len(skeys))]\n",
    "            Full_classif[vidnum,:] = [clcs[i] for i in range(len(ckeys))]\n",
    "            N_transitions[vidnum,:] = np.reshape(trans, (num_tran_keys, num_tran_keys))\n",
    "            print(\"T threshold: %s\" %trans_fil)\n",
    "            print(\"C threshold: %s\" %class_thresh)\n",
    "            print(N_transitions[vidnum,:])\n",
    "            #print(\"finished vid %s\" %vidnum)\n",
    "        trans_runs[index] = [[Top_bottoms, Full_classif, N_transitions, (trans_fil, class_thresh), num_top_keys, num_full_keys,\n",
    "                                 num_tran_keys, skeys, ckeys, num_tran_keys, num_total_frames], thresholds, params]\n",
    "        index += 1\n",
    "        #---------------------------------------------------------------------------------\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "np.save('trans_runs_0.5.npy',trans_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Pipeline for lists of frames\"\"\"\n",
    "\"\"\"\"\"\"\n",
    "\"\"\"Pipeline for videos:\"\"\"\n",
    "# initialize frame lists\n",
    "filenames = glob(\"./tchakamau/2ND*/*7.avi\")#[\"./tchakamau/New_setup/45681_10Vpp_25.avi\"\n",
    "print(filenames)\n",
    "num_top_keys = 3\n",
    "num_full_keys = 3\n",
    "num_tran_keys = 2\n",
    "trans_threshes = [25, 30, 50]#[5, 8, 10, 19, 27, 38, 52, 60]\n",
    "trans_runs = {}\n",
    "#trans_fil = 10\n",
    "\n",
    "ave = np.average\n",
    "\n",
    "area_threshold = 1850   # must have enough particles\n",
    "sol_threshold = 0.95\n",
    "iner_threshold = (320, 410)\n",
    "convex_thresholds = (2000, 2800)   # convex hull area (> 2500 filtered)  # particles must be in parallelogram\n",
    "minor_thresholds = (38, 48) # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "#major_thresholds = (59, 76)\n",
    "major_threshold = 78\n",
    "\"\"\"area_threshold = 1800   # must have enough particles\n",
    "convex_thresholds = (2000, 2800)   # convex hull area (> 2500 filtered)  # particles must be in parallelogram\n",
    "minor_thresholds = (38, 48) # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "major_thresholds = (59, 76)\"\"\"\n",
    "\n",
    "print(\"Number files: \", len(filenames))\n",
    "\n",
    "for trans_fil in trans_threshes:\n",
    "    print(\"T threshold: %s\" %trans_fil)\n",
    "    Top_bottoms = np.zeros((len(filenames), num_top_keys))\n",
    "    Full_classif = np.zeros((len(filenames), num_full_keys))\n",
    "    N_transitions = np.zeros((len(filenames), num_tran_keys, num_tran_keys))\n",
    "    num_total_frames = 0 \n",
    "    filtrate_len = 0\n",
    "    for vidnum in range(len(filenames)):\n",
    "        print(\"Processing vid %s : %s\" %(vidnum, filenames[vidnum]))\n",
    "        #meta = ffprobe(filenames[vidnum])\n",
    "        #print(meta)#['@nb_frames'])\n",
    "        #print(5)\n",
    "        frames = vreader(filenames[vidnum])\n",
    "        #frame_vid = frames[:, :, :, 2]# making videos ino a frame list\n",
    "        #print(frames)\n",
    "\n",
    "\n",
    "\n",
    "        sides = {\"t\":[], \"c\":[], \"ucf\":[]}\n",
    "        classes = {\"t\":[], \"c\":[], \"ucf\":[]}\n",
    "        transitions = [(\"t->t\",[]), (\"t->c\",[]),\n",
    "                      (\"c->t\" ,[]), (\"c->c\",[])]\n",
    "        \n",
    "        transitions = OrderedDict(transitions)\n",
    "        broken_count = 0\n",
    "        class_num = 0\n",
    "        origin = 'ucf'\n",
    "        last_class = 'ucf'\n",
    "        last_whole = 0\n",
    "        for fr in frames:\n",
    "            frame = fr[:, :, 2]\n",
    "            num_total_frames += 1\n",
    "            org = total_threshold_filter(frame, num_total_frames, trans_fil,\n",
    "                                         broken_count, class_num, origin, last_class, last_whole, filtrate_len, \n",
    "                                         sides, classes, transitions)\n",
    "            broken_count, class_num, origin, last_class, last_whole, filtrate_len = org\n",
    "        filtered_len = filtrate_len\n",
    "        #----------------------------------------------------------------\n",
    "        trans_len = len([y for x in transitions.values() for y in x])\n",
    "        skeys = list(sides.keys())\n",
    "        ckeys = list(classes.keys())\n",
    "        tkeys = list(transitions.keys())\n",
    "        slcs = [len(sides[x]) for x in skeys]\n",
    "        clcs = [len(classes[x]) for x in ckeys]\n",
    "        trans = [len(transitions[x]) for x in tkeys] #num of each transition\n",
    "        ucf = len(sides[\"ucf\"])\n",
    "\n",
    "\n",
    "        Top_bottoms[vidnum,:] = [slcs[i] for i in range(len(skeys))]\n",
    "        Full_classif[vidnum,:] = [clcs[i] for i in range(len(ckeys))]\n",
    "        N_transitions[vidnum,:] = np.reshape(trans, (num_tran_keys, num_tran_keys))\n",
    "        print(N_transitions[vidnum,:])\n",
    "        #print(\"finished vid %s\" %vidnum)\n",
    "    trans_runs[trans_fil] = [Top_bottoms, Full_classif, N_transitions, trans_threshes, num_top_keys, num_full_keys,\n",
    "                             num_tran_keys, skeys, ckeys, num_tran_keys, num_total_frames]\n",
    "    #---------------------------------------------------------------------------------\n",
    "    \n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "np.save('trans_runs_new1.npy',trans_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trans_runs= np.load('trans_runs2.npy')[()]\n",
    "\"\"\"num_top_keys = 4\n",
    "num_full_keys = 6\n",
    "num_tran_keys = 5\n",
    "trans_threshes = [5, 8, 10, 19, 27, 38, 52, 60]\n",
    "sides = {\"bm\":[], \"b\":[], \"t\":[], \"ucf\":[]}\n",
    "classes = {\"bm\":[], \"br\":[], \"bl\":[], \"tr\":[], \"tl\":[], \"ucf\":[]}\n",
    "transitions = {\"bm->bm\" :[], \"bm->br\":[], \"bm->bl\":[], \"bm->tr\":[], \"bm->tl\":[],\n",
    "              \"br->bm\" :[], \"br->br\":[], \"br->bl\":[], \"br->tr\":[], \"br->tl\":[],\n",
    "              \"bl->bm\" :[], \"bl->br\":[], \"bl->bl\":[], \"bl->tr\":[], \"bl->tl\":[],\n",
    "              \"tr->bm\" :[], \"tr->br\":[], \"tr->bl\":[], \"tr->tr\":[], \"tr->tl\":[],\n",
    "              \"tl->bm\" :[], \"tl->br\":[], \"tl->bl\":[], \"tl->tr\":[], \"tl->tl\":[]}\"\"\"\n",
    "\n",
    "skeys = list(sides.keys())\n",
    "ckeys = list(classes.keys())\n",
    "for trans_fil in trans_threshes:\n",
    "    print(\"\\nTRANSITION THRESHOLD \", trans_fil)\n",
    "    \n",
    "    #Top_bottoms, Full_classif, N_transitions = trans_runs[trans_fil]\n",
    "    Top_bottoms, Full_classif, N_transitions, trans_threshes, num_top_keys, num_full_keys, num_tran_keys, skeys, ckeys, num_tran_keys, num_total_frames = trans_runs[trans_fil]\n",
    "    sums = np.sum\n",
    "    Tb_sums = [sums(Top_bottoms[:, c]) for c in range(num_top_keys)]\n",
    "    Fc_sums = [sums(Full_classif[:, c]) for c in range(num_full_keys)]\n",
    "    Nt_sums = sums(N_transitions, axis = 0)#[sums(N_transitions[:, c]) for c in range(num_tran_keys)]\n",
    "    #print(\"\\nNumber of frames obbserved: \", num_total_frames)\n",
    "\n",
    "    Tb_percs = [Tb_sums[c] *100 /sums(Tb_sums) for c in range(num_top_keys)]\n",
    "    Fc_percs = [Fc_sums[c] *100/sums(Fc_sums) for c in range(num_full_keys)]\n",
    "    Nt_percs = Nt_sums *100/sums(Nt_sums)\n",
    "    #print(sums(N_transitions), sums(Nt_sums))\n",
    "\n",
    "\n",
    "    print(\"\\nsums in broad classifications\")\n",
    "    [print(skeys[i], \"sum %.f\" %Tb_sums[i]) for i in range(len(skeys))]\n",
    "    print(\"Total: \", sums(Tb_sums) )\n",
    "    print(\"\\nsums in narrow classifications\")\n",
    "    [print(ckeys[i], \"sum %.f\" %Fc_sums[i]) for i in range(len(ckeys))]\n",
    "    print(\"Total: \", sums(Fc_sums ) )\n",
    "    print(\"\\nsums of transitions broad\")\n",
    "    T_eb = np.vstack([Nt_sums[0], \n",
    "                                 (Nt_sums[1] + Nt_sums[2]) , \n",
    "                                 (Nt_sums[3] + Nt_sums[4])])\n",
    "    Nt_sums_broad = np.column_stack([T_eb[:, 0], \n",
    "                                 (T_eb[:, 1]+ T_eb[:, 2]), \n",
    "                                 (T_eb[:, 3]+ T_eb[:, 4])])\n",
    "    print(Nt_sums_broad)\n",
    "    print(\"\\nsums of transitions narrow\")\n",
    "    print(Nt_sums)\n",
    "    print(\"Total: \", sums(Nt_sums) )\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"print(\"\\n%s in broad classifications\")\n",
    "    [print(skeys[i], \" %.f%%\" %Tb_percs[i]) for i in range(len(skeys))]\n",
    "    print(\"\\n%s in narrow classifications\")\n",
    "    [print(ckeys[i], \" %.f%%\" %Fc_percs[i]) for i in range(len(ckeys))]\"\"\"\n",
    "    #ERROR ANALSIS HERE\n",
    "    print(\"\\nErrors in transition matrix ((row_sums - column_sums) / 2)\")\n",
    "    print(((sums(Nt_sums, axis = 1) - sums(Nt_sums, axis =0))/2))\n",
    "    print(\"\\nError %%s in transition matrix ((row_sums - column_sums) *100 / (row_sums + column_sums))\")\n",
    "    print(((sums(Nt_sums, axis = 1) - sums(Nt_sums, axis =0))*100 /(sums(Nt_sums, axis = 1) + sums(Nt_sums, axis =0))))\n",
    "    \n",
    "    print(\"\\nTransition matrix, broad\")\n",
    "    T_eb = np.vstack([Nt_percs[0], \n",
    "                                 (Nt_percs[1] + Nt_percs[2]) , \n",
    "                                 (Nt_percs[3] + Nt_percs[4])])\n",
    "    Nt_percs_broad = np.column_stack([T_eb[:, 0], \n",
    "                                 (T_eb[:, 1]+ T_eb[:, 2]), \n",
    "                                 (T_eb[:, 3]+ T_eb[:, 4])])\n",
    "    print(Nt_percs_broad)\n",
    "    \"\"\"print(\"row_sums of transitin matrix, broad\")\n",
    "    print(sums(Nt_percs_broad, axis = 1))\n",
    "    print(\"\\n%s of transitions broad(->bm, ->b, ->t):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 0)[0]*100/sums(Nt_sums), \n",
    "           (sums(Nt_sums, axis = 0)[1] + sums(Nt_sums, axis = 0)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 0)[3] + sums(Nt_sums, axis = 0)[4])*100/(sums(Nt_sums))])\n",
    "    print(\"\\n%s of transitions broad(bm->, b->, t->):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 1)[0]*100/sums(Nt_sums),\n",
    "           (sums(Nt_sums, axis = 1)[1] + sums(Nt_sums, axis = 1)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 1)[3] + sums(Nt_sums, axis =1)[4])*100/(sums(Nt_sums))])#(Nt_percs[i,1] + Nt_percs[i,1+1] + Nt_percs[i+1, 1] + Nt_percs[i+1, 1+1] + sums(Nt_percs[0, 1:3]))) for i in [1,3]]\n",
    "    \"\"\"\n",
    "    #print(\"->t %.f%%\" %(Nt_percs[i,2] + Nt_percs[i,2+1] + Nt_percs[i+1, 2] + Nt_percs[i+1, 2+1] + sums(Nt_percs[0, 3:5]))) for i in [1,3]]\n",
    "    print(\"\\nTransition matrix, narrow\")\n",
    "    print(Nt_percs)\n",
    "    print(sums(Nt_percs))\n",
    "    print(\"\\n%s of transitions to states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 0)*100/sums(Nt_percs))]\n",
    "    print(\"\\n%s of transitions from states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 1)*100/sums(Nt_percs))]\n",
    "    print(\"\\n%s of transitions to states broad:\")\n",
    "    [print(sums(Nt_percs_broad, axis = 0)*100/sums(Nt_percs_broad))]\n",
    "    print(\"\\n%s of transitions from states broad:\")\n",
    "    [print(sums(Nt_percs_broad, axis = 1)*100/sums(Nt_percs_broad))]\n",
    "    #print(\"\\n%s of transitions narrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trans_runs= np.load('trans_runs1.npy')[()]\n",
    "\"\"\"num_top_keys = 4\n",
    "num_full_keys = 6\n",
    "num_tran_keys = 5\n",
    "trans_threshes = [5, 8, 10, 19, 27, 38, 52, 60]\n",
    "sides = {\"bm\":[], \"b\":[], \"t\":[], \"ucf\":[]}\n",
    "classes = {\"bm\":[], \"br\":[], \"bl\":[], \"tr\":[], \"tl\":[], \"ucf\":[]}\n",
    "transitions = {\"bm->bm\" :[], \"bm->br\":[], \"bm->bl\":[], \"bm->tr\":[], \"bm->tl\":[],\n",
    "              \"br->bm\" :[], \"br->br\":[], \"br->bl\":[], \"br->tr\":[], \"br->tl\":[],\n",
    "              \"bl->bm\" :[], \"bl->br\":[], \"bl->bl\":[], \"bl->tr\":[], \"bl->tl\":[],\n",
    "              \"tr->bm\" :[], \"tr->br\":[], \"tr->bl\":[], \"tr->tr\":[], \"tr->tl\":[],\n",
    "              \"tl->bm\" :[], \"tl->br\":[], \"tl->bl\":[], \"tl->tr\":[], \"tl->tl\":[]}\"\"\"\n",
    "\n",
    "skeys = list(sides.keys())\n",
    "ckeys = list(classes.keys())\n",
    "for trans_fil in trans_threshes:\n",
    "    print(\"\\nTRANSITION THRESHOLD \", trans_fil)\n",
    "    \n",
    "    #Top_bottoms, Full_classif, N_transitions = trans_runs[trans_fil]\n",
    "    Top_bottoms, Full_classif, N_transitions, trans_threshes, num_top_keys, num_full_keys, num_tran_keys, skeys, ckeys, num_tran_keys, num_total_frames = trans_runs[trans_fil]\n",
    "    sums = np.sum\n",
    "    Tb_sums = [sums(Top_bottoms[:, c]) for c in range(num_top_keys)]\n",
    "    Fc_sums = [sums(Full_classif[:, c]) for c in range(num_full_keys)]\n",
    "    Nt_sums = sums(N_transitions, axis = 0)#[sums(N_transitions[:, c]) for c in range(num_tran_keys)]\n",
    "    #print(\"\\nNumber of frames obbserved: \", num_total_frames)\n",
    "\n",
    "    Tb_percs = [Tb_sums[c] *100 /sums(Tb_sums) for c in range(num_top_keys)]\n",
    "    Fc_percs = [Fc_sums[c] *100/sums(Fc_sums) for c in range(num_full_keys)]\n",
    "    Nt_percs = Nt_sums *100/sums(Nt_sums)\n",
    "    #print(sums(N_transitions), sums(Nt_sums))\n",
    "\n",
    "\n",
    "    print(\"\\nsums in broad classifications\")\n",
    "    [print(skeys[i], \"sum %.f\" %Tb_sums[i]) for i in range(len(skeys))]\n",
    "    print(\"Total: \", sums(Tb_sums) )\n",
    "    print(\"\\nsums in narrow classifications\")\n",
    "    [print(ckeys[i], \"sum %.f\" %Fc_sums[i]) for i in range(len(ckeys))]\n",
    "    print(\"Total: \", sums(Fc_sums ) )\n",
    "    print(\"\\nsums of transitions broad\")\n",
    "    T_eb = np.vstack([Nt_sums[0], \n",
    "                                 (Nt_sums[1] + Nt_sums[2]) , \n",
    "                                 (Nt_sums[3] + Nt_sums[4])])\n",
    "    Nt_sums_broad = np.column_stack([T_eb[:, 0], \n",
    "                                 (T_eb[:, 1]+ T_eb[:, 2]), \n",
    "                                 (T_eb[:, 3]+ T_eb[:, 4])])\n",
    "    print(Nt_sums_broad)\n",
    "    print(\"\\nsums of transitions narrow\")\n",
    "    print(Nt_sums)\n",
    "    print(\"Total: \", sums(Nt_sums) )\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"print(\"\\n%s in broad classifications\")\n",
    "    [print(skeys[i], \" %.f%%\" %Tb_percs[i]) for i in range(len(skeys))]\n",
    "    print(\"\\n%s in narrow classifications\")\n",
    "    [print(ckeys[i], \" %.f%%\" %Fc_percs[i]) for i in range(len(ckeys))]\"\"\"\n",
    "    #ERROR ANALSIS HERE\n",
    "    print(\"Errors in transition matrix (row_sums - column_sums / 2)\")\n",
    "    print((sums(Nt_percs_broad, axis = 1) - sums(Nt_percs_broad, axis = 1) / 2))\n",
    "    \n",
    "    print(\"Transition matrix, broad\")\n",
    "    T_eb = np.vstack([Nt_percs[0], \n",
    "                                 (Nt_percs[1] + Nt_percs[2]) , \n",
    "                                 (Nt_percs[3] + Nt_percs[4])])\n",
    "    Nt_percs_broad = np.column_stack([T_eb[:, 0], \n",
    "                                 (T_eb[:, 1]+ T_eb[:, 2]), \n",
    "                                 (T_eb[:, 3]+ T_eb[:, 4])])\n",
    "    print(Nt_percs_broad)\n",
    "    print(\"row_sums of transitin matrix, broad\")\n",
    "    print(sums(Nt_percs_broad, axis = 1))\n",
    "    print(\"\\n%s of transitions broad(->bm, ->b, ->t):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 0)[0]*100/sums(Nt_sums), \n",
    "           (sums(Nt_sums, axis = 0)[1] + sums(Nt_sums, axis = 0)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 0)[3] + sums(Nt_sums, axis = 0)[4])*100/(sums(Nt_sums))])\n",
    "    print(\"\\n%s of transitions broad(bm->, b->, t->):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 1)[0]*100/sums(Nt_sums),\n",
    "           (sums(Nt_sums, axis = 1)[1] + sums(Nt_sums, axis = 1)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 1)[3] + sums(Nt_sums, axis =1)[4])*100/(sums(Nt_sums))])#(Nt_percs[i,1] + Nt_percs[i,1+1] + Nt_percs[i+1, 1] + Nt_percs[i+1, 1+1] + sums(Nt_percs[0, 1:3]))) for i in [1,3]]\n",
    "    #print(\"->t %.f%%\" %(Nt_percs[i,2] + Nt_percs[i,2+1] + Nt_percs[i+1, 2] + Nt_percs[i+1, 2+1] + sums(Nt_percs[0, 3:5]))) for i in [1,3]]\n",
    "    print(\"\\nTransition matrix, narrow\")\n",
    "    print(Nt_percs)\n",
    "    print(sums(Nt_percs))\n",
    "    print(\"\\n%s of transitions to states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 0)*100/sums(Nt_percs))]\n",
    "    print(\"\\n%s of transitions from states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 1)*100/sums(Nt_percs))]\n",
    "    #print(\"\\n%s of transitions narrow\")\n",
    "    #[print(tkeys[i], \" %.f%%\" %Nt_percs.flatten()[i]) for i in range(len(tkeys))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trans_runs= np.load('trans_runs.npy')[()]\n",
    "num_top_keys = 4\n",
    "num_full_keys = 6\n",
    "num_tran_keys = 5\n",
    "trans_threshes = [5, 8, 10, 19, 27, 38, 52, 60]\n",
    "sides = {\"bm\":[], \"b\":[], \"t\":[], \"ucf\":[]}\n",
    "classes = {\"bm\":[], \"br\":[], \"bl\":[], \"tr\":[], \"tl\":[], \"ucf\":[]}\n",
    "transitions = {\"bm->bm\" :[], \"bm->br\":[], \"bm->bl\":[], \"bm->tr\":[], \"bm->tl\":[],\n",
    "              \"br->bm\" :[], \"br->br\":[], \"br->bl\":[], \"br->tr\":[], \"br->tl\":[],\n",
    "              \"bl->bm\" :[], \"bl->br\":[], \"bl->bl\":[], \"bl->tr\":[], \"bl->tl\":[],\n",
    "              \"tr->bm\" :[], \"tr->br\":[], \"tr->bl\":[], \"tr->tr\":[], \"tr->tl\":[],\n",
    "              \"tl->bm\" :[], \"tl->br\":[], \"tl->bl\":[], \"tl->tr\":[], \"tl->tl\":[]}\n",
    "\n",
    "skeys = list(sides.keys())\n",
    "ckeys = list(classes.keys())\n",
    "for trans_fil in trans_threshes:\n",
    "    print(\"\\nTRANSITION THRESHOLD \", trans_fil)\n",
    "    \n",
    "    Top_bottoms, Full_classif, N_transitions = trans_runs[trans_fil]\n",
    "    #Top_bottoms, Full_classif, N_transitions, trans_threshes, num_top_keys, num_full_keys,\n",
    "                             #num_tran_keys, skeys, ckeys, num_tran_keys, num_total_frames = trans_runs[trans_fil]\n",
    "    sums = np.sum\n",
    "    Tb_sums = [sums(Top_bottoms[:, c]) for c in range(num_top_keys)]\n",
    "    Fc_sums = [sums(Full_classif[:, c]) for c in range(num_full_keys)]\n",
    "    Nt_sums = sums(N_transitions, axis = 0)#[sums(N_transitions[:, c]) for c in range(num_tran_keys)]\n",
    "    #print(\"\\nNumber of frames obbserved: \", num_total_frames)\n",
    "\n",
    "    Tb_percs = [Tb_sums[c] *100 /sums(Tb_sums) for c in range(num_top_keys)]\n",
    "    Fc_percs = [Fc_sums[c] *100/sums(Fc_sums) for c in range(num_full_keys)]\n",
    "    Nt_percs = Nt_sums *100/sums(Nt_sums)\n",
    "    #print(sums(N_transitions), sums(Nt_sums))\n",
    "\n",
    "\n",
    "    print(\"\\nsums in broad classifications\")\n",
    "    [print(skeys[i], \"sum %.f\" %Tb_sums[i]) for i in range(len(skeys))]\n",
    "    print(\"Total: \", sums(Tb_sums) )\n",
    "    print(\"\\nsums in narrow classifications\")\n",
    "    [print(ckeys[i], \"sum %.f\" %Fc_sums[i]) for i in range(len(ckeys))]\n",
    "    print(\"Total: \", sums(Fc_sums ) )\n",
    "    print(\"\\nsums of transitions broad\")\n",
    "    T_eb = np.vstack([Nt_sums[0], \n",
    "                                 (Nt_sums[1] + Nt_sums[2]) , \n",
    "                                 (Nt_sums[3] + Nt_sums[4])])\n",
    "    Nt_sums_broad = np.column_stack([T_eb[:, 0], \n",
    "                                 (T_eb[:, 1]+ T_eb[:, 2]), \n",
    "                                 (T_eb[:, 3]+ T_eb[:, 4])])\n",
    "    print(Nt_sums_broad)\n",
    "    print(\"\\nsums of transitions narrow\")\n",
    "    print(Nt_sums)\n",
    "    print(\"Total: \", sums(Nt_sums) )\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n%s in broad classifications\")\n",
    "    [print(skeys[i], \" %.f%%\" %Tb_percs[i]) for i in range(len(skeys))]\n",
    "    print(\"\\n%s in narrow classifications\")\n",
    "    [print(ckeys[i], \" %.f%%\" %Fc_percs[i]) for i in range(len(ckeys))]\n",
    "    print(\"Transition matrix, broad\")\n",
    "    T_eb = np.vstack([Nt_percs[0], \n",
    "                                 (Nt_percs[1] + Nt_percs[2]) , \n",
    "                                 (Nt_percs[3] + Nt_percs[4])])\n",
    "    Nt_percs_broad = np.column_stack([T_eb[:, 0], \n",
    "                                 (T_eb[:, 1]+ T_eb[:, 2]), \n",
    "                                 (T_eb[:, 3]+ T_eb[:, 4])])\n",
    "    print(Nt_percs_broad)\n",
    "    print(\"row_sums of transitin matrix, broad\")\n",
    "    print(sums(Nt_percs_broad, axis = 1))\n",
    "    print(\"\\n%s of transitions broad(->bm, ->b, ->t):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 0)[0]*100/sums(Nt_sums), \n",
    "           (sums(Nt_sums, axis = 0)[1] + sums(Nt_sums, axis = 0)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 0)[3] + sums(Nt_sums, axis = 0)[4])*100/(sums(Nt_sums))])\n",
    "    print(\"\\n%s of transitions broad(bm->, b->, t->):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 1)[0]*100/sums(Nt_sums),\n",
    "           (sums(Nt_sums, axis = 1)[1] + sums(Nt_sums, axis = 1)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 1)[3] + sums(Nt_sums, axis =1)[4])*100/(sums(Nt_sums))])#(Nt_percs[i,1] + Nt_percs[i,1+1] + Nt_percs[i+1, 1] + Nt_percs[i+1, 1+1] + sums(Nt_percs[0, 1:3]))) for i in [1,3]]\n",
    "    #print(\"->t %.f%%\" %(Nt_percs[i,2] + Nt_percs[i,2+1] + Nt_percs[i+1, 2] + Nt_percs[i+1, 2+1] + sums(Nt_percs[0, 3:5]))) for i in [1,3]]\n",
    "    print(\"\\nTransition matrix, narrow\")\n",
    "    print(Nt_percs)\n",
    "    print(sums(Nt_percs))\n",
    "    print(\"\\n%s of transitions to states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 0)*100/sums(Nt_percs))]\n",
    "    print(\"\\n%s of transitions from states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 1)*100/sums(Nt_percs))]\n",
    "    #print(\"\\n%s of transitions narrow\")\n",
    "    #[print(tkeys[i], \" %.f%%\" %Nt_percs.flatten()[i]) for i in range(len(tkeys))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
