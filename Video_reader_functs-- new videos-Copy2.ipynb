{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is video reader with all operations inside fnctions, so they can be called on \\n    each frame out of a set of frames, and each video out of a set of videos\\n    '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This is video reader with all operations inside fnctions, so they can be called on \n",
    "    each frame out of a set of frames, and each video out of a set of videos\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports\"\"\"\n",
    "import matplotlib.pyplot as plt #for maknig plots inside the notebook\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from skvideo.io import vreader, ffprobe\n",
    "from skimage import measure, morphology\n",
    "from skimage.filters import *\n",
    "from operator import attrgetter\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import chain\n",
    "#from functools import partial, update_wrapper\n",
    "from scipy import ndimage \n",
    "from pims import pipeline, Video\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict \n",
    "#import antigravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions\"\"\"\n",
    "# apply total thresholding to each of a list of frames; filter slides with wrong number\n",
    "def total_threshold_filter(frame, frame_no, transition_threshold, class_thresh,\n",
    "                           broken_count, class_num, origin, last_class, last_whole, filtrate_len, \n",
    "                           sides, classes, transitions): \n",
    "    \n",
    "    m_lab = measure.label\n",
    "    m_rop = measure.regionprops\n",
    "    # returns a new list, different from the orginal\n",
    "    thresh_img = frame > threshold_li(frame) # binary image\n",
    "    img_labelled = m_lab(thresh_img) # contains connected regions\n",
    "    properties_list = m_rop(img_labelled, coordinates = 'rc') # data about regions, for each connected region\n",
    "\n",
    "    #----------getting maximum connected region----------\n",
    "    biggest_r = max(properties_list, key = attrgetter('area'))\n",
    "\n",
    "    biggest_r = m_rop(morphology.closing(m_lab(biggest_r.filled_image)), coordinates='rc')[0]\n",
    "    #----------------------filter------------------------- can use actual filter\n",
    "    test = (biggest_r.filled_area > area_threshold\n",
    "               \n",
    "               #and biggest_r.major_axis_length < major_threshold # must then be well-formed\n",
    "               ) # major_axis length (< filterd) # particles must be in parallelogram\n",
    "    if test: # keep frames that have enough paricles, and are not transitions\n",
    "        if (biggest_r.inertia_tensor[0, 0] + biggest_r.inertia_tensor[1,1] > iner_threshold[0]\n",
    "                and biggest_r.inertia_tensor[0, 0] + biggest_r.inertia_tensor[1,1] < iner_threshold[1]):\n",
    "            i_threshed = frame > threshold_isodata(frame)\n",
    "            img2_labelled = m_lab(i_threshed)\n",
    "            properties2_list = m_rop(img2_labelled, coordinates = 'rc')\n",
    "            biggest_r2 = max(properties2_list, key = attrgetter('area'))\n",
    "            #-----------------------------classify pt 1---------------------------------------\n",
    "            coprod = coord_prod(thresh_img, i_threshed)\n",
    "            side = sideify(biggest_r2)\n",
    "            clas = side\n",
    "            sides[side].append(frame_no)\n",
    "            classes[clas].append(frame_no)\n",
    "            #print(clas)\n",
    "        else:\n",
    "            clas = 'ucf'\n",
    "            \n",
    "        if clas == 'ucf':\n",
    "            #broken_count += 1\n",
    "            #class_num = 0\n",
    "            #print('ucf->reset class')\n",
    "            pass\n",
    "        else:\n",
    "            if origin == 'ucf':\n",
    "                origin = last_class\n",
    "                #print(\"reset origin\")\n",
    "            if clas == last_class:\n",
    "                class_num += 1\n",
    "                #print(\"class_num: %s\" %class_num)\n",
    "            else:\n",
    "                class_num = 0\n",
    "                #print(\"class_num: %s\" %class_num)\n",
    "            if class_num >= class_thresh: \n",
    "                if broken_count >= transition_threshold or clas != origin:\n",
    "                    transitions[origin + \"->\" + clas].append((last_whole, frame_no))\n",
    "                    #print(origin + \"->\" + clas)\n",
    "                    origin = clas\n",
    "                    #print(\"origin: %s\" %origin)\n",
    "                broken_count = 0\n",
    "                #print(\"broken_count: %s\" %broken_count)\n",
    "                \n",
    "            \n",
    "                \n",
    "            last_whole = frame_no\n",
    "            filtrate_len += 1 \n",
    "            last_class = clas\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        #print(\"broken\")\n",
    "        class_num = 0\n",
    "        #print(\"class_num: %s\" %class_num)\n",
    "        broken_count += 1\n",
    "        #print(\"broken_count: %s\" %broken_count)\n",
    "\n",
    "    return [broken_count, class_num, origin, last_class, last_whole, filtrate_len]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# take largest isodata image region, and return aclassification\n",
    "def sideify(idir):\n",
    "    iner = idir.inertia_tensor[0, 0] + idir.inertia_tensor[1, 1]\n",
    "    maal = idir.major_axis_length\n",
    "    mial = idir.minor_axis_length\n",
    "    sol = idir.solidity \n",
    "    ecc = idir.eccentricity\n",
    "    cva = idir.convex_area\n",
    "    area = idir.area\n",
    "    if area < 1280:\n",
    "        return \"ucf\"\n",
    "    elif ecc <= 0.7 and  mial > 41:\n",
    "        return \"t\"\n",
    "    elif ecc > 0.8 and ecc < 0.91 and maal > 66.5 and maal < 74: # maal > 67.5 and or (mial < 41 and maal > 65): # it's on top\n",
    "        return \"c\"\n",
    "    else:\n",
    "        return \"ucf\"\n",
    "    \"\"\"iner = idir.inertia_tensor[0, 0] + idir.inertia_tensor[1, 1]\n",
    "    maal = idir.major_axis_length\n",
    "    mial = idir.minor_axis_length\n",
    "    sol = idir.solidity \n",
    "    ecc = idir.eccentricity\n",
    "    cva = idir.convex_area\n",
    "    if sol <= 0.725 or (iner> 405 and mial > 43.5): # sol <.72\n",
    "        return \"bm\"\n",
    "    elif ecc > 0.8 or maal > 65: # or (mial < 41 and maal > 65): # it's on top #ec >.82\n",
    "        return \"t\"\n",
    "    elif ecc < 0.75 or maal < 64.5: #or mial > 42  #and cva > 2200 and iner < 325: #or (maal < 64 and iner < 360): # it's on bottom\n",
    "        return \"b\"\n",
    "    else:\n",
    "        return \"ucf\"\n",
    "        \"\"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def coord_prod(thresh_y, thresh_i):\n",
    "    m_rop = measure.regionprops\n",
    "    full = largest_region_extractor(measure.label(thresh_y))\n",
    "    four = largest_region_extractor(measure.label(thresh_i))\n",
    "    full_or = m_rop(full.astype(int), coordinates = 'rc')[0].orientation\n",
    "    one_and_some = full^four\n",
    "    one = largest_region_extractor(measure.label(one_and_some))\n",
    "\n",
    "\n",
    "    #Begin finding substitue for major and minor axes herre\n",
    "    # use min and maax x and  values to find the geometric center\n",
    "    # or use those to substitue for eigenvectors \n",
    "    rotated_one = ndimage.rotate(one, math.degrees(-full_or), reshape = False)\n",
    "    rotated_full = ndimage.rotate(full, math.degrees(-full_or), reshape = False)\n",
    "    geo_cent = m_rop(rotated_full.astype(int), coordinates = 'rc')[0].bbox\n",
    "    #print(geo_cent)\n",
    "    ave = np.average\n",
    "    cent_x = ave([geo_cent[1], geo_cent[3]]) \n",
    "    cent_y = ave([geo_cent[0], geo_cent[2]])\n",
    "    #print(cent_x, cent_y)\n",
    "\n",
    "    raw_coords = (m_rop(rotated_full.astype(int), coordinates = 'rc')[0].coords).T\n",
    "    ys = raw_coords[0]\n",
    "    xs = raw_coords[1]\n",
    "    x = xs - cent_x\n",
    "    y = ys - cent_y      \n",
    "\n",
    "    one_com = m_rop(rotated_one.astype(int))[0].centroid\n",
    "\n",
    "    rel_com_one = (one_com[1] - cent_x, one_com[0] - cent_y)\n",
    "    product = np.prod(rel_com_one)\n",
    "    return product\n",
    "        \n",
    "def rotate_point(point, angle):\n",
    "    x0 = point[0]\n",
    "    y0 = point[1]\n",
    "    x1 = x0*np.cos(angle) - y0*np.sin(angle)\n",
    "    y1 = x0*np.sin(angle) + y0*np.cos(angle)\n",
    "    return (x1, y1)\n",
    " \n",
    "def region_selector(labeled_image, label):\n",
    "    #print(label)\n",
    "    x = labeled_image == label\n",
    "    #plt.imshow(x)\n",
    "    return x\n",
    "\n",
    "# make a function that takes a set of labeled regions, and then  returns a boolean array containing only the largest\n",
    "def largest_region_extractor(labeled_regions_set):\n",
    "    props_lists = measure.regionprops(labeled_regions_set)\n",
    "    #print(len(labeled_regions_set), len(props_lists))\n",
    "    biggest_r_label = max(props_lists, key = attrgetter('area')).label\n",
    "    return region_selector(labeled_regions_set, biggest_r_label)    \n",
    "#from pair of labelled, thresholded images, return an image category (of three)\n",
    "\n",
    "#from pair of labelled,thresholded images, return the x/y sign or x/y magnitude for the transparent dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./tchakamau\\\\2ND_4_PRTS\\\\45661_10Vpp_0.avi', './tchakamau\\\\2ND_4_PRTS\\\\45751_10Vpp_1.avi', './tchakamau\\\\2ND_4_PRTS\\\\45751_10Vpp_2.avi', './tchakamau\\\\2ND_4_PRTS\\\\45751_10Vpp_3.avi', './tchakamau\\\\2ND_4_PRTS\\\\45801_10Vpp_4.avi', './tchakamau\\\\2ND_4_PRTS\\\\45821_10Vpp_5.avi', './tchakamau\\\\2ND_4_PRTS\\\\45861_10Vpp_6.avi', './tchakamau\\\\2ND_4_PRTS\\\\45861_10Vpp_7.avi']\n",
      "Number files:  8\n",
      "T threshold: 30\n",
      "Processing vid 0 : ./tchakamau\\2ND_4_PRTS\\45661_10Vpp_0.avi\n",
      "[[12. 10.]\n",
      " [10. 15.]]\n",
      "Processing vid 1 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_1.avi\n",
      "[[18. 33.]\n",
      " [33. 46.]]\n",
      "Processing vid 2 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_2.avi\n",
      "[[ 5.  3.]\n",
      " [ 3. 13.]]\n",
      "Processing vid 3 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_3.avi\n",
      "[[ 9.  8.]\n",
      " [ 9. 27.]]\n",
      "Processing vid 4 : ./tchakamau\\2ND_4_PRTS\\45801_10Vpp_4.avi\n",
      "[[16.  6.]\n",
      " [ 5.  6.]]\n",
      "Processing vid 5 : ./tchakamau\\2ND_4_PRTS\\45821_10Vpp_5.avi\n",
      "[[16.  9.]\n",
      " [10. 21.]]\n",
      "Processing vid 6 : ./tchakamau\\2ND_4_PRTS\\45861_10Vpp_6.avi\n",
      "[[33. 12.]\n",
      " [12. 52.]]\n",
      "Processing vid 7 : ./tchakamau\\2ND_4_PRTS\\45861_10Vpp_7.avi\n",
      "[[ 7.  6.]\n",
      " [ 5. 19.]]\n",
      "T threshold: 40\n",
      "Processing vid 0 : ./tchakamau\\2ND_4_PRTS\\45661_10Vpp_0.avi\n",
      "[[10. 10.]\n",
      " [10. 13.]]\n",
      "Processing vid 1 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_1.avi\n",
      "[[11. 33.]\n",
      " [33. 39.]]\n",
      "Processing vid 2 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_2.avi\n",
      "[[ 5.  3.]\n",
      " [ 3. 12.]]\n",
      "Processing vid 3 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_3.avi\n",
      "[[ 6.  8.]\n",
      " [ 9. 20.]]\n",
      "Processing vid 4 : ./tchakamau\\2ND_4_PRTS\\45801_10Vpp_4.avi\n",
      "[[9. 6.]\n",
      " [5. 6.]]\n",
      "Processing vid 5 : ./tchakamau\\2ND_4_PRTS\\45821_10Vpp_5.avi\n",
      "[[11.  9.]\n",
      " [10. 18.]]\n",
      "Processing vid 6 : ./tchakamau\\2ND_4_PRTS\\45861_10Vpp_6.avi\n",
      "[[23. 12.]\n",
      " [12. 45.]]\n",
      "Processing vid 7 : ./tchakamau\\2ND_4_PRTS\\45861_10Vpp_7.avi\n",
      "[[ 6.  6.]\n",
      " [ 5. 16.]]\n",
      "T threshold: 50\n",
      "Processing vid 0 : ./tchakamau\\2ND_4_PRTS\\45661_10Vpp_0.avi\n",
      "[[ 8. 10.]\n",
      " [10. 10.]]\n",
      "Processing vid 1 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_1.avi\n",
      "[[10. 33.]\n",
      " [33. 31.]]\n",
      "Processing vid 2 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_2.avi\n",
      "[[ 3.  3.]\n",
      " [ 3. 10.]]\n",
      "Processing vid 3 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_3.avi\n",
      "[[ 3.  8.]\n",
      " [ 9. 17.]]\n",
      "Processing vid 4 : ./tchakamau\\2ND_4_PRTS\\45801_10Vpp_4.avi\n",
      "[[8. 6.]\n",
      " [5. 6.]]\n",
      "Processing vid 5 : ./tchakamau\\2ND_4_PRTS\\45821_10Vpp_5.avi\n",
      "[[ 8.  9.]\n",
      " [10. 18.]]\n",
      "Processing vid 6 : ./tchakamau\\2ND_4_PRTS\\45861_10Vpp_6.avi\n",
      "[[17. 12.]\n",
      " [12. 39.]]\n",
      "Processing vid 7 : ./tchakamau\\2ND_4_PRTS\\45861_10Vpp_7.avi\n",
      "[[ 5.  6.]\n",
      " [ 5. 12.]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Pipeline for lists of frames\"\"\"\n",
    "\"\"\"\"\"\"\n",
    "\"\"\"Pipeline for videos:\"\"\"\n",
    "# initialize frame lists\n",
    "filenames = glob(\"./tchakamau/2ND*/4*[0-9].avi\")#[\"./tchakamau/New_setup/45681_10Vpp_25.avi\"\n",
    "print(filenames)\n",
    "num_top_keys = 3\n",
    "num_full_keys = 3\n",
    "num_tran_keys = 2\n",
    "trans_threshes = [30, 40, 50]#[5, 8, 10, 19, 27, 38, 52, 60]\n",
    "class_thresh = 22\n",
    "trans_runs = {}\n",
    "#trans_fil = 10\n",
    "\n",
    "ave = np.average\n",
    "\n",
    "area_threshold = 1875   # must have enough particles\n",
    "iner_threshold = (340, 500)   # convex hull area (> 2500 filtered)  # particles must be in parallelogram # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "#major_thresholds = (59, 76)\n",
    "\"\"\"area_threshold = 1800   # must have enough particles\n",
    "convex_thresholds = (2000, 2800)   # convex hull area (> 2500 filtered)  # particles must be in parallelogram\n",
    "minor_thresholds = (38, 48) # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "major_thresholds = (59, 76)\"\"\"\n",
    "thresholds = [area_threshold , iner_threshold ]\n",
    "params = [1280,  0.7 ,41,0.8,0.91,66.5,74]\n",
    "print(\"Number files: \", len(filenames))\n",
    "\n",
    "for trans_fil in trans_threshes:\n",
    "    print(\"T threshold: %s\" %trans_fil)    \n",
    "    Top_bottoms = np.zeros((len(filenames), num_top_keys))\n",
    "    Full_classif = np.zeros((len(filenames), num_full_keys))\n",
    "    N_transitions = np.zeros((len(filenames), num_tran_keys, num_tran_keys))\n",
    "    num_total_frames = 0 \n",
    "    filtrate_len = 0\n",
    "    for vidnum in range(len(filenames)):\n",
    "        print(\"Processing vid %s : %s\" %(vidnum, filenames[vidnum]))\n",
    "        #meta = ffprobe(filenames[vidnum])\n",
    "        #print(meta)#['@nb_frames'])\n",
    "        #print(5)\n",
    "        frames = vreader(filenames[vidnum])\n",
    "        #frame_vid = frames[:, :, :, 2]# making videos ino a frame list\n",
    "        #print(frames)\n",
    "\n",
    "\n",
    "\n",
    "        sides = {\"t\":[], \"c\":[], \"ucf\":[]}\n",
    "        classes = {\"t\":[], \"c\":[], \"ucf\":[]}\n",
    "        transitions = [(\"t->t\",[]), (\"t->c\",[]),\n",
    "                      (\"c->t\" ,[]), (\"c->c\",[])]\n",
    "\n",
    "        transitions = OrderedDict(transitions)\n",
    "        broken_count = 0\n",
    "        class_num = 0\n",
    "        origin = 'ucf'\n",
    "        last_class = 'ucf'\n",
    "        last_whole = 0\n",
    "        for fr in frames:\n",
    "            frame = fr[:, :, 2]\n",
    "            num_total_frames += 1\n",
    "            org = total_threshold_filter(frame, num_total_frames, trans_fil, class_thresh,\n",
    "                                         broken_count, class_num, origin, last_class, last_whole, filtrate_len, \n",
    "                                         sides, classes, transitions)\n",
    "            broken_count, class_num, origin, last_class, last_whole, filtrate_len = org\n",
    "        filtered_len = filtrate_len\n",
    "        #----------------------------------------------------------------\n",
    "        trans_len = len([y for x in transitions.values() for y in x])\n",
    "        skeys = list(sides.keys())\n",
    "        ckeys = list(classes.keys())\n",
    "        tkeys = list(transitions.keys())\n",
    "        slcs = [len(sides[x]) for x in skeys]\n",
    "        clcs = [len(classes[x]) for x in ckeys]\n",
    "        trans = [len(transitions[x]) for x in tkeys] #num of each transition\n",
    "        ucf = len(sides[\"ucf\"])\n",
    "\n",
    "\n",
    "        Top_bottoms[vidnum,:] = [slcs[i] for i in range(len(skeys))]\n",
    "        Full_classif[vidnum,:] = [clcs[i] for i in range(len(ckeys))]\n",
    "        N_transitions[vidnum,:] = np.reshape(trans, (num_tran_keys, num_tran_keys))\n",
    "        print(N_transitions[vidnum,:])\n",
    "        #print(\"finished vid %s\" %vidnum)\n",
    "    trans_runs[trans_fil] = [[Top_bottoms, Full_classif, N_transitions, trans_threshes, num_top_keys, num_full_keys,\n",
    "                             num_tran_keys, skeys, ckeys, num_tran_keys, num_total_frames], thresholds, params]\n",
    "        #---------------------------------------------------------------------------------\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "np.save('trans_round2.npy',trans_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./tchakamau\\\\2ND_4_PRTS\\\\45661_10Vpp_0.avi', './tchakamau\\\\2ND_4_PRTS\\\\45751_10Vpp_1.avi', './tchakamau\\\\2ND_4_PRTS\\\\45751_10Vpp_2.avi', './tchakamau\\\\2ND_4_PRTS\\\\45751_10Vpp_3.avi', './tchakamau\\\\2ND_4_PRTS\\\\45801_10Vpp_4.avi', './tchakamau\\\\2ND_4_PRTS\\\\45821_10Vpp_5.avi', './tchakamau\\\\2ND_4_PRTS\\\\45861_10Vpp_6.avi', './tchakamau\\\\2ND_4_PRTS\\\\45861_10Vpp_7.avi']\n",
      "Number files:  8\n",
      "T threshold: 60\n",
      "Processing vid 0 : ./tchakamau\\2ND_4_PRTS\\45661_10Vpp_0.avi\n",
      "[[ 8. 10.]\n",
      " [10.  8.]]\n",
      "Processing vid 1 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_1.avi\n",
      "[[ 9. 33.]\n",
      " [33. 30.]]\n",
      "Processing vid 2 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_2.avi\n",
      "[[2. 3.]\n",
      " [3. 9.]]\n",
      "Processing vid 3 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_3.avi\n",
      "[[ 1.  8.]\n",
      " [ 9. 16.]]\n",
      "Processing vid 4 : ./tchakamau\\2ND_4_PRTS\\45801_10Vpp_4.avi\n",
      "[[7. 6.]\n",
      " [5. 6.]]\n",
      "Processing vid 5 : ./tchakamau\\2ND_4_PRTS\\45821_10Vpp_5.avi\n",
      "[[ 7.  9.]\n",
      " [10. 16.]]\n",
      "Processing vid 6 : ./tchakamau\\2ND_4_PRTS\\45861_10Vpp_6.avi\n",
      "[[15. 12.]\n",
      " [12. 36.]]\n",
      "Processing vid 7 : ./tchakamau\\2ND_4_PRTS\\45861_10Vpp_7.avi\n",
      "[[ 5.  6.]\n",
      " [ 5. 11.]]\n",
      "T threshold: 70\n",
      "Processing vid 0 : ./tchakamau\\2ND_4_PRTS\\45661_10Vpp_0.avi\n",
      "[[ 8. 10.]\n",
      " [10.  8.]]\n",
      "Processing vid 1 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_1.avi\n",
      "[[ 4. 33.]\n",
      " [33. 27.]]\n",
      "Processing vid 2 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_2.avi\n",
      "[[2. 3.]\n",
      " [3. 9.]]\n",
      "Processing vid 3 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_3.avi\n",
      "[[ 1.  8.]\n",
      " [ 9. 13.]]\n",
      "Processing vid 4 : ./tchakamau\\2ND_4_PRTS\\45801_10Vpp_4.avi\n",
      "[[6. 6.]\n",
      " [5. 5.]]\n",
      "Processing vid 5 : ./tchakamau\\2ND_4_PRTS\\45821_10Vpp_5.avi\n",
      "[[ 6.  9.]\n",
      " [10. 16.]]\n",
      "Processing vid 6 : ./tchakamau\\2ND_4_PRTS\\45861_10Vpp_6.avi\n",
      "[[12. 12.]\n",
      " [12. 33.]]\n",
      "Processing vid 7 : ./tchakamau\\2ND_4_PRTS\\45861_10Vpp_7.avi\n",
      "[[5. 6.]\n",
      " [5. 9.]]\n",
      "T threshold: 80\n",
      "Processing vid 0 : ./tchakamau\\2ND_4_PRTS\\45661_10Vpp_0.avi\n",
      "[[ 7. 10.]\n",
      " [10.  7.]]\n",
      "Processing vid 1 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_1.avi\n",
      "[[ 3. 33.]\n",
      " [33. 26.]]\n",
      "Processing vid 2 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_2.avi\n",
      "[[2. 3.]\n",
      " [3. 9.]]\n",
      "Processing vid 3 : ./tchakamau\\2ND_4_PRTS\\45751_10Vpp_3.avi\n",
      "[[ 1.  8.]\n",
      " [ 9. 12.]]\n",
      "Processing vid 4 : ./tchakamau\\2ND_4_PRTS\\45801_10Vpp_4.avi\n",
      "[[5. 6.]\n",
      " [5. 5.]]\n",
      "Processing vid 5 : ./tchakamau\\2ND_4_PRTS\\45821_10Vpp_5.avi\n",
      "[[ 4.  9.]\n",
      " [10. 11.]]\n",
      "Processing vid 6 : ./tchakamau\\2ND_4_PRTS\\45861_10Vpp_6.avi\n",
      "[[11. 12.]\n",
      " [12. 31.]]\n",
      "Processing vid 7 : ./tchakamau\\2ND_4_PRTS\\45861_10Vpp_7.avi\n",
      "[[4. 6.]\n",
      " [5. 9.]]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Pipeline for lists of frames\"\"\"\n",
    "\"\"\"\"\"\"\n",
    "\"\"\"Pipeline for videos:\"\"\"\n",
    "# initialize frame lists\n",
    "filenames = glob(\"./tchakamau/2ND*/4*[0-9].avi\")#[\"./tchakamau/New_setup/45681_10Vpp_25.avi\"\n",
    "print(filenames)\n",
    "num_top_keys = 3\n",
    "num_full_keys = 3\n",
    "num_tran_keys = 2\n",
    "trans_threshes = [60, 70, 80]#[5, 8, 10, 19, 27, 38, 52, 60]\n",
    "class_thresh = 22\n",
    "trans_runs = {}\n",
    "#trans_fil = 10\n",
    "\n",
    "ave = np.average\n",
    "\n",
    "area_threshold = 1875   # must have enough particles\n",
    "iner_threshold = (340, 500)   # convex hull area (> 2500 filtered)  # particles must be in parallelogram # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "#major_thresholds = (59, 76)\n",
    "\"\"\"area_threshold = 1800   # must have enough particles\n",
    "convex_thresholds = (2000, 2800)   # convex hull area (> 2500 filtered)  # particles must be in parallelogram\n",
    "minor_thresholds = (38, 48) # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "major_thresholds = (59, 76)\"\"\"\n",
    "thresholds = [area_threshold , iner_threshold ]\n",
    "params = [1280,  0.7 ,41,0.8,0.91,66.5,74]\n",
    "print(\"Number files: \", len(filenames))\n",
    "\n",
    "for trans_fil in trans_threshes:\n",
    "    print(\"T threshold: %s\" %trans_fil)    \n",
    "    Top_bottoms = np.zeros((len(filenames), num_top_keys))\n",
    "    Full_classif = np.zeros((len(filenames), num_full_keys))\n",
    "    N_transitions = np.zeros((len(filenames), num_tran_keys, num_tran_keys))\n",
    "    num_total_frames = 0 \n",
    "    filtrate_len = 0\n",
    "    for vidnum in range(len(filenames)):\n",
    "        print(\"Processing vid %s : %s\" %(vidnum, filenames[vidnum]))\n",
    "        #meta = ffprobe(filenames[vidnum])\n",
    "        #print(meta)#['@nb_frames'])\n",
    "        #print(5)\n",
    "        frames = vreader(filenames[vidnum])\n",
    "        #frame_vid = frames[:, :, :, 2]# making videos ino a frame list\n",
    "        #print(frames)\n",
    "\n",
    "\n",
    "\n",
    "        sides = {\"t\":[], \"c\":[], \"ucf\":[]}\n",
    "        classes = {\"t\":[], \"c\":[], \"ucf\":[]}\n",
    "        transitions = [(\"t->t\",[]), (\"t->c\",[]),\n",
    "                      (\"c->t\" ,[]), (\"c->c\",[])]\n",
    "\n",
    "        transitions = OrderedDict(transitions)\n",
    "        broken_count = 0\n",
    "        class_num = 0\n",
    "        origin = 'ucf'\n",
    "        last_class = 'ucf'\n",
    "        last_whole = 0\n",
    "        for fr in frames:\n",
    "            frame = fr[:, :, 2]\n",
    "            num_total_frames += 1\n",
    "            org = total_threshold_filter(frame, num_total_frames, trans_fil, class_thresh,\n",
    "                                         broken_count, class_num, origin, last_class, last_whole, filtrate_len, \n",
    "                                         sides, classes, transitions)\n",
    "            broken_count, class_num, origin, last_class, last_whole, filtrate_len = org\n",
    "        filtered_len = filtrate_len\n",
    "        #----------------------------------------------------------------\n",
    "        trans_len = len([y for x in transitions.values() for y in x])\n",
    "        skeys = list(sides.keys())\n",
    "        ckeys = list(classes.keys())\n",
    "        tkeys = list(transitions.keys())\n",
    "        slcs = [len(sides[x]) for x in skeys]\n",
    "        clcs = [len(classes[x]) for x in ckeys]\n",
    "        trans = [len(transitions[x]) for x in tkeys] #num of each transition\n",
    "        ucf = len(sides[\"ucf\"])\n",
    "\n",
    "\n",
    "        Top_bottoms[vidnum,:] = [slcs[i] for i in range(len(skeys))]\n",
    "        Full_classif[vidnum,:] = [clcs[i] for i in range(len(ckeys))]\n",
    "        N_transitions[vidnum,:] = np.reshape(trans, (num_tran_keys, num_tran_keys))\n",
    "        print(N_transitions[vidnum,:])\n",
    "        #print(\"finished vid %s\" %vidnum)\n",
    "    trans_runs[trans_fil] = [[Top_bottoms, Full_classif, N_transitions, trans_threshes, num_top_keys, num_full_keys,\n",
    "                             num_tran_keys, skeys, ckeys, num_tran_keys, num_total_frames], thresholds, params]\n",
    "        #---------------------------------------------------------------------------------\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "np.save('trans_round2_2.npy',trans_runs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRANSITION THRESHOLD  60\n",
      "\n",
      "sums in broad classifications\n",
      "t sum 158937\n",
      "c sum 247469\n",
      "ucf sum 48857\n",
      "Total:  455263.0\n",
      "\n",
      "sums in narrow classifications\n",
      "t sum 158937\n",
      "c sum 247469\n",
      "ucf sum 48857\n",
      "Total:  455263.0\n",
      "\n",
      "sums of transitions broad\n",
      "[[ 54.  87.]\n",
      " [ 87. 132.]]\n",
      "\n",
      "sums of transitions narrow\n",
      "[[ 54.  87.]\n",
      " [ 87. 132.]]\n",
      "Total:  360.0\n",
      "\n",
      "Errors in transition matrix ((row_sums - column_sums) / 2)\n",
      "[0. 0.]\n",
      "\n",
      "Error %%s in transition matrix ((row_sums - column_sums) *100 / (row_sums + column_sums))\n",
      "[0. 0.]\n",
      "\n",
      "Transition matrix, broad\n",
      "[[15.         24.16666667]\n",
      " [24.16666667 36.66666667]]\n",
      "\n",
      "Transition matrix, narrow\n",
      "[[15.         24.16666667]\n",
      " [24.16666667 36.66666667]]\n",
      "100.0\n",
      "\n",
      "%s of transitions to states narrow:\n",
      "[39.16666667 60.83333333]\n",
      "\n",
      "%s of transitions from states narrow:\n",
      "[39.16666667 60.83333333]\n",
      "\n",
      "%s of transitions to states broad:\n",
      "[39.16666667 60.83333333]\n",
      "\n",
      "%s of transitions from states broad:\n",
      "[39.16666667 60.83333333]\n",
      "\n",
      "TRANSITION THRESHOLD  70\n",
      "\n",
      "sums in broad classifications\n",
      "t sum 158937\n",
      "c sum 247469\n",
      "ucf sum 48857\n",
      "Total:  455263.0\n",
      "\n",
      "sums in narrow classifications\n",
      "t sum 158937\n",
      "c sum 247469\n",
      "ucf sum 48857\n",
      "Total:  455263.0\n",
      "\n",
      "sums of transitions broad\n",
      "[[ 44.  87.]\n",
      " [ 87. 120.]]\n",
      "\n",
      "sums of transitions narrow\n",
      "[[ 44.  87.]\n",
      " [ 87. 120.]]\n",
      "Total:  338.0\n",
      "\n",
      "Errors in transition matrix ((row_sums - column_sums) / 2)\n",
      "[0. 0.]\n",
      "\n",
      "Error %%s in transition matrix ((row_sums - column_sums) *100 / (row_sums + column_sums))\n",
      "[0. 0.]\n",
      "\n",
      "Transition matrix, broad\n",
      "[[13.01775148 25.73964497]\n",
      " [25.73964497 35.50295858]]\n",
      "\n",
      "Transition matrix, narrow\n",
      "[[13.01775148 25.73964497]\n",
      " [25.73964497 35.50295858]]\n",
      "100.0\n",
      "\n",
      "%s of transitions to states narrow:\n",
      "[38.75739645 61.24260355]\n",
      "\n",
      "%s of transitions from states narrow:\n",
      "[38.75739645 61.24260355]\n",
      "\n",
      "%s of transitions to states broad:\n",
      "[38.75739645 61.24260355]\n",
      "\n",
      "%s of transitions from states broad:\n",
      "[38.75739645 61.24260355]\n",
      "\n",
      "TRANSITION THRESHOLD  80\n",
      "\n",
      "sums in broad classifications\n",
      "t sum 158937\n",
      "c sum 247469\n",
      "ucf sum 48857\n",
      "Total:  455263.0\n",
      "\n",
      "sums in narrow classifications\n",
      "t sum 158937\n",
      "c sum 247469\n",
      "ucf sum 48857\n",
      "Total:  455263.0\n",
      "\n",
      "sums of transitions broad\n",
      "[[ 37.  87.]\n",
      " [ 87. 110.]]\n",
      "\n",
      "sums of transitions narrow\n",
      "[[ 37.  87.]\n",
      " [ 87. 110.]]\n",
      "Total:  321.0\n",
      "\n",
      "Errors in transition matrix ((row_sums - column_sums) / 2)\n",
      "[0. 0.]\n",
      "\n",
      "Error %%s in transition matrix ((row_sums - column_sums) *100 / (row_sums + column_sums))\n",
      "[0. 0.]\n",
      "\n",
      "Transition matrix, broad\n",
      "[[11.52647975 27.10280374]\n",
      " [27.10280374 34.26791277]]\n",
      "\n",
      "Transition matrix, narrow\n",
      "[[11.52647975 27.10280374]\n",
      " [27.10280374 34.26791277]]\n",
      "100.0\n",
      "\n",
      "%s of transitions to states narrow:\n",
      "[38.62928349 61.37071651]\n",
      "\n",
      "%s of transitions from states narrow:\n",
      "[38.62928349 61.37071651]\n",
      "\n",
      "%s of transitions to states broad:\n",
      "[38.62928349 61.37071651]\n",
      "\n",
      "%s of transitions from states broad:\n",
      "[38.62928349 61.37071651]\n"
     ]
    }
   ],
   "source": [
    "trans_runs= np.load('trans_round2_2.npy')[()]\n",
    "trans_threshes = [60, 70, 80]\n",
    "\"\"\"num_top_keys = 4\n",
    "num_full_keys = 6\n",
    "num_tran_keys = 5\n",
    "trans_threshes = [5, 8, 10, 19, 27, 38, 52, 60]\n",
    "sides = {\"bm\":[], \"b\":[], \"t\":[], \"ucf\":[]}\n",
    "classes = {\"bm\":[], \"br\":[], \"bl\":[], \"tr\":[], \"tl\":[], \"ucf\":[]}\n",
    "transitions = {\"bm->bm\" :[], \"bm->br\":[], \"bm->bl\":[], \"bm->tr\":[], \"bm->tl\":[],\n",
    "              \"br->bm\" :[], \"br->br\":[], \"br->bl\":[], \"br->tr\":[], \"br->tl\":[],\n",
    "              \"bl->bm\" :[], \"bl->br\":[], \"bl->bl\":[], \"bl->tr\":[], \"bl->tl\":[],\n",
    "              \"tr->bm\" :[], \"tr->br\":[], \"tr->bl\":[], \"tr->tr\":[], \"tr->tl\":[],\n",
    "              \"tl->bm\" :[], \"tl->br\":[], \"tl->bl\":[], \"tl->tr\":[], \"tl->tl\":[]}\"\"\"\n",
    "\n",
    "skeys = list(sides.keys())\n",
    "ckeys = list(classes.keys())\n",
    "for trans_fil in trans_threshes:\n",
    "    print(\"\\nTRANSITION THRESHOLD \", trans_fil)\n",
    "    \n",
    "    #Top_bottoms, Full_classif, N_transitions = trans_runs[trans_fil]\n",
    "    Top_bottoms, Full_classif, N_transitions, trans_threshes, num_top_keys, num_full_keys, num_tran_keys, skeys, ckeys, num_tran_keys, num_total_frames = trans_runs[trans_fil][0]\n",
    "    sums = np.sum\n",
    "    Tb_sums = [sums(Top_bottoms[:, c]) for c in range(num_top_keys)]\n",
    "    Fc_sums = [sums(Full_classif[:, c]) for c in range(num_full_keys)]\n",
    "    Nt_sums = sums(N_transitions, axis = 0)#[sums(N_transitions[:, c]) for c in range(nu   m_tran_keys)]\n",
    "    #print(\"\\nNumber of frames obbserved: \", num_total_frames)\n",
    "\n",
    "    Tb_percs = [Tb_sums[c] *100 /sums(Tb_sums) for c in range(num_top_keys)]\n",
    "    Fc_percs = [Fc_sums[c] *100/sums(Fc_sums) for c in range(num_full_keys)]\n",
    "    Nt_percs = Nt_sums *100/sums(Nt_sums)\n",
    "    #print(sums(N_transitions), sums(Nt_sums))\n",
    "\n",
    "\n",
    "    print(\"\\nsums in broad classifications\")\n",
    "    [print(skeys[i], \"sum %.f\" %Tb_sums[i]) for i in range(len(skeys))]\n",
    "    print(\"Total: \", sums(Tb_sums) )\n",
    "    print(\"\\nsums in narrow classifications\")\n",
    "    [print(ckeys[i], \"sum %.f\" %Fc_sums[i]) for i in range(len(ckeys))]\n",
    "    print(\"Total: \", sums(Fc_sums ) )\n",
    "    print(\"\\nsums of transitions broad\")\n",
    "    Nt_sums_broad =Nt_sums\n",
    "    print(Nt_sums_broad)\n",
    "    print(\"\\nsums of transitions narrow\")\n",
    "    print(Nt_sums)\n",
    "    print(\"Total: \", sums(Nt_sums) )\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"print(\"\\n%s in broad classifications\")\n",
    "    [print(skeys[i], \" %.f%%\" %Tb_percs[i]) for i in range(len(skeys))]\n",
    "    print(\"\\n%s in narrow classifications\")\n",
    "    [print(ckeys[i], \" %.f%%\" %Fc_percs[i]) for i in range(len(ckeys))]\"\"\"\n",
    "    #ERROR ANALSIS HERE\n",
    "    print(\"\\nErrors in transition matrix ((row_sums - column_sums) / 2)\")\n",
    "    print(((sums(Nt_sums, axis = 1) - sums(Nt_sums, axis =0))/2))\n",
    "    print(\"\\nError %%s in transition matrix ((row_sums - column_sums) *100 / (row_sums + column_sums))\")\n",
    "    print(((sums(Nt_sums, axis = 1) - sums(Nt_sums, axis =0))*100 /(sums(Nt_sums, axis = 1) + sums(Nt_sums, axis =0))))\n",
    "    \n",
    "    print(\"\\nTransition matrix, broad\")\n",
    "    Nt_percs_broad = Nt_percs\n",
    "    print(Nt_percs_broad)\n",
    "    \"\"\"print(\"row_sums of transitin matrix, broad\")\n",
    "    print(sums(Nt_percs_broad, axis = 1))\n",
    "    print(\"\\n%s of transitions broad(->bm, ->b, ->t):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 0)[0]*100/sums(Nt_sums), \n",
    "           (sums(Nt_sums, axis = 0)[1] + sums(Nt_sums, axis = 0)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 0)[3] + sums(Nt_sums, axis = 0)[4])*100/(sums(Nt_sums))])\n",
    "    print(\"\\n%s of transitions broad(bm->, b->, t->):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 1)[0]*100/sums(Nt_sums),\n",
    "           (sums(Nt_sums, axis = 1)[1] + sums(Nt_sums, axis = 1)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 1)[3] + sums(Nt_sums, axis =1)[4])*100/(sums(Nt_sums))])#(Nt_percs[i,1] + Nt_percs[i,1+1] + Nt_percs[i+1, 1] + Nt_percs[i+1, 1+1] + sums(Nt_percs[0, 1:3]))) for i in [1,3]]\n",
    "    \"\"\"\n",
    "    #print(\"->t %.f%%\" %(Nt_percs[i,2] + Nt_percs[i,2+1] + Nt_percs[i+1, 2] + Nt_percs[i+1, 2+1] + sums(Nt_percs[0, 3:5]))) for i in [1,3]]\n",
    "    print(\"\\nTransition matrix, narrow\")\n",
    "    print(Nt_percs)\n",
    "    print(sums(Nt_percs))\n",
    "    print(\"\\n%s of transitions to states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 0)*100/sums(Nt_percs))]\n",
    "    print(\"\\n%s of transitions from states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 1)*100/sums(Nt_percs))]\n",
    "    print(\"\\n%s of transitions to states broad:\")\n",
    "    [print(sums(Nt_percs_broad, axis = 0)*100/sums(Nt_percs_broad))]\n",
    "    print(\"\\n%s of transitions from states broad:\")\n",
    "    [print(sums(Nt_percs_broad, axis = 1)*100/sums(Nt_percs_broad))]\n",
    "    #print(\"\\n%s of transitions narrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRANSITION THRESHOLD  30\n",
      "\n",
      "sums in broad classifications\n",
      "t sum 158937\n",
      "c sum 247469\n",
      "ucf sum 48857\n",
      "Total:  455263.0\n",
      "\n",
      "sums in narrow classifications\n",
      "t sum 158937\n",
      "c sum 247469\n",
      "ucf sum 48857\n",
      "Total:  455263.0\n",
      "\n",
      "sums of transitions broad\n",
      "[[116.  87.]\n",
      " [ 87. 199.]]\n",
      "\n",
      "sums of transitions narrow\n",
      "[[116.  87.]\n",
      " [ 87. 199.]]\n",
      "Total:  489.0\n",
      "\n",
      "Errors in transition matrix ((row_sums - column_sums) / 2)\n",
      "[0. 0.]\n",
      "\n",
      "Error %%s in transition matrix ((row_sums - column_sums) *100 / (row_sums + column_sums))\n",
      "[0. 0.]\n",
      "\n",
      "Transition matrix, broad\n",
      "[[23.72188139 17.79141104]\n",
      " [17.79141104 40.69529652]]\n",
      "\n",
      "Transition matrix, narrow\n",
      "[[23.72188139 17.79141104]\n",
      " [17.79141104 40.69529652]]\n",
      "100.0\n",
      "\n",
      "%s of transitions to states narrow:\n",
      "[41.51329243 58.48670757]\n",
      "\n",
      "%s of transitions from states narrow:\n",
      "[41.51329243 58.48670757]\n",
      "\n",
      "%s of transitions to states broad:\n",
      "[41.51329243 58.48670757]\n",
      "\n",
      "%s of transitions from states broad:\n",
      "[41.51329243 58.48670757]\n",
      "\n",
      "TRANSITION THRESHOLD  40\n",
      "\n",
      "sums in broad classifications\n",
      "t sum 158937\n",
      "c sum 247469\n",
      "ucf sum 48857\n",
      "Total:  455263.0\n",
      "\n",
      "sums in narrow classifications\n",
      "t sum 158937\n",
      "c sum 247469\n",
      "ucf sum 48857\n",
      "Total:  455263.0\n",
      "\n",
      "sums of transitions broad\n",
      "[[ 81.  87.]\n",
      " [ 87. 169.]]\n",
      "\n",
      "sums of transitions narrow\n",
      "[[ 81.  87.]\n",
      " [ 87. 169.]]\n",
      "Total:  424.0\n",
      "\n",
      "Errors in transition matrix ((row_sums - column_sums) / 2)\n",
      "[0. 0.]\n",
      "\n",
      "Error %%s in transition matrix ((row_sums - column_sums) *100 / (row_sums + column_sums))\n",
      "[0. 0.]\n",
      "\n",
      "Transition matrix, broad\n",
      "[[19.10377358 20.51886792]\n",
      " [20.51886792 39.85849057]]\n",
      "\n",
      "Transition matrix, narrow\n",
      "[[19.10377358 20.51886792]\n",
      " [20.51886792 39.85849057]]\n",
      "100.0\n",
      "\n",
      "%s of transitions to states narrow:\n",
      "[39.62264151 60.37735849]\n",
      "\n",
      "%s of transitions from states narrow:\n",
      "[39.62264151 60.37735849]\n",
      "\n",
      "%s of transitions to states broad:\n",
      "[39.62264151 60.37735849]\n",
      "\n",
      "%s of transitions from states broad:\n",
      "[39.62264151 60.37735849]\n",
      "\n",
      "TRANSITION THRESHOLD  50\n",
      "\n",
      "sums in broad classifications\n",
      "t sum 158937\n",
      "c sum 247469\n",
      "ucf sum 48857\n",
      "Total:  455263.0\n",
      "\n",
      "sums in narrow classifications\n",
      "t sum 158937\n",
      "c sum 247469\n",
      "ucf sum 48857\n",
      "Total:  455263.0\n",
      "\n",
      "sums of transitions broad\n",
      "[[ 62.  87.]\n",
      " [ 87. 143.]]\n",
      "\n",
      "sums of transitions narrow\n",
      "[[ 62.  87.]\n",
      " [ 87. 143.]]\n",
      "Total:  379.0\n",
      "\n",
      "Errors in transition matrix ((row_sums - column_sums) / 2)\n",
      "[0. 0.]\n",
      "\n",
      "Error %%s in transition matrix ((row_sums - column_sums) *100 / (row_sums + column_sums))\n",
      "[0. 0.]\n",
      "\n",
      "Transition matrix, broad\n",
      "[[16.35883905 22.95514512]\n",
      " [22.95514512 37.73087071]]\n",
      "\n",
      "Transition matrix, narrow\n",
      "[[16.35883905 22.95514512]\n",
      " [22.95514512 37.73087071]]\n",
      "100.0\n",
      "\n",
      "%s of transitions to states narrow:\n",
      "[39.31398417 60.68601583]\n",
      "\n",
      "%s of transitions from states narrow:\n",
      "[39.31398417 60.68601583]\n",
      "\n",
      "%s of transitions to states broad:\n",
      "[39.31398417 60.68601583]\n",
      "\n",
      "%s of transitions from states broad:\n",
      "[39.31398417 60.68601583]\n"
     ]
    }
   ],
   "source": [
    "trans_runs= np.load('trans_round2.npy')[()]\n",
    "trans_threshes = [30, 40, 50]\n",
    "\"\"\"num_top_keys = 4\n",
    "num_full_keys = 6\n",
    "num_tran_keys = 5\n",
    "trans_threshes = [5, 8, 10, 19, 27, 38, 52, 60]\n",
    "sides = {\"bm\":[], \"b\":[], \"t\":[], \"ucf\":[]}\n",
    "classes = {\"bm\":[], \"br\":[], \"bl\":[], \"tr\":[], \"tl\":[], \"ucf\":[]}\n",
    "transitions = {\"bm->bm\" :[], \"bm->br\":[], \"bm->bl\":[], \"bm->tr\":[], \"bm->tl\":[],\n",
    "              \"br->bm\" :[], \"br->br\":[], \"br->bl\":[], \"br->tr\":[], \"br->tl\":[],\n",
    "              \"bl->bm\" :[], \"bl->br\":[], \"bl->bl\":[], \"bl->tr\":[], \"bl->tl\":[],\n",
    "              \"tr->bm\" :[], \"tr->br\":[], \"tr->bl\":[], \"tr->tr\":[], \"tr->tl\":[],\n",
    "              \"tl->bm\" :[], \"tl->br\":[], \"tl->bl\":[], \"tl->tr\":[], \"tl->tl\":[]}\"\"\"\n",
    "\n",
    "skeys = list(sides.keys())\n",
    "ckeys = list(classes.keys())\n",
    "for trans_fil in trans_threshes:\n",
    "    print(\"\\nTRANSITION THRESHOLD \", trans_fil)\n",
    "    \n",
    "    #Top_bottoms, Full_classif, N_transitions = trans_runs[trans_fil]\n",
    "    Top_bottoms, Full_classif, N_transitions, trans_threshes, num_top_keys, num_full_keys, num_tran_keys, skeys, ckeys, num_tran_keys, num_total_frames = trans_runs[trans_fil][0]\n",
    "    sums = np.sum\n",
    "    Tb_sums = [sums(Top_bottoms[:, c]) for c in range(num_top_keys)]\n",
    "    Fc_sums = [sums(Full_classif[:, c]) for c in range(num_full_keys)]\n",
    "    Nt_sums = sums(N_transitions, axis = 0)#[sums(N_transitions[:, c]) for c in range(nu   m_tran_keys)]\n",
    "    #print(\"\\nNumber of frames obbserved: \", num_total_frames)\n",
    "\n",
    "    Tb_percs = [Tb_sums[c] *100 /sums(Tb_sums) for c in range(num_top_keys)]\n",
    "    Fc_percs = [Fc_sums[c] *100/sums(Fc_sums) for c in range(num_full_keys)]\n",
    "    Nt_percs = Nt_sums *100/sums(Nt_sums)\n",
    "    #print(sums(N_transitions), sums(Nt_sums))\n",
    "\n",
    "\n",
    "    print(\"\\nsums in broad classifications\")\n",
    "    [print(skeys[i], \"sum %.f\" %Tb_sums[i]) for i in range(len(skeys))]\n",
    "    print(\"Total: \", sums(Tb_sums) )\n",
    "    print(\"\\nsums in narrow classifications\")\n",
    "    [print(ckeys[i], \"sum %.f\" %Fc_sums[i]) for i in range(len(ckeys))]\n",
    "    print(\"Total: \", sums(Fc_sums ) )\n",
    "    print(\"\\nsums of transitions broad\")\n",
    "    Nt_sums_broad =Nt_sums\n",
    "    print(Nt_sums_broad)\n",
    "    print(\"\\nsums of transitions narrow\")\n",
    "    print(Nt_sums)\n",
    "    print(\"Total: \", sums(Nt_sums) )\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"print(\"\\n%s in broad classifications\")\n",
    "    [print(skeys[i], \" %.f%%\" %Tb_percs[i]) for i in range(len(skeys))]\n",
    "    print(\"\\n%s in narrow classifications\")\n",
    "    [print(ckeys[i], \" %.f%%\" %Fc_percs[i]) for i in range(len(ckeys))]\"\"\"\n",
    "    #ERROR ANALSIS HERE\n",
    "    print(\"\\nErrors in transition matrix ((row_sums - column_sums) / 2)\")\n",
    "    print(((sums(Nt_sums, axis = 1) - sums(Nt_sums, axis =0))/2))\n",
    "    print(\"\\nError %%s in transition matrix ((row_sums - column_sums) *100 / (row_sums + column_sums))\")\n",
    "    print(((sums(Nt_sums, axis = 1) - sums(Nt_sums, axis =0))*100 /(sums(Nt_sums, axis = 1) + sums(Nt_sums, axis =0))))\n",
    "    \n",
    "    print(\"\\nTransition matrix, broad\")\n",
    "    Nt_percs_broad = Nt_percs\n",
    "    print(Nt_percs_broad)\n",
    "    \"\"\"print(\"row_sums of transitin matrix, broad\")\n",
    "    print(sums(Nt_percs_broad, axis = 1))\n",
    "    print(\"\\n%s of transitions broad(->bm, ->b, ->t):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 0)[0]*100/sums(Nt_sums), \n",
    "           (sums(Nt_sums, axis = 0)[1] + sums(Nt_sums, axis = 0)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 0)[3] + sums(Nt_sums, axis = 0)[4])*100/(sums(Nt_sums))])\n",
    "    print(\"\\n%s of transitions broad(bm->, b->, t->):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 1)[0]*100/sums(Nt_sums),\n",
    "           (sums(Nt_sums, axis = 1)[1] + sums(Nt_sums, axis = 1)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 1)[3] + sums(Nt_sums, axis =1)[4])*100/(sums(Nt_sums))])#(Nt_percs[i,1] + Nt_percs[i,1+1] + Nt_percs[i+1, 1] + Nt_percs[i+1, 1+1] + sums(Nt_percs[0, 1:3]))) for i in [1,3]]\n",
    "    \"\"\"\n",
    "    #print(\"->t %.f%%\" %(Nt_percs[i,2] + Nt_percs[i,2+1] + Nt_percs[i+1, 2] + Nt_percs[i+1, 2+1] + sums(Nt_percs[0, 3:5]))) for i in [1,3]]\n",
    "    print(\"\\nTransition matrix, narrow\")\n",
    "    print(Nt_percs)\n",
    "    print(sums(Nt_percs))\n",
    "    print(\"\\n%s of transitions to states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 0)*100/sums(Nt_percs))]\n",
    "    print(\"\\n%s of transitions from states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 1)*100/sums(Nt_percs))]\n",
    "    print(\"\\n%s of transitions to states broad:\")\n",
    "    [print(sums(Nt_percs_broad, axis = 0)*100/sums(Nt_percs_broad))]\n",
    "    print(\"\\n%s of transitions from states broad:\")\n",
    "    [print(sums(Nt_percs_broad, axis = 1)*100/sums(Nt_percs_broad))]\n",
    "    #print(\"\\n%s of transitions narrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "TRANSITION THRESHOLD  60\n",
      "\n",
      "sums in broad classifications\n",
      "bm sum 84370\n",
      "b sum 109454\n",
      "t sum 83204\n",
      "ucf sum 92566\n",
      "Total:  369594.0\n",
      "\n",
      "sums in narrow classifications\n",
      "bm sum 84370\n",
      "br sum 73791\n",
      "bl sum 35663\n",
      "tr sum 40931\n",
      "tl sum 42273\n",
      "ucf sum 92566\n",
      "Total:  369594.0\n",
      "\n",
      "sums of transitions broad\n",
      "[[ 54.  21.  70.]\n",
      " [ 15.  70.  42.]\n",
      " [ 77.  34. 262.]]\n",
      "\n",
      "sums of transitions narrow\n",
      "[[ 54.  12.   9.  25.  45.]\n",
      " [  4.   6.  13.  10.  13.]\n",
      " [ 11.  14.  37.   8.  11.]\n",
      " [ 27.   3.  13. 161.  19.]\n",
      " [ 50.  10.   8.  19.  63.]]\n",
      "Total:  645.0\n",
      "\n",
      "Errors in transition matrix ((row_sums - column_sums) / 2)\n",
      "[-0.5  0.5  0.5  0.  -0.5]\n",
      "\n",
      "Error %%s in transition matrix ((row_sums - column_sums) *100 / (row_sums + column_sums))\n",
      "[-0.34364261  1.0989011   0.62111801  0.         -0.33222591]\n",
      "\n",
      "Transition matrix, broad\n",
      "[[ 8.37209302  3.25581395 10.85271318]\n",
      " [ 2.3255814  10.85271318  6.51162791]\n",
      " [11.9379845   5.27131783 40.62015504]]\n",
      "\n",
      "Transition matrix, narrow\n",
      "[[ 8.37209302  1.86046512  1.39534884  3.87596899  6.97674419]\n",
      " [ 0.62015504  0.93023256  2.01550388  1.5503876   2.01550388]\n",
      " [ 1.70542636  2.17054264  5.73643411  1.24031008  1.70542636]\n",
      " [ 4.18604651  0.46511628  2.01550388 24.96124031  2.94573643]\n",
      " [ 7.75193798  1.5503876   1.24031008  2.94573643  9.76744186]]\n",
      "100.0\n",
      "\n",
      "%s of transitions to states narrow:\n",
      "[22.63565891  6.97674419 12.40310078 34.57364341 23.41085271]\n",
      "\n",
      "%s of transitions from states narrow:\n",
      "[22.48062016  7.13178295 12.55813953 34.57364341 23.25581395]\n",
      "\n",
      "%s of transitions to states broad:\n",
      "[22.63565891 19.37984496 57.98449612]\n",
      "\n",
      "%s of transitions from states broad:\n",
      "[22.48062016 19.68992248 57.82945736]\n",
      "\n",
      "TRANSITION THRESHOLD  70\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "70",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-eaec4925b4e4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[1;31m#Top_bottoms, Full_classif, N_transitions = trans_runs[trans_fil]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m     \u001b[0mTop_bottoms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFull_classif\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mN_transitions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrans_threshes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_top_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_full_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_tran_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mskeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mckeys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_tran_keys\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_total_frames\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrans_runs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtrans_fil\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m     \u001b[0msums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m     \u001b[0mTb_sums\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0msums\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTop_bottoms\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_top_keys\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 70"
     ]
    }
   ],
   "source": [
    "trans_runs= np.load('trans_runs2.npy')[()]\n",
    "\"\"\"num_top_keys = 4\n",
    "num_full_keys = 6\n",
    "num_tran_keys = 5\n",
    "trans_threshes = [5, 8, 10, 19, 27, 38, 52, 60]\n",
    "sides = {\"bm\":[], \"b\":[], \"t\":[], \"ucf\":[]}\n",
    "classes = {\"bm\":[], \"br\":[], \"bl\":[], \"tr\":[], \"tl\":[], \"ucf\":[]}\n",
    "transitions = {\"bm->bm\" :[], \"bm->br\":[], \"bm->bl\":[], \"bm->tr\":[], \"bm->tl\":[],\n",
    "              \"br->bm\" :[], \"br->br\":[], \"br->bl\":[], \"br->tr\":[], \"br->tl\":[],\n",
    "              \"bl->bm\" :[], \"bl->br\":[], \"bl->bl\":[], \"bl->tr\":[], \"bl->tl\":[],\n",
    "              \"tr->bm\" :[], \"tr->br\":[], \"tr->bl\":[], \"tr->tr\":[], \"tr->tl\":[],\n",
    "              \"tl->bm\" :[], \"tl->br\":[], \"tl->bl\":[], \"tl->tr\":[], \"tl->tl\":[]}\"\"\"\n",
    "\n",
    "skeys = list(sides.keys())\n",
    "ckeys = list(classes.keys())\n",
    "for trans_fil in trans_threshes:\n",
    "    print(\"\\nTRANSITION THRESHOLD \", trans_fil)\n",
    "    \n",
    "    #Top_bottoms, Full_classif, N_transitions = trans_runs[trans_fil]\n",
    "    Top_bottoms, Full_classif, N_transitions, trans_threshes, num_top_keys, num_full_keys, num_tran_keys, skeys, ckeys, num_tran_keys, num_total_frames = trans_runs[trans_fil]\n",
    "    sums = np.sum\n",
    "    Tb_sums = [sums(Top_bottoms[:, c]) for c in range(num_top_keys)]\n",
    "    Fc_sums = [sums(Full_classif[:, c]) for c in range(num_full_keys)]\n",
    "    Nt_sums = sums(N_transitions, axis = 0)#[sums(N_transitions[:, c]) for c in range(nu   m_tran_keys)]\n",
    "    #print(\"\\nNumber of frames obbserved: \", num_total_frames)\n",
    "\n",
    "    Tb_percs = [Tb_sums[c] *100 /sums(Tb_sums) for c in range(num_top_keys)]\n",
    "    Fc_percs = [Fc_sums[c] *100/sums(Fc_sums) for c in range(num_full_keys)]\n",
    "    Nt_percs = Nt_sums *100/sums(Nt_sums)\n",
    "    #print(sums(N_transitions), sums(Nt_sums))\n",
    "\n",
    "\n",
    "    print(\"\\nsums in broad classifications\")\n",
    "    [print(skeys[i], \"sum %.f\" %Tb_sums[i]) for i in range(len(skeys))]\n",
    "    print(\"Total: \", sums(Tb_sums) )\n",
    "    print(\"\\nsums in narrow classifications\")\n",
    "    [print(ckeys[i], \"sum %.f\" %Fc_sums[i]) for i in range(len(ckeys))]\n",
    "    print(\"Total: \", sums(Fc_sums ) )\n",
    "    print(\"\\nsums of transitions broad\")\n",
    "    T_eb = np.vstack([Nt_sums[0], \n",
    "                                 (Nt_sums[1] + Nt_sums[2]) , \n",
    "                                 (Nt_sums[3] + Nt_sums[4])])\n",
    "    Nt_sums_broad = np.column_stack([T_eb[:, 0], \n",
    "                                 (T_eb[:, 1]+ T_eb[:, 2]), \n",
    "                                 (T_eb[:, 3]+ T_eb[:, 4])])\n",
    "    print(Nt_sums_broad)\n",
    "    print(\"\\nsums of transitions narrow\")\n",
    "    print(Nt_sums)\n",
    "    print(\"Total: \", sums(Nt_sums) )\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"print(\"\\n%s in broad classifications\")\n",
    "    [print(skeys[i], \" %.f%%\" %Tb_percs[i]) for i in range(len(skeys))]\n",
    "    print(\"\\n%s in narrow classifications\")\n",
    "    [print(ckeys[i], \" %.f%%\" %Fc_percs[i]) for i in range(len(ckeys))]\"\"\"\n",
    "    #ERROR ANALSIS HERE\n",
    "    print(\"\\nErrors in transition matrix ((row_sums - column_sums) / 2)\")\n",
    "    print(((sums(Nt_sums, axis = 1) - sums(Nt_sums, axis =0))/2))\n",
    "    print(\"\\nError %%s in transition matrix ((row_sums - column_sums) *100 / (row_sums + column_sums))\")\n",
    "    print(((sums(Nt_sums, axis = 1) - sums(Nt_sums, axis =0))*100 /(sums(Nt_sums, axis = 1) + sums(Nt_sums, axis =0))))\n",
    "    \n",
    "    print(\"\\nTransition matrix, broad\")\n",
    "    T_eb = np.vstack([Nt_percs[0], \n",
    "                                 (Nt_percs[1] + Nt_percs[2]) , \n",
    "                                 (Nt_percs[3] + Nt_percs[4])])\n",
    "    Nt_percs_broad = np.column_stack([T_eb[:, 0], \n",
    "                                 (T_eb[:, 1]+ T_eb[:, 2]), \n",
    "                                 (T_eb[:, 3]+ T_eb[:, 4])])\n",
    "    print(Nt_percs_broad)\n",
    "    \"\"\"print(\"row_sums of transitin matrix, broad\")\n",
    "    print(sums(Nt_percs_broad, axis = 1))\n",
    "    print(\"\\n%s of transitions broad(->bm, ->b, ->t):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 0)[0]*100/sums(Nt_sums), \n",
    "           (sums(Nt_sums, axis = 0)[1] + sums(Nt_sums, axis = 0)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 0)[3] + sums(Nt_sums, axis = 0)[4])*100/(sums(Nt_sums))])\n",
    "    print(\"\\n%s of transitions broad(bm->, b->, t->):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 1)[0]*100/sums(Nt_sums),\n",
    "           (sums(Nt_sums, axis = 1)[1] + sums(Nt_sums, axis = 1)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 1)[3] + sums(Nt_sums, axis =1)[4])*100/(sums(Nt_sums))])#(Nt_percs[i,1] + Nt_percs[i,1+1] + Nt_percs[i+1, 1] + Nt_percs[i+1, 1+1] + sums(Nt_percs[0, 1:3]))) for i in [1,3]]\n",
    "    \"\"\"\n",
    "    #print(\"->t %.f%%\" %(Nt_percs[i,2] + Nt_percs[i,2+1] + Nt_percs[i+1, 2] + Nt_percs[i+1, 2+1] + sums(Nt_percs[0, 3:5]))) for i in [1,3]]\n",
    "    print(\"\\nTransition matrix, narrow\")\n",
    "    print(Nt_percs)\n",
    "    print(sums(Nt_percs))\n",
    "    print(\"\\n%s of transitions to states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 0)*100/sums(Nt_percs))]\n",
    "    print(\"\\n%s of transitions from states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 1)*100/sums(Nt_percs))]\n",
    "    print(\"\\n%s of transitions to states broad:\")\n",
    "    [print(sums(Nt_percs_broad, axis = 0)*100/sums(Nt_percs_broad))]\n",
    "    print(\"\\n%s of transitions from states broad:\")\n",
    "    [print(sums(Nt_percs_broad, axis = 1)*100/sums(Nt_percs_broad))]\n",
    "    #print(\"\\n%s of transitions narrow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trans_runs= np.load('trans_runs1.npy')[()]\n",
    "\"\"\"num_top_keys = 4\n",
    "num_full_keys = 6\n",
    "num_tran_keys = 5\n",
    "trans_threshes = [5, 8, 10, 19, 27, 38, 52, 60]\n",
    "sides = {\"bm\":[], \"b\":[], \"t\":[], \"ucf\":[]}\n",
    "classes = {\"bm\":[], \"br\":[], \"bl\":[], \"tr\":[], \"tl\":[], \"ucf\":[]}\n",
    "transitions = {\"bm->bm\" :[], \"bm->br\":[], \"bm->bl\":[], \"bm->tr\":[], \"bm->tl\":[],\n",
    "              \"br->bm\" :[], \"br->br\":[], \"br->bl\":[], \"br->tr\":[], \"br->tl\":[],\n",
    "              \"bl->bm\" :[], \"bl->br\":[], \"bl->bl\":[], \"bl->tr\":[], \"bl->tl\":[],\n",
    "              \"tr->bm\" :[], \"tr->br\":[], \"tr->bl\":[], \"tr->tr\":[], \"tr->tl\":[],\n",
    "              \"tl->bm\" :[], \"tl->br\":[], \"tl->bl\":[], \"tl->tr\":[], \"tl->tl\":[]}\"\"\"\n",
    "\n",
    "skeys = list(sides.keys())\n",
    "ckeys = list(classes.keys())\n",
    "for trans_fil in trans_threshes:\n",
    "    print(\"\\nTRANSITION THRESHOLD \", trans_fil)\n",
    "    \n",
    "    #Top_bottoms, Full_classif, N_transitions = trans_runs[trans_fil]\n",
    "    Top_bottoms, Full_classif, N_transitions, trans_threshes, num_top_keys, num_full_keys, num_tran_keys, skeys, ckeys, num_tran_keys, num_total_frames = trans_runs[trans_fil]\n",
    "    sums = np.sum\n",
    "    Tb_sums = [sums(Top_bottoms[:, c]) for c in range(num_top_keys)]\n",
    "    Fc_sums = [sums(Full_classif[:, c]) for c in range(num_full_keys)]\n",
    "    Nt_sums = sums(N_transitions, axis = 0)#[sums(N_transitions[:, c]) for c in range(num_tran_keys)]\n",
    "    #print(\"\\nNumber of frames obbserved: \", num_total_frames)\n",
    "\n",
    "    Tb_percs = [Tb_sums[c] *100 /sums(Tb_sums) for c in range(num_top_keys)]\n",
    "    Fc_percs = [Fc_sums[c] *100/sums(Fc_sums) for c in range(num_full_keys)]\n",
    "    Nt_percs = Nt_sums *100/sums(Nt_sums)\n",
    "    #print(sums(N_transitions), sums(Nt_sums))\n",
    "\n",
    "\n",
    "    print(\"\\nsums in broad classifications\")\n",
    "    [print(skeys[i], \"sum %.f\" %Tb_sums[i]) for i in range(len(skeys))]\n",
    "    print(\"Total: \", sums(Tb_sums) )\n",
    "    print(\"\\nsums in narrow classifications\")\n",
    "    [print(ckeys[i], \"sum %.f\" %Fc_sums[i]) for i in range(len(ckeys))]\n",
    "    print(\"Total: \", sums(Fc_sums ) )\n",
    "    print(\"\\nsums of transitions broad\")\n",
    "    T_eb = np.vstack([Nt_sums[0], \n",
    "                                 (Nt_sums[1] + Nt_sums[2]) , \n",
    "                                 (Nt_sums[3] + Nt_sums[4])])\n",
    "    Nt_sums_broad = np.column_stack([T_eb[:, 0], \n",
    "                                 (T_eb[:, 1]+ T_eb[:, 2]), \n",
    "                                 (T_eb[:, 3]+ T_eb[:, 4])])\n",
    "    print(Nt_sums_broad)\n",
    "    print(\"\\nsums of transitions narrow\")\n",
    "    print(Nt_sums)\n",
    "    print(\"Total: \", sums(Nt_sums) )\n",
    "\n",
    "\n",
    "\n",
    "    \"\"\"print(\"\\n%s in broad classifications\")\n",
    "    [print(skeys[i], \" %.f%%\" %Tb_percs[i]) for i in range(len(skeys))]\n",
    "    print(\"\\n%s in narrow classifications\")\n",
    "    [print(ckeys[i], \" %.f%%\" %Fc_percs[i]) for i in range(len(ckeys))]\"\"\"\n",
    "    #ERROR ANALSIS HERE\n",
    "    print(\"Errors in transition matrix (row_sums - column_sums / 2)\")\n",
    "    print((sums(Nt_percs_broad, axis = 1) - sums(Nt_percs_broad, axis = 1) / 2))\n",
    "    \n",
    "    print(\"Transition matrix, broad\")\n",
    "    T_eb = np.vstack([Nt_percs[0], \n",
    "                                 (Nt_percs[1] + Nt_percs[2]) , \n",
    "                                 (Nt_percs[3] + Nt_percs[4])])\n",
    "    Nt_percs_broad = np.column_stack([T_eb[:, 0], \n",
    "                                 (T_eb[:, 1]+ T_eb[:, 2]), \n",
    "                                 (T_eb[:, 3]+ T_eb[:, 4])])\n",
    "    print(Nt_percs_broad)\n",
    "    print(\"row_sums of transitin matrix, broad\")\n",
    "    print(sums(Nt_percs_broad, axis = 1))\n",
    "    print(\"\\n%s of transitions broad(->bm, ->b, ->t):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 0)[0]*100/sums(Nt_sums), \n",
    "           (sums(Nt_sums, axis = 0)[1] + sums(Nt_sums, axis = 0)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 0)[3] + sums(Nt_sums, axis = 0)[4])*100/(sums(Nt_sums))])\n",
    "    print(\"\\n%s of transitions broad(bm->, b->, t->):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 1)[0]*100/sums(Nt_sums),\n",
    "           (sums(Nt_sums, axis = 1)[1] + sums(Nt_sums, axis = 1)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 1)[3] + sums(Nt_sums, axis =1)[4])*100/(sums(Nt_sums))])#(Nt_percs[i,1] + Nt_percs[i,1+1] + Nt_percs[i+1, 1] + Nt_percs[i+1, 1+1] + sums(Nt_percs[0, 1:3]))) for i in [1,3]]\n",
    "    #print(\"->t %.f%%\" %(Nt_percs[i,2] + Nt_percs[i,2+1] + Nt_percs[i+1, 2] + Nt_percs[i+1, 2+1] + sums(Nt_percs[0, 3:5]))) for i in [1,3]]\n",
    "    print(\"\\nTransition matrix, narrow\")\n",
    "    print(Nt_percs)\n",
    "    print(sums(Nt_percs))\n",
    "    print(\"\\n%s of transitions to states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 0)*100/sums(Nt_percs))]\n",
    "    print(\"\\n%s of transitions from states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 1)*100/sums(Nt_percs))]\n",
    "    #print(\"\\n%s of transitions narrow\")\n",
    "    #[print(tkeys[i], \" %.f%%\" %Nt_percs.flatten()[i]) for i in range(len(tkeys))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "trans_runs= np.load('trans_runs.npy')[()]\n",
    "num_top_keys = 4\n",
    "num_full_keys = 6\n",
    "num_tran_keys = 5\n",
    "trans_threshes = [5, 8, 10, 19, 27, 38, 52, 60]\n",
    "sides = {\"bm\":[], \"b\":[], \"t\":[], \"ucf\":[]}\n",
    "classes = {\"bm\":[], \"br\":[], \"bl\":[], \"tr\":[], \"tl\":[], \"ucf\":[]}\n",
    "transitions = {\"bm->bm\" :[], \"bm->br\":[], \"bm->bl\":[], \"bm->tr\":[], \"bm->tl\":[],\n",
    "              \"br->bm\" :[], \"br->br\":[], \"br->bl\":[], \"br->tr\":[], \"br->tl\":[],\n",
    "              \"bl->bm\" :[], \"bl->br\":[], \"bl->bl\":[], \"bl->tr\":[], \"bl->tl\":[],\n",
    "              \"tr->bm\" :[], \"tr->br\":[], \"tr->bl\":[], \"tr->tr\":[], \"tr->tl\":[],\n",
    "              \"tl->bm\" :[], \"tl->br\":[], \"tl->bl\":[], \"tl->tr\":[], \"tl->tl\":[]}\n",
    "\n",
    "skeys = list(sides.keys())\n",
    "ckeys = list(classes.keys())\n",
    "for trans_fil in trans_threshes:\n",
    "    print(\"\\nTRANSITION THRESHOLD \", trans_fil)\n",
    "    \n",
    "    Top_bottoms, Full_classif, N_transitions = trans_runs[trans_fil]\n",
    "    #Top_bottoms, Full_classif, N_transitions, trans_threshes, num_top_keys, num_full_keys,\n",
    "                             #num_tran_keys, skeys, ckeys, num_tran_keys, num_total_frames = trans_runs[trans_fil]\n",
    "    sums = np.sum\n",
    "    Tb_sums = [sums(Top_bottoms[:, c]) for c in range(num_top_keys)]\n",
    "    Fc_sums = [sums(Full_classif[:, c]) for c in range(num_full_keys)]\n",
    "    Nt_sums = sums(N_transitions, axis = 0)#[sums(N_transitions[:, c]) for c in range(num_tran_keys)]\n",
    "    #print(\"\\nNumber of frames obbserved: \", num_total_frames)\n",
    "\n",
    "    Tb_percs = [Tb_sums[c] *100 /sums(Tb_sums) for c in range(num_top_keys)]\n",
    "    Fc_percs = [Fc_sums[c] *100/sums(Fc_sums) for c in range(num_full_keys)]\n",
    "    Nt_percs = Nt_sums *100/sums(Nt_sums)\n",
    "    #print(sums(N_transitions), sums(Nt_sums))\n",
    "\n",
    "\n",
    "    print(\"\\nsums in broad classifications\")\n",
    "    [print(skeys[i], \"sum %.f\" %Tb_sums[i]) for i in range(len(skeys))]\n",
    "    print(\"Total: \", sums(Tb_sums) )\n",
    "    print(\"\\nsums in narrow classifications\")\n",
    "    [print(ckeys[i], \"sum %.f\" %Fc_sums[i]) for i in range(len(ckeys))]\n",
    "    print(\"Total: \", sums(Fc_sums ) )\n",
    "    print(\"\\nsums of transitions broad\")\n",
    "    T_eb = np.vstack([Nt_sums[0], \n",
    "                                 (Nt_sums[1] + Nt_sums[2]) , \n",
    "                                 (Nt_sums[3] + Nt_sums[4])])\n",
    "    Nt_sums_broad = np.column_stack([T_eb[:, 0], \n",
    "                                 (T_eb[:, 1]+ T_eb[:, 2]), \n",
    "                                 (T_eb[:, 3]+ T_eb[:, 4])])\n",
    "    print(Nt_sums_broad)\n",
    "    print(\"\\nsums of transitions narrow\")\n",
    "    print(Nt_sums)\n",
    "    print(\"Total: \", sums(Nt_sums) )\n",
    "\n",
    "\n",
    "\n",
    "    print(\"\\n%s in broad classifications\")\n",
    "    [print(skeys[i], \" %.f%%\" %Tb_percs[i]) for i in range(len(skeys))]\n",
    "    print(\"\\n%s in narrow classifications\")\n",
    "    [print(ckeys[i], \" %.f%%\" %Fc_percs[i]) for i in range(len(ckeys))]\n",
    "    print(\"Transition matrix, broad\")\n",
    "    T_eb = np.vstack([Nt_percs[0], \n",
    "                                 (Nt_percs[1] + Nt_percs[2]) , \n",
    "                                 (Nt_percs[3] + Nt_percs[4])])\n",
    "    Nt_percs_broad = np.column_stack([T_eb[:, 0], \n",
    "                                 (T_eb[:, 1]+ T_eb[:, 2]), \n",
    "                                 (T_eb[:, 3]+ T_eb[:, 4])])\n",
    "    print(Nt_percs_broad)\n",
    "    print(\"row_sums of transitin matrix, broad\")\n",
    "    print(sums(Nt_percs_broad, axis = 1))\n",
    "    print(\"\\n%s of transitions broad(->bm, ->b, ->t):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 0)[0]*100/sums(Nt_sums), \n",
    "           (sums(Nt_sums, axis = 0)[1] + sums(Nt_sums, axis = 0)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 0)[3] + sums(Nt_sums, axis = 0)[4])*100/(sums(Nt_sums))])\n",
    "    print(\"\\n%s of transitions broad(bm->, b->, t->):\")\n",
    "    #print(\"->bm %.f%%\" %(Nt_percs[0, 0] + sums(Nt_percs[1:3, 0]) + sums(Nt_percs[3:5, 0])))\n",
    "    print([sums(Nt_sums, axis = 1)[0]*100/sums(Nt_sums),\n",
    "           (sums(Nt_sums, axis = 1)[1] + sums(Nt_sums, axis = 1)[2])*100/(sums(Nt_sums)),\n",
    "           (sums(Nt_sums, axis = 1)[3] + sums(Nt_sums, axis =1)[4])*100/(sums(Nt_sums))])#(Nt_percs[i,1] + Nt_percs[i,1+1] + Nt_percs[i+1, 1] + Nt_percs[i+1, 1+1] + sums(Nt_percs[0, 1:3]))) for i in [1,3]]\n",
    "    #print(\"->t %.f%%\" %(Nt_percs[i,2] + Nt_percs[i,2+1] + Nt_percs[i+1, 2] + Nt_percs[i+1, 2+1] + sums(Nt_percs[0, 3:5]))) for i in [1,3]]\n",
    "    print(\"\\nTransition matrix, narrow\")\n",
    "    print(Nt_percs)\n",
    "    print(sums(Nt_percs))\n",
    "    print(\"\\n%s of transitions to states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 0)*100/sums(Nt_percs))]\n",
    "    print(\"\\n%s of transitions from states narrow:\")\n",
    "    [print(sums(Nt_percs, axis = 1)*100/sums(Nt_percs))]\n",
    "    #print(\"\\n%s of transitions narrow\")\n",
    "    #[print(tkeys[i], \" %.f%%\" %Nt_percs.flatten()[i]) for i in range(len(tkeys))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
