{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is video reader with all operations inside fnctions, so they can be called on \\n    each frame out of a set of frames, and each video out of a set of videos\\n    '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This is video reader with all operations inside fnctions, so they can be called on \n",
    "    each frame out of a set of frames, and each video out of a set of videos\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports\"\"\"\n",
    "import matplotlib.pyplot as plt #for maknig plots inside the notebook\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from skvideo.io import vread\n",
    "from skimage import measure\n",
    "from skimage.filters import threshold_yen, threshold_isodata\n",
    "from operator import attrgetter\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import chain\n",
    "#from functools import partial, update_wrapper\n",
    "from scipy import ndimage \n",
    "from pims import pipeline, Video\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "#import antigravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions\"\"\"\n",
    "# apply total thresholding to each of a list of frames; filter slides with wrong number\n",
    "def total_threshold_filter(framelist, trans_fil): \n",
    "    # returns a new list, different from the orginal\n",
    "    fll = len(framelist)\n",
    "    m_lab = measure.label\n",
    "    m_rop = measure.regionprops\n",
    "    \n",
    "    sides = {\"bm\":[], \"b\":[], \"t\":[], \"ucf\":[]}\n",
    "    classes = {\"bm\":[], \"br\":[], \"bl\":[], \"tr\":[], \"tl\":[], \"ucf\":[], \"newt\":[]}\n",
    "    transitions = {\"bm->bm\" :[], \"bm->br\":[], \"bm->bl\":[], \"bm->tr\":[], \"bm->tl\":[],\n",
    "                  \"br->bm\" :[], \"br->br\":[], \"br->bl\":[], \"br->tr\":[], \"br->tl\":[],\n",
    "                  \"bl->bm\" :[], \"bl->br\":[], \"bl->bl\":[], \"bl->tr\":[], \"bl->tl\":[],\n",
    "                  \"tr->bm\" :[], \"tr->br\":[], \"tr->bl\":[], \"tr->tr\":[], \"tr->tl\":[],\n",
    "                  \"tl->bm\" :[], \"tl->br\":[], \"tl->bl\":[], \"tl->tr\":[], \"tl->tl\":[]}\n",
    "    \n",
    "    transition_threshold = trans_fil\n",
    "    broken = 0\n",
    "    broken_count = 0\n",
    "    area_threshold = 1800   # must have enough particles\n",
    "    convex_thresholds = (2000, 2800)   # convex hull area (> 2500 filtered)  # particles must be in parallelogram\n",
    "    minor_thresholds = (38, 48) # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "    major_thresholds = (59, 76)\n",
    "    last_class = ''\n",
    "    last_whole = 0\n",
    "    filtrate_len = 0\n",
    "    \n",
    "    for i in range(fll):\n",
    "       # print(\"new_frame\")\n",
    "        frame = framelist[i]\n",
    "        thresh_img = frame > threshold_yen(frame) # binary image\n",
    "        img_labelled = m_lab(thresh_img) # contains connected regions\n",
    "        properties_list = m_rop(img_labelled, coordinates = 'rc') # data about regions, for each connected region\n",
    "        \n",
    "        #----------getting maximum connected region----------\n",
    "        biggest_r = max(properties_list, key = attrgetter('area'))\n",
    "        \"\"\" for k in range(len(properties_list)):\n",
    "            if areas[k] > biggest_area:\n",
    "                biggest_r = properties_list[k]\n",
    "            else:\n",
    "                pass\"\"\"\n",
    "\n",
    "        #----------------------filter------------------------- can use actual filter\n",
    "        test = (biggest_r.filled_area > area_threshold and   # must have enough particles\n",
    "            biggest_r.minor_axis_length > minor_thresholds[0] # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "            and biggest_r.minor_axis_length < minor_thresholds[1]  # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "            and biggest_r.convex_area > convex_thresholds[0]  # convex hull area (> 2500 filtered)  # particles must be in parallelogram\n",
    "            and biggest_r.convex_area < convex_thresholds[1]  # convex hull area (> 2500 filtered)  # particles must be in parallelogram\n",
    "            and biggest_r.major_axis_length > major_thresholds[0]  # major_axis length (< filterd) # particles must be in parallelogram\n",
    "            and biggest_r.major_axis_length < major_thresholds[1])  # major_axis length (< filterd) # particles must be in parallelogram\n",
    "        if test: # keep frames that have enough paricles, and are not transitions\n",
    "            i_threshed = frame > threshold_isodata(frame)\n",
    "            img2_labelled = m_lab(i_threshed)\n",
    "            properties2_list = m_rop(img2_labelled, coordinates = 'rc')\n",
    "            biggest_r2 = max(properties2_list, key = attrgetter('area'))\n",
    "            #-----------------------------classify pt 1---------------------------------------\n",
    "            coprod = coord_prod(thresh_img, i_threshed)\n",
    "            side = sideify(biggest_r2)\n",
    "            clas = classify(side, -coprod)\n",
    "            sides[side].append(i)\n",
    "            classes[clas].append(i)\n",
    "            if broken_count >= transition_threshold and side != 'ucf' and last_class not in ['', 'ucf', 'newt']: #if previous n frames were broken, and a transition between identifiableclasses ocurred\n",
    "                transitions[last_class + \"->\" + clas].append((last_whole, i))\n",
    "            broken = 0 #reset marker to not broken\n",
    "            broken_count = 0\n",
    "            last_class = clas\n",
    "            last_whole = i\n",
    "            filtrate_len += 1\n",
    "        else:\n",
    "            broken = 1 #set marker to broken\n",
    "            broken_count += 1\n",
    "\n",
    "    return [filtrate_len, sides, classes, transitions]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# take largest isodata image region, and return aclassification\n",
    "def sideify(idir):\n",
    "    iner = idir.inertia_tensor[0, 0] + idir.inertia_tensor[1, 1]\n",
    "    maal = idir.major_axis_length\n",
    "    mial = idir.minor_axis_length\n",
    "    sol = idir.solidity \n",
    "    ecc = idir.eccentricity\n",
    "    cva = idir.convex_area\n",
    "    if sol <= 0.725 or (iner> 405 and mial > 43.5): # sol <.72\n",
    "        return \"bm\"\n",
    "    elif ecc > 0.8 or maal > 65: # or (mial < 41 and maal > 65): # it's on top #ec >.82\n",
    "        return \"t\"\n",
    "    elif ecc < 0.75 or maal < 64.5: #or mial > 42  #and cva > 2200 and iner < 325: #or (maal < 64 and iner < 360): # it's on bottom\n",
    "        return \"b\"\n",
    "    else:\n",
    "        return \"ucf\"\n",
    "\n",
    "def classify(side, coprod):\n",
    "    if side == \"t\":\n",
    "        if coprod > 0:\n",
    "            return \"tl\"\n",
    "        else:\n",
    "            return \"tr\"\n",
    "    elif side == \"b\": \n",
    "        if coprod > 0:\n",
    "            return \"br\"\n",
    "        else:\n",
    "            return \"bl\"\n",
    "    elif side == \"bm\":\n",
    "        return \"bm\"\n",
    "    elif side == \"ucf\":\n",
    "        return \"ucf\"\n",
    "    else:\n",
    "        return \"newt\"\n",
    "\n",
    "\n",
    "def coord_prod(thresh_y, thresh_i):\n",
    "    m_rop = measure.regionprops\n",
    "    for i in range(0, 1):#len(fl):\n",
    "        full = largest_region_extractor(measure.label(thresh_y))\n",
    "        four = largest_region_extractor(measure.label(thresh_i))\n",
    "        full_or = m_rop(full.astype(int), coordinates = 'rc')[0].orientation\n",
    "        one_and_some = full^four\n",
    "        one = largest_region_extractor(measure.label(one_and_some))\n",
    "        \n",
    "          \n",
    "        #Begin finding substitue for major and minor axes herre\n",
    "        # use min and maax x and  values to find the geometric center\n",
    "        # or use those to substitue for eigenvectors \n",
    "        rotated_one = ndimage.rotate(one, math.degrees(-full_or), reshape = False)\n",
    "        rotated_full = ndimage.rotate(full, math.degrees(-full_or), reshape = False)\n",
    "        geo_cent = m_rop(rotated_full.astype(int), coordinates = 'rc')[0].bbox\n",
    "        #print(geo_cent)\n",
    "        ave = np.average\n",
    "        cent_x = ave([geo_cent[1], geo_cent[3]]) \n",
    "        cent_y = ave([geo_cent[0], geo_cent[2]])\n",
    "        #print(cent_x, cent_y)\n",
    "        \n",
    "        raw_coords = (m_rop(rotated_full.astype(int), coordinates = 'rc')[0].coords).T\n",
    "        ys = raw_coords[0]\n",
    "        xs = raw_coords[1]\n",
    "        x = xs - cent_x\n",
    "        y = ys - cent_y      \n",
    "        \n",
    "        one_com = m_rop(rotated_one.astype(int))[0].centroid\n",
    "        \n",
    "        rel_com_one = (one_com[1] - cent_x, one_com[0] - cent_y)\n",
    "        product = np.prod(rel_com_one)\n",
    "        return product\n",
    "        \n",
    "def rotate_point(point, angle):\n",
    "    x0 = point[0]\n",
    "    y0 = point[1]\n",
    "    x1 = x0*np.cos(angle) - y0*np.sin(angle)\n",
    "    y1 = x0*np.sin(angle) + y0*np.cos(angle)\n",
    "    return (x1, y1)\n",
    " \n",
    "def region_selector(labeled_image, label):\n",
    "    #print(label)\n",
    "    x = labeled_image == label\n",
    "    #plt.imshow(x)\n",
    "    return x\n",
    "\n",
    "# make a function that takes a set of labeled regions, and then  returns a boolean array containing only the largest\n",
    "def largest_region_extractor(labeled_regions_set):\n",
    "    props_lists = measure.regionprops(labeled_regions_set)\n",
    "    #print(len(labeled_regions_set), len(props_lists))\n",
    "    biggest_r_p = props_lists[0]\n",
    "    biggest_r_label = props_lists[0].label\n",
    "    for i in range(0, len(props_lists)):\n",
    "        pli = props_lists[i]\n",
    "        if pli.area > biggest_r_p.area:\n",
    "            biggest_r_p = pli\n",
    "            biggest_r_label = pli.label\n",
    "        else:\n",
    "            pass\n",
    "    return region_selector(labeled_regions_set, biggest_r_label)    \n",
    "#from pair of labelled, thresholded images, return an image category (of three)\n",
    "\n",
    "#from pair of labelled,thresholded images, return the x/y sign or x/y magnitude for the transparent dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./tchakamau/New_setup\\\\45621_10Vpp_22.avi', './tchakamau/New_setup\\\\45621_10Vpp_23.avi', './tchakamau/New_setup\\\\45681_10Vpp_24.avi', './tchakamau/New_setup\\\\45681_10Vpp_25.avi', './tchakamau/New_setup\\\\45681_10Vpp_26.avi', './tchakamau/New_setup\\\\45681_10Vpp_27.avi', './tchakamau/New_setup\\\\45701_10Vpp_18.avi', './tchakamau/New_setup\\\\45701_10Vpp_19.avi', './tchakamau/New_setup\\\\45701_10Vpp_20.avi', './tchakamau/New_setup\\\\45701_10Vpp_21.avi']\n",
      "Num files:  10\n",
      "read vid 0\n",
      "processing vid 0\n",
      "finished vid 0\n",
      "read vid 1\n",
      "processing vid 1\n",
      "finished vid 1\n",
      "read vid 2\n",
      "processing vid 2\n",
      "finished vid 2\n",
      "read vid 3\n",
      "processing vid 3\n",
      "finished vid 3\n",
      "read vid 4\n",
      "processing vid 4\n",
      "finished vid 4\n",
      "read vid 5\n",
      "processing vid 5\n",
      "finished vid 5\n",
      "read vid 6\n",
      "processing vid 6\n",
      "finished vid 6\n",
      "read vid 7\n",
      "processing vid 7\n",
      "finished vid 7\n",
      "read vid 8\n",
      "processing vid 8\n",
      "finished vid 8\n",
      "read vid 9\n",
      "processing vid 9\n",
      "finished vid 9\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Pipeline for lists of frames\"\"\"\n",
    "\"\"\"\"\"\"\n",
    "\"\"\"Pipeline for videos:\"\"\"\n",
    "# initialize frame lists\n",
    "filenames = glob(\"./tchakamau/New_setup/*[0-9].avi\")#glob(\"./tchakamau/New_setup/*[0-9]*filtered.avi\") + glob(\"./tchakamau/New_setup/*23.avi\")#[\"./tchakamau/New_setup/45681_10Vpp_25.avi\", \"./tchakamau/New_setup/45701_10Vpp_20.avi\"]#glob(\"./tchakamau/New_setup/*.avi\")#  #filenames = \n",
    "print(filenames)\n",
    "num_top_keys = 4\n",
    "num_full_keys = 7\n",
    "num_tran_keys = 5\n",
    "Top_bottoms = np.zeros((len(filenames), num_top_keys))\n",
    "Full_classif = np.zeros((len(filenames), num_full_keys))\n",
    "N_transitions = np.zeros((len(filenames), num_tran_keys, num_tran_keys))\n",
    "trans_fil = 10\n",
    "\n",
    "ave = np.average\n",
    "num_total_frames = 0    \n",
    "print(\"Num files: \", len(filenames))\n",
    "for vidnum in range(len(filenames)):\n",
    "    frames = vread(filenames[vidnum])\n",
    "    print(\"read vid %s\" %vidnum)\n",
    "    frame_vid = frames[:, :, :, 2]# making videos ino a frame list\n",
    "    num_total_frames += len(frame_vid)\n",
    "    print(\"processing vid %s\" %vidnum)\n",
    "    org = total_threshold_filter(frame_vid, trans_fil)\n",
    "    filtered_len = org[0]\n",
    "    sids = org[1]\n",
    "    cls = org[2]\n",
    "    tran = org[3]\n",
    "    #----------------------------------------------------------------\n",
    "    trans_len = len([y for x in tran.values() for y in x])\n",
    "    skeys = list(sids.keys())\n",
    "    ckeys = list(cls.keys())\n",
    "    tkeys = list(tran.keys())\n",
    "    slcs = [len(sids[x]) for x in skeys]\n",
    "    clcs = [len(cls[x]) for x in ckeys]\n",
    "    trans = [len(tran[x]) for x in tkeys]\n",
    "    ucf = len(sids[\"ucf\"])\n",
    "    newtucf = len(cls[\"newt\"]) + ucf\n",
    "\n",
    "\n",
    "\n",
    "    Top_bottoms[vidnum,:] = [slcs[i] for i in range(len(skeys))]\n",
    "    Full_classif[vidnum,:] = [clcs[i] for i in range(len(ckeys))]\n",
    "    N_transitions[vidnum,:] = np.reshape(trans, (num_tran_keys, num_tran_keys))\n",
    "    print(\"finished vid %s\" %vidnum)\n",
    "\n",
    "\n",
    "    \n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[11.  1.  1.  2.  8.]\n",
      "  [ 4. 18. 15.  4.  3.]\n",
      "  [ 2. 14. 15.  6.  5.]\n",
      "  [ 7.  2. 10.  3.  5.]\n",
      "  [ 4.  7.  5.  2.  2.]]\n",
      "\n",
      " [[ 2.  2.  0.  1.  0.]\n",
      "  [ 2.  7.  4.  0.  0.]\n",
      "  [ 3.  5.  6.  5.  2.]\n",
      "  [ 3.  2.  7.  2.  2.]\n",
      "  [ 1.  1.  2.  2.  3.]]\n",
      "\n",
      " [[ 3.  0.  1.  2.  0.]\n",
      "  [ 3.  1.  0.  1.  2.]\n",
      "  [ 0.  0.  3.  0.  1.]\n",
      "  [ 4.  0.  0.  5.  3.]\n",
      "  [ 4.  0.  3.  0.  1.]]\n",
      "\n",
      " [[ 2.  0.  0.  0.  2.]\n",
      "  [ 1.  1.  1.  1.  0.]\n",
      "  [ 0.  3.  2.  2.  1.]\n",
      "  [ 2.  0.  0.  3.  0.]\n",
      "  [ 0.  1.  2.  2.  1.]]\n",
      "\n",
      " [[ 0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.]\n",
      "  [ 0.  0.  0.  0.  0.]]]\n"
     ]
    }
   ],
   "source": [
    "print(N_transitions[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of frames obbserved:  493015\n",
      "\n",
      "sums in broad classifications\n",
      "bm sum 70883\n",
      "b sum 120079\n",
      "t sum 176777\n",
      "ucf sum 1855\n",
      "Total:  369594.0\n",
      "\n",
      "sums in narrow classifications\n",
      "bm sum 70883\n",
      "br sum 78820\n",
      "bl sum 41259\n",
      "tr sum 86994\n",
      "tl sum 89783\n",
      "ucf sum 1855\n",
      "newt sum 0\n",
      "Total:  369594.0\n",
      "\n",
      "sums of transitions\n",
      "[[86. 14. 15. 30. 32.]\n",
      " [39. 75. 71. 39. 21.]\n",
      " [23. 64. 90. 34. 33.]\n",
      " [49. 22. 41. 46. 42.]\n",
      " [44. 29. 31. 35. 55.]]\n",
      "Total:  1060.0\n",
      "\n",
      "%s in broad classifications\n",
      "bm  19%\n",
      "b  32%\n",
      "t  48%\n",
      "ucf  1%\n",
      "\n",
      "%s in narrow classifications\n",
      "bm  19%\n",
      "br  21%\n",
      "bl  11%\n",
      "tr  24%\n",
      "tl  24%\n",
      "ucf  1%\n",
      "newt  0%\n",
      "Transition matrix, broad\n",
      "[[ 8.  3.  6.]\n",
      " [ 6. 28. 12.]\n",
      " [ 9. 12. 17.]]\n",
      "row_sums of transitin matrix, broad\n",
      "[16.69811321 46.13207547 37.16981132]\n",
      "\n",
      "%s of transitions broad:\n",
      "bm->bm 8%\n",
      "b->bm 6%\n",
      "t->bm 9%\n",
      "bm->b 3%\n",
      "bm->t 6%\n",
      "b->b 28%\n",
      "b->t 12%\n",
      "t->b 12%\n",
      "t->t 17%\n",
      "\n",
      "Transition matrix, narrow\n",
      "[[8. 1. 1. 3. 3.]\n",
      " [4. 7. 7. 4. 2.]\n",
      " [2. 6. 8. 3. 3.]\n",
      " [5. 2. 4. 4. 4.]\n",
      " [4. 3. 3. 3. 5.]]\n",
      "100.0\n",
      "\n",
      "%s of transitions narrow\n",
      "bm->bm  8%\n",
      "bm->br  1%\n",
      "bm->bl  1%\n",
      "bm->tr  3%\n",
      "bm->tl  3%\n",
      "br->bm  4%\n",
      "br->br  7%\n",
      "br->bl  7%\n",
      "br->tr  4%\n",
      "br->tl  2%\n",
      "bl->bm  2%\n",
      "bl->br  6%\n",
      "bl->bl  8%\n",
      "bl->tr  3%\n",
      "bl->tl  3%\n",
      "tr->bm  5%\n",
      "tr->br  2%\n",
      "tr->bl  4%\n",
      "tr->tr  4%\n",
      "tr->tl  4%\n",
      "tl->bm  4%\n",
      "tl->br  3%\n",
      "tl->bl  3%\n",
      "tl->tr  3%\n",
      "tl->tl  5%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None,\n",
       " None]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\"\"\"Print average values (wuth column labels from slcs, clcs, trans) for rows of the array\"\"\"\n",
    "var = np.var\n",
    "sums = np.sum\n",
    "Tb_sums = [sums(Top_bottoms[:, c]) for c in range(num_top_keys)]\n",
    "Fc_sums = [sums(Full_classif[:, c]) for c in range(num_full_keys)]\n",
    "Nt_sums = sums(N_transitions, axis = 0)#[sums(N_transitions[:, c]) for c in range(num_tran_keys)]\n",
    "print(\"\\nNumber of frames obbserved: \", num_total_frames)\n",
    "\n",
    "Tb_percs = [Tb_sums[c] *100 /sum(Tb_sums) for c in range(num_top_keys)]\n",
    "Fc_percs = [Fc_sums[c] *100/sum(Fc_sums) for c in range(num_full_keys)]\n",
    "Nt_percs = Nt_sums *100/sums(Nt_sums)\n",
    "#print(sums(N_transitions), sums(Nt_sums))\n",
    "\n",
    "\n",
    "print(\"\\nsums in broad classifications\")\n",
    "[print(skeys[i], \"sum %.f\" %Tb_sums[i]) for i in range(len(skeys))]\n",
    "print(\"Total: \", sum(Tb_sums) )\n",
    "print(\"\\nsums in narrow classifications\")\n",
    "[print(ckeys[i], \"sum %.f\" %Fc_sums[i]) for i in range(len(ckeys))]\n",
    "print(\"Total: \", sum(Fc_sums ) )\n",
    "print(\"\\nsums of transitions\")\n",
    "print(Nt_sums)\n",
    "print(\"Total: \", sums(Nt_sums) )\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\n%s in broad classifications\")\n",
    "[print(skeys[i], \" %.f%%\" %Tb_percs[i]) for i in range(len(skeys))]\n",
    "print(\"\\n%s in narrow classifications\")\n",
    "[print(ckeys[i], \" %.f%%\" %Fc_percs[i]) for i in range(len(ckeys))]\n",
    "print(\"Transition matrix, broad\")\n",
    "T_eb = np.vstack([Nt_percs[0], \n",
    "                             (Nt_percs[1] + Nt_percs[2]) , \n",
    "                             (Nt_percs[3] + Nt_percs[4])])\n",
    "Nt_percs_broad = np.column_stack([T_eb[:, 0], \n",
    "                             (T_eb[:, 1]+ T_eb[:, 2]), \n",
    "                             (T_eb[:, 3]+ T_eb[:, 4])])\n",
    "print(Nt_percs_broad)\n",
    "print(\"row_sums of transitin matrix, broad\")\n",
    "print(sums(Nt_percs_broad, axis = 1))\n",
    "print(\"\\n%s of transitions broad:\")\n",
    "print(\"bm->bm %.f%%\" %Nt_percs[0, 0])\n",
    "print(\"b->bm %.f%%\" %sums(Nt_percs[1:3, 0]))\n",
    "print(\"t->bm %.f%%\" %sums(Nt_percs[3:5, 0]))\n",
    "print(\"bm->b %.f%%\" %sums(Nt_percs[0, 1:3]))\n",
    "print(\"bm->t %.f%%\" %sums(Nt_percs[0, 3:5]))\n",
    "[print(skeys[int(np.ceil(i/2))]+\"->\"+ skeys[int(np.ceil(j/2))], \"%.f%%\" %(Nt_percs[i,j] + Nt_percs[i,j+1] + Nt_percs[i+1, j] + Nt_percs[i+1, j+1])) \n",
    " for i in [1,3] for j in [1,3]]\n",
    "print(\"\\nTransition matrix, narrow\")\n",
    "print(Nt_percs)\n",
    "print(sums(Nt_percs))\n",
    "print(\"\\n%s of transitions narrow\")\n",
    "[print(tkeys[i], \" %.f%%\" %Nt_percs.flatten()[i]) for i in range(len(tkeys))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
