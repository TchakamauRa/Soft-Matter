{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the one which analyses the videos. It takes the videos and provides a text file containing matices for the transitions and transition times for all the videos.\n",
    "\n",
    "This version is good for when there is a majority of one particle type. When the two are even, there has to be an account fro mixed bonding so the code's a little different. Remember though to set all the variables in the final block of code according to the actual data you took. These are the 'bond lenghts', and they are inferred from a sample of videos using the 'shape testing' code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports\"\"\"\n",
    "import matplotlib.pyplot as plt #for maknig plots inside the notebook\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from skvideo.io import vreader, ffprobe\n",
    "from skimage import measure, morphology, feature\n",
    "from skimage.filters import *\n",
    "from skimage.morphology import *\n",
    "from operator import attrgetter\n",
    "import numpy as np\n",
    "import math\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict \n",
    "\n",
    "blob_doh = skimage.feature.blob_doh\n",
    "blob_dog = skimage.feature.blob_dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block processes single frames. It is written for the 3-styrene ('glas'), 1-polyethylene ('plas') case. To adapt this code for another case, like having three ethylene, replace 'glas on glas' (styrene-styrene bonding) with 'plas on plas', and swap out 'plas' and 'glas' for each other everywhere. 'glas' is, in this code, whichever is the most frequent type, and 'plas' is the material of which there is only one particle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions\"\"\"\n",
    "# This does most of the work. \n",
    "# It takes in a single frame and classifies the raft of particles in it as one of the epected shapes \n",
    "# or as unclassified, which here includes broken rafts (particles which are not in a complete raft of 4)\n",
    "# and also mis-shapen rafts, such as rafts with a gap in the middle if it'sbig enough, and rafts that are ambiguous to the program\n",
    "def total_threshold_filter(frame, frame_no, transition_threshold, class_thresh,\n",
    "                           broken_count, class_num, origin, last_class, last_whole, state_start, filtrate_len, \n",
    "                           classes, transitions, times): \n",
    "    \n",
    "   \n",
    "   # ---detect blobs ----------------\n",
    "    thresh_img = frame > threshold_isodata(frame)# binary image\n",
    "        \n",
    "    # The ethylene blobs\n",
    "    phighlight = binary_opening(thresh_img, square(14))\n",
    "    img = np.copy(frame)\n",
    "    img[phighlight==0] = 0\n",
    "    pblobs =blob_doh(img, min_sigma = 10, max_sigma = 16, threshold = 0.007, num_sigma= 15, overlap=0.6)\n",
    "    \n",
    "    # The styrene blobs\n",
    "    ghighlight = opening(\n",
    "        white_tophat(gaussian(thresh_img, sigma=0.2), square(14)),\n",
    "                                   disk(4))\n",
    "    img = np.copy(frame)\n",
    "    img[ghighlight==0] = 0\n",
    "    gblobs =blob_dog(img, min_sigma = 8, max_sigma = 12, threshold = 0.2, overlap=0.5)\n",
    "    gblobs[:, 2] = gblobs[:, 2] * np.sqrt(2)\n",
    "\n",
    "    # The number of each blob\n",
    "    ngblobs = len(gblobs)\n",
    "    npblobs = len(pblobs) \n",
    "    num_blobs = ngblobs + npblobs\n",
    "    \n",
    "    # These two collect the number of bonds there are, between ethylene balls and betwee ethylene and styrene balls\n",
    "    plas_on_glas_dists =[connect((pblob[1], pblob[0]),m_bond, gblobs) for pblob in pblobs] #mixed bonding\n",
    "    num_mconnections = reducer(plas_on_glas_dists)\n",
    "\n",
    "\n",
    "    glas_on_glas_dists =[connect((gblobs[i][1], gblobs[i][0]),g_bond, gblobs[i+1:]) for i in range(ngblobs-1)] # same type bonding\n",
    "    num_gconnections = reducer(glas_on_glas_dists)\n",
    "\n",
    "\n",
    "\n",
    "    num_connections = sum([num_gconnections,num_mconnections])\n",
    "    \n",
    "    # keep frames that have enough paricles, with enough connectivity to be a bonded raft\n",
    "    #        Sometimes the junk reflections from the transducer make extra blobs, hence the '>'\n",
    "    test = (num_connections >= expected_connections and num_blobs>=expected_blobs)\n",
    "    \n",
    "    if test:\n",
    "        clas =sideify(num_gconnections, num_mconnections ) \n",
    "        classes[clas]+=1  # count 1 instance of this shape\n",
    "        \n",
    "        if clas == 'ucf': # unclassifiable\n",
    "            pass\n",
    "        else:\n",
    "            if origin == 'ucf': #saety in case video starts on a broken frame\n",
    "                origin = last_class\n",
    "            if clas == last_class: # if the raft has kept its shape since last frame\n",
    "                class_num += 1\n",
    "            else:\n",
    "                class_num = 0 # reset the stability counter\n",
    "                \n",
    "            # If the raft has been stable for longer than the stability threshold in its current state\n",
    "            if class_num >= class_thresh: \n",
    "                # If the raft was broken for longer than the broken threshold before attaining this state\n",
    "                # or if current state is not the same as the previous stable state,\n",
    "                # record a transition under the appropriate key in the dictionary\n",
    "                # and record the three measures of transition time in their dictionary\n",
    "                if broken_count >= transition_threshold or clas != origin:\n",
    "                    transitions[origin + \"->\" + clas]+=1\n",
    "                    \n",
    "                    between_time = frame_no - state_start                               \n",
    "                    times[origin + \"->\" + clas][0].append(between_time)  \n",
    "\n",
    "                    stable_time = last_whole - state_start\n",
    "                    times[origin + \"->\" + clas][1].append(stable_time)\n",
    "\n",
    "                    unstable_time = frame_no - last_whole                      \n",
    "                    times[origin + \"->\" + clas][2].append(unstable_time)\n",
    "                \n",
    "                    state_start = frame_no # the start of a new state, this state\n",
    "                    \n",
    "                    origin = clas # reset the 'previous state' label to this state\n",
    "                    \n",
    "                broken_count = 0 # since the raft is now stable, reset the time for which it has been broken\n",
    "                last_whole = frame_no # and update the last recorded stable frame to this one\n",
    "                \n",
    "            filtrate_len += 1 # this is the number of frames which were classifiable, and it's not used afterwards\n",
    "            last_class = clas\n",
    "            \n",
    "            \n",
    "    else:\n",
    "        class_num = 0 # if it's not a well-formed raft, reset the sability counter\n",
    "        broken_count += 1 # and update the time for which it's been broken\n",
    "\n",
    "    return [broken_count, class_num, origin, last_class, last_whole,state_start, filtrate_len]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# This is the shape classifier\n",
    "def sideify( num_gconnections, num_mconnections):    \n",
    "    if num_mconnections == 2 and num_gconnections ==3:# and num_mconnections==4: #gtotallengths>48\n",
    "        return \"t\"\n",
    "    elif num_mconnections == 3 and num_gconnections ==2:# and num_mconnections == 4:\n",
    "        return \"c\"\n",
    "    else:\n",
    "        return \"ucf\"\n",
    "\n",
    "# just a summer\n",
    "def reducer(connections):\n",
    "    return sum(connections) \n",
    "\n",
    "# given a focal point, a radiuus of connectiity, and a list of other circles\n",
    "# determine which of a list of them it is connected to\n",
    "def connect(cv, radius, bloblist): \n",
    "    num_connections = 0\n",
    "    for blob2 in bloblist:\n",
    "        cv2 = (blob2[1], blob2[0]) # center of blob2\n",
    "        vector_d = vector_dist(cv, cv2)\n",
    "        if vector_d <= 2*radius and vector_d > .2*radius: # blob centers closer than diameter of one blob\n",
    "            num_connections += 1\n",
    "        else:\n",
    "            pass\n",
    "    return (num_connections)\n",
    "\n",
    "def vector_dist(v1, v2): # euclidean distance between 2 points\n",
    "    return math.sqrt(np.sum([(v1[i] - v2[i])**2 for i in range(len(v1))]))\n",
    "\n",
    "def third_item(l1):\n",
    "    return l1[2]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block applies the previous code to every frame, and every video. Intermediate results are printed. Typically, I copy the printed tet into a text file myself, and that is how the other programs I have written expect it to be presented. I do save the results to a file for safekeeping; however it is in a different format and I don't read from it any longer. You could modiy this code to write directly the displayed text to a save file in its current format, or modify the Mari Multiplication code to read from the saved file's set of arrays instead, for a change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Number files:  0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ckeys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-fb9b0bdbaeeb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     92\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     93\u001b[0m         trans_runs[index] = [[Full_classif, (N_transitions, T_transitions), (trans_fil, class_thresh), num_full_keys,\n\u001b[1;32m---> 94\u001b[1;33m                                  num_tran_keys, ckeys, num_total_frames], params]\n\u001b[0m\u001b[0;32m     95\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     96\u001b[0m         \u001b[1;31m#---------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ckeys' is not defined"
     ]
    }
   ],
   "source": [
    "filenames = glob(\"./tchakamau/De*styrene/*[0-9].avi\") # all the video data \n",
    "filenames.sort() # want to go through them in a reproducible order in case we have to restart halfway through\n",
    "print(filenames)\n",
    "num_top_keys = 3 # number of states plus 'unlclassified'\n",
    "num_full_keys = 3\n",
    "num_tran_keys = 2 # number of states\n",
    "num_lengths = 3 # number of measures of transition time\n",
    "trans_threshes = np.linspace(30, 60, 2) # Place the transition thesholds you would like to use here\n",
    "class_threshes =[20,30] # and the stability thresholds you want; every combination of these is done\n",
    "trans_runs = {} # this is the dictionary holding the results\n",
    "\n",
    "# this is a list of parameters custom chosen for this data using 'shape testing'\n",
    "ave = np.average\n",
    "expected_blobs = 4 # number of particles to a raft\n",
    "expected_connections = 5 # number of bonds in a raft\n",
    "g_bond = 15*1 # glass bonding distance cutoff\n",
    "m_bond = 15*1.15 # mixed bonding cutoff\n",
    "\n",
    "\n",
    "params = [expected_blobs , expected_connections, g_bond, m_bond] # stores the key parameters in the save file to document the run\n",
    "\n",
    "print(\"Number files: \", len(filenames))\n",
    "\n",
    "# Let's get started\n",
    "index = 0 # count the number of threshold pairs \n",
    "for trans_fil in trans_threshes:     \n",
    "    for class_thresh in class_threshes:\n",
    "        \n",
    "        Full_classif = np.zeros((len(filenames), num_full_keys)) # empty array for the no. frames spent in each state\n",
    "        N_transitions = np.zeros((len(filenames), num_tran_keys, num_tran_keys)) # and for the transitions in this video\n",
    "        T_transitions = [[[[[] for i in range(num_tran_keys)] for j in range(num_tran_keys)] for k in range(num_lengths)] \n",
    "                          for l in range(len(filenames))] # and a list for the times\n",
    "        num_total_frames = 0 \n",
    "        filtrate_len = 0\n",
    "        for vidnum in range(len(filenames)):\n",
    "            print(\"Processing vid %s : %s\" %(vidnum, filenames[vidnum]))\n",
    "            frames = vreader(filenames[vidnum]) # does not load whole video\n",
    "            # makes an object to load single frames at a time later\n",
    "\n",
    "            # Every video collects the results into these dictionaries, and pass them onto the arrays when the video ends\n",
    "            classes = [(\"t\",0), (\"c\",0), (\"ucf\",0)]\n",
    "            transitions = [(\"t->t\",0), (\"t->c\",0),\n",
    "                          (\"c->t\" ,0), (\"c->c\",0)]\n",
    "            times = [(\"t->t\",[[] for i in range(num_lengths)]), (\"t->c\",[[] for i in range(num_lengths)]),\n",
    "                          (\"c->t\" ,[[] for i in range(num_lengths)]), (\"c->c\",[[] for i in range(num_lengths)])]\n",
    "            transitions = OrderedDict(transitions)\n",
    "            times = OrderedDict(times)            \n",
    "            classes = OrderedDict(classes)\n",
    "            \n",
    "            # all these are updated frame by frame \n",
    "            broken_count = 0\n",
    "            class_num = 0\n",
    "            origin = 'ucf'\n",
    "            last_class = 'ucf'\n",
    "            last_whole = 0\n",
    "            state_start = 0\n",
    "            frame_no = 0\n",
    "            \n",
    "            # And we call every frame now\n",
    "            for fr in frames:\n",
    "                frame = fr[:, :, 2] # take only the green channel for greyscale\n",
    "                frame_no += 1\n",
    "                num_total_frames += 1\n",
    "                # call our classifying function, and use it to update our parameters\n",
    "                org = total_threshold_filter(frame, frame_no, trans_fil, class_thresh,\n",
    "                                             broken_count, class_num, origin, last_class, last_whole, state_start, filtrate_len, \n",
    "                                              classes, transitions, times)\n",
    "                broken_count, class_num, origin, last_class, last_whole, state_start, filtrate_len = org\n",
    "            \n",
    "            #-------Sort the results out from this video and add to the collector arrays/lists------------------\n",
    "            ckeys = list(classes.keys())\n",
    "            clcs = [classes[x] for x in ckeys] # list of frame nums per class\n",
    "            \n",
    "            tkeys = list(times.keys())\n",
    "            tims = [times[x] for x in tkeys]\n",
    "            \n",
    "            trkeys = list(transitions.keys())\n",
    "            trans = [transitions[x] for x in trkeys] # num of each transition\n",
    "\n",
    "            \n",
    "            Full_classif[vidnum,:] = clcs\n",
    "            N_transitions[vidnum,:] = np.reshape(trans, (num_tran_keys, num_tran_keys))             \n",
    "            T_transitions[vidnum] = np.moveaxis(np.reshape(tims, (num_tran_keys, num_tran_keys,num_lengths)),\n",
    "                                                  [0,1,2], [1,2,0])\n",
    "            \n",
    "            # So we all follow along (and can collect results if it ends early)\n",
    "            print(\"T threshold: %s\" %trans_fil)\n",
    "            print(\"C threshold: %s\" %class_thresh)\n",
    "            print(N_transitions[vidnum,:])\n",
    "            print(T_transitions[vidnum])\n",
    "            print(Full_classif[vidnum,:])\n",
    "            \n",
    "        trans_runs[index] = [[Full_classif, (N_transitions, T_transitions), (trans_fil, class_thresh), num_full_keys,\n",
    "                                 num_tran_keys, ckeys, num_total_frames], params]\n",
    "        index += 1\n",
    "        #---------------------------------------------------------------------------------\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "np.save('your_favourite_filename.npy',trans_runs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
