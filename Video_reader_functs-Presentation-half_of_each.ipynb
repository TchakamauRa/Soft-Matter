{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is the one which analyses the videos. It takes the videos and provides a text file containing matices for the transitions and transition times for all the videos.\n",
    "Remember though to set all the variables like fp_bond and the variables inside blob_doh, etc according to the actual data you took. These 'bond lenghts', are to be inferred from a sample of videos using the 'shape testing' code, and the variables in the blob detection functions are to come from the shape_testing code, which shows how good they are at picking out the particles from the video. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports\"\"\"\n",
    "import matplotlib.pyplot as plt #for maknig plots inside the notebook\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from skvideo.io import vreader, ffprobe\n",
    "from skimage import measure, morphology, feature\n",
    "from skimage.filters import *\n",
    "from skimage.morphology import *\n",
    "from operator import attrgetter\n",
    "import numpy as np\n",
    "import math\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "from collections import OrderedDict \n",
    "\n",
    "blob_doh = skimage.feature.blob_doh\n",
    "blob_dog = skimage.feature.blob_dog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block processes single frames. It is written for the 2-styrene ('glas'), 2-polyethylene ('plas') case. To adapt this code for another case, where there are all three types of bonds (g-g, p-p, p-g), you'll have to figure out which of those bonds you need to measure to classify particles. I've chosen to use only p-p and g-g bonds as they're easier to measure, and to use two lengths. One is a long distance 'bond', representing the longest lengths on the raft. All four particles should read as 'connected' within this lenght to all the rest, unless the raft is broken. The shorter distance corresponds to two particles which are acually touching, and so are 'bonded' in the way we care about for this 'bond strength' testing experiment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions\"\"\"\n",
    "# This does most of the work. \n",
    "# It takes in a single frame and classifies the raft of particles in it as one of the epected shapes \n",
    "# or as unclassified, which here includes broken rafts (particles which are not in a complete raft of 4)\n",
    "# and also mis-shapen rafts, such as rafts with a gap in the middle if it'sbig enough, and rafts that are ambiguous to the program\n",
    "def total_threshold_filter(frame, frame_no, transition_threshold, class_thresh,\n",
    "                           broken_count, class_num, origin, last_class, last_whole, state_start, filtrate_len, \n",
    "                           classes, transitions, times): \n",
    "    \n",
    "   \n",
    "   # ---detect blobs ----------------\n",
    "    thresh_img = frame > threshold_isodata(frame)# binary image\n",
    "        \n",
    "    # The ethylene blobs\n",
    "    phighlight = binary_opening(thresh_img, square(14))\n",
    "    img = np.copy(frame)\n",
    "    img[phighlight==0] = 0\n",
    "    pblobs =blob_doh(img, min_sigma =8, max_sigma = 17, threshold = 0.007, num_sigma= 15, overlap=0.5)\n",
    "    \n",
    "    # The styrene blobs\n",
    "    ghighlight = gaussian(\n",
    "        opening(\n",
    "             (thresh_img^phighlight)\n",
    "                           , disk(1)), sigma = 0.65)\n",
    "    img = np.copy(frame)\n",
    "    img[ghighlight==0] = 0\n",
    "    gblobs = blob_doh(img, min_sigma =9, max_sigma = 16, threshold = 0.005, num_sigma= 15, overlap=0.2)\n",
    "    \n",
    "\n",
    "    # The number of each blob\n",
    "    ngblobs = len(gblobs)\n",
    "    npblobs = len(pblobs) \n",
    "    num_blobs = ngblobs + npblobs\n",
    "    \n",
    "    # These two collect the number of bonds there are, between styrene balls, and betwen polyethylene balls respectively\n",
    "    glas_on_glas_dists =np.array([connect((gblobs[i][1], gblobs[i][0]),(g_bond, fg_bond), gblobs[i+1:]) for i in range(ngblobs-1)])\n",
    "    num_gconnections, num_fgconnections = reducer(glas_on_glas_dists)\n",
    "\n",
    "    plas_on_plas_dists = np.array([connect((pblobs[i][1], pblobs[i][0]),(p_bond, fp_bond), pblobs[i+1:]) for i in range(npblobs-1)])\n",
    "    num_pconnections, num_fpconnections = reducer(plas_on_plas_dists)\n",
    "\n",
    "\n",
    "    num_connections = sum([num_pconnections, num_gconnections])\n",
    "    \n",
    "    # this algorithm doesn't feature an initial test for historical reasons and becuase it works this way too\n",
    "    clas =sideify(num_pconnections,num_gconnections, num_fpconnections, num_fgconnections ) # find what shape it is\n",
    "    classes[clas]+=1  # count 1 instance of this shape\n",
    "\n",
    "    if clas == 'ucf': # unclassifiable        \n",
    "        broken_count += 1 # if we can't classify the raft it must be broken\n",
    "        class_num = 0 # and therefore not in a particular state anymore\n",
    "    else:\n",
    "        if origin == 'ucf': #safety in case video starts on a broken frame: set the origin to this new frame instead\n",
    "            origin = last_class\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "        if clas == last_class: # if the raft has kept its shape since last frame\n",
    "            class_num += 1\n",
    "        else:\n",
    "            class_num = 0 # reset the stability counter\n",
    "\n",
    "        # If the raft has been stable for longer than the stability threshold in its current state\n",
    "        if class_num >= class_thresh: \n",
    "            # If the raft was broken for longer than the broken threshold before attaining this state\n",
    "            # or if current state is not the same as the previous stable state,\n",
    "            # record a transition under the appropriate key in the dictionary\n",
    "            # and record the three measures of transition time in their dictionary\n",
    "            if broken_count >= transition_threshold or clas != origin:\n",
    "                transitions[origin + \"->\" + clas]+=1\n",
    "\n",
    "                between_time = frame_no - state_start                               \n",
    "                times[origin + \"->\" + clas][0].append(between_time)  \n",
    "\n",
    "                stable_time = last_whole - state_start\n",
    "                times[origin + \"->\" + clas][1].append(stable_time)\n",
    "\n",
    "                unstable_time = frame_no - last_whole                      \n",
    "                times[origin + \"->\" + clas][2].append(unstable_time)\n",
    "\n",
    "                state_start = frame_no # the start of a new state, this state\n",
    "\n",
    "                origin = clas # reset the 'previous state' label to this state\n",
    "\n",
    "            broken_count = 0 # since the raft is now stable, reset the time for which it has been broken\n",
    "            last_whole = frame_no # and update the last recorded stable frame to this one\n",
    "        else:\n",
    "            pass\n",
    "\n",
    "        filtrate_len += 1 # this is the number of frames which were classifiable, and it's not used afterwards\n",
    "        last_class = clas\n",
    "            \n",
    "     \n",
    "\n",
    "    return [broken_count, class_num, origin, last_class, last_whole,state_start, filtrate_len]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# This is the shape classifier\n",
    "def sideify(num_pconnections, num_gconnections, num_fpconnections, num_fgconnections):\n",
    "    if num_fpconnections + num_fgconnections < 2:\n",
    "        return \"ucf\"\n",
    "    elif num_pconnections == 1 and num_gconnections ==0:# plastic-touches\n",
    "        return \"p\"\n",
    "    elif num_pconnections == 0 and num_gconnections ==1:# glass-touches\n",
    "        return \"g\"\n",
    "    elif num_pconnections == 1 and num_gconnections ==1:# both-touch\n",
    "        return \"b\"\n",
    "    else:\n",
    "        return \"ucf\"\n",
    "\n",
    "# summer\n",
    "def reducer(connections):\n",
    "    if len(connections)== 0:\n",
    "        return [0, 0]\n",
    "    else:\n",
    "        return(np.sum(connections, axis=0))\n",
    "\n",
    "# given a focal point, a radiuus of connectiity, and a list of other circles\n",
    "# determine which of a list of them it is connected to\n",
    "def connect(cv, radii, bloblist): # center of blob2, radius of all blobs, list of other blobs\n",
    "    num_connections = 0\n",
    "    num_f_connections = 0\n",
    "    norm_radius = 15\n",
    "    total_separations = 0\n",
    "    normalized_dists = []\n",
    "    for blob2 in bloblist:\n",
    "        cv2 = (blob2[1], blob2[0]) # center of blob2\n",
    "        vector_d = vector_dist(cv, cv2)\n",
    "        total_separations += vector_d\n",
    "        r1,r2 = radii\n",
    "        if vector_d <= 2*r1 and vector_d > .2*r1: # blob centers closer than diameter of one blob\n",
    "            num_connections += 1\n",
    "        if vector_d <= 2*r2 and vector_d > .2*r1: # and frther than 1/5th of it, else it's multiple points of the same blob\n",
    "            num_f_connections += 1\n",
    "        else:\n",
    "            pass\n",
    "        if vector_d <= 4*r1: \n",
    "            normalized_dists.append(vector_d/(2*norm_radius))\n",
    "    return (num_connections, num_f_connections)\n",
    "\n",
    "\n",
    "def vector_dist(v1, v2): # euclidean distance between 2 points\n",
    "    return math.sqrt(np.sum([(v1[i] - v2[i])**2 for i in range(len(v1))]))\n",
    "\n",
    "def third_item(l1):\n",
    "    return l1[2]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code block applies the previous code to every frame, and every video. Intermediate results are printed. Typically, I copy the printed tet into a text file myself, and that is how the other programs I have written expect it to be presented. I do save the results to a file for safekeeping; however it is in a different format and I don't read from it any longer. You could modiy this code to write directly the displayed text to a save file in its current format, or modify the Matrix Multiplication code to read from the saved file's set of arrays instead, for a change."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "Number files:  0\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ckeys' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-de1dbdfea4cb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     98\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     99\u001b[0m         trans_runs[index] = [[Full_classif, (N_transitions, T_transitions), (trans_fil, class_thresh), num_full_keys,\n\u001b[1;32m--> 100\u001b[1;33m                                  num_tran_keys, ckeys, num_total_frames], params]\n\u001b[0m\u001b[0;32m    101\u001b[0m         \u001b[0mindex\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m         \u001b[1;31m#---------------------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ckeys' is not defined"
     ]
    }
   ],
   "source": [
    "filenames = glob(\".yourfiles\") # all the video data \n",
    "filenames.sort() # want to go through them in a reproducible order in case we have to restart halfway through\n",
    "print(filenames)\n",
    "num_top_keys = 4 # number of states plus 'unlclassified'\n",
    "num_full_keys = 4\n",
    "num_tran_keys = 3 # number of states\n",
    "num_lengths = 3 # number of measures of transition time\n",
    "trans_threshes = np.linspace(30, 60, 2) # Place the transition thesholds you would like to use here\n",
    "class_threshes =[20,30] # and the stability thresholds you want; every combination of these is done\n",
    "trans_runs = {} # this is the dictionary holding the results\n",
    "\n",
    "# this is a list of parameters custom chosen for this data using 'shape testing'\n",
    "ave = np.average\n",
    "expected_blobs = 4 \n",
    "expected_connections = 5\n",
    "p_bond = 15*1 # particles touch\n",
    "g_bond = 15*1\n",
    "fp_bond = 15*1.4 # particles in ehe same raft\n",
    "fg_bond = 15*1.5\n",
    "\n",
    "\n",
    "params = [expected_blobs , expected_connections, g_bond, p_bond] # stores the key parameters in the save file to document the run\n",
    "\n",
    "print(\"Number files: \", len(filenames))\n",
    "\n",
    "# Let's get started\n",
    "index = 0 # count the number of threshold pairs \n",
    "for trans_fil in trans_threshes:     \n",
    "    for class_thresh in class_threshes:\n",
    "        \n",
    "        Full_classif = np.zeros((len(filenames), num_full_keys)) # empty array for the no. frames spent in each state\n",
    "        N_transitions = np.zeros((len(filenames), num_tran_keys, num_tran_keys)) # and for the transitions in this video\n",
    "        T_transitions = [[[[[] for i in range(num_tran_keys)] for j in range(num_tran_keys)] for k in range(num_lengths)] \n",
    "                          for l in range(len(filenames))] # and a list for the times\n",
    "        num_total_frames = 0 \n",
    "        filtrate_len = 0\n",
    "        for vidnum in range(len(filenames)):\n",
    "            print(\"Processing vid %s : %s\" %(vidnum, filenames[vidnum]))\n",
    "            frames = vreader(filenames[vidnum]) # does not load whole video\n",
    "            # makes an object to load single frames at a time later\n",
    "\n",
    "            # Every video collects the results into these dictionaries, and pass them onto the arrays when the video ends\n",
    "            cclasses = [(\"p\",0), (\"g\",0), (\"b\",0), (\"ucf\",0)]\n",
    "            transitions = [(\"p->p\",0),(\"p->g\",0), (\"p->b\",0),\n",
    "                           (\"g->p\",0),(\"g->g\",0), (\"g->b\",0),\n",
    "                          (\"b->p\",0),(\"b->g\",0), (\"b->b\",0)]\n",
    "            times = [(\"p->p\",[[] for i in range(num_lengths)]),(\"p->g\",[[] for i in range(num_lengths)]), (\"p->b\",[[] for i in range(num_lengths)]),\n",
    "                           (\"g->p\",[[] for i in range(num_lengths)]),(\"g->g\",[[] for i in range(num_lengths)]), (\"g->b\",[[] for i in range(num_lengths)]),\n",
    "                          (\"b->p\",[[] for i in range(num_lengths)]),(\"b->g\",[[] for i in range(num_lengths)]), (\"b->b\",[[] for i in range(num_lengths)])]\n",
    "            \n",
    "            transitions = OrderedDict(transitions)\n",
    "            times = OrderedDict(times)            \n",
    "            classes = OrderedDict(classes)\n",
    "            \n",
    "            \n",
    "            # all these are updated frame by frame \n",
    "            broken_count = 0\n",
    "            class_num = 0\n",
    "            origin = 'ucf'\n",
    "            last_class = 'ucf'\n",
    "            last_whole = 0\n",
    "            state_start = 0\n",
    "            frame_no = 0\n",
    "            \n",
    "            # And we call every frame now\n",
    "            for fr in frames:\n",
    "                frame = fr[:, :, 2]# only one colour channel = greyscale\n",
    "                frame_no += 1\n",
    "                num_total_frames += 1\n",
    "                # call our classifying function, and use it to update our parameters\n",
    "                org = total_threshold_filter(frame, frame_no, trans_fil, class_thresh,\n",
    "                                             broken_count, class_num, origin, last_class, last_whole, state_start, filtrate_len, \n",
    "                                              classes, transitions, times)\n",
    "                broken_count, class_num, origin, last_class, last_whole, state_start, filtrate_len = org\n",
    "            \n",
    "            #-------Sort the results out from this video and add to the collector arrays/lists------------------\n",
    "            ckeys = list(classes.keys())\n",
    "            clcs = [classes[x] for x in ckeys] # list of frame nums per class\n",
    "            \n",
    "            tkeys = list(times.keys())\n",
    "            tims = [times[x] for x in tkeys]\n",
    "            \n",
    "            trkeys = list(transitions.keys())\n",
    "            trans = [transitions[x] for x in trkeys] # num of each transition\n",
    "\n",
    "            \n",
    "            Full_classif[vidnum,:] = clcs\n",
    "            N_transitions[vidnum,:] = np.reshape(trans, (num_tran_keys, num_tran_keys))             \n",
    "            T_transitions[vidnum] = np.moveaxis(np.reshape(tims, (num_tran_keys, num_tran_keys,num_lengths)),\n",
    "                                                  [0,1,2], [1,2,0])\n",
    "            \n",
    "            # So we all follow along (and can collect results if it ends early)\n",
    "            print(\"T threshold: %s\" %trans_fil)\n",
    "            print(\"C threshold: %s\" %class_thresh)\n",
    "            print(N_transitions[vidnum,:])\n",
    "            print(T_transitions[vidnum])\n",
    "            print(Full_classif[vidnum,:])\n",
    "            \n",
    "        trans_runs[index] = [[Full_classif, (N_transitions, T_transitions), (trans_fil, class_thresh), num_full_keys,\n",
    "                                 num_tran_keys, ckeys, num_total_frames], params]\n",
    "        index += 1\n",
    "        #---------------------------------------------------------------------------------\n",
    "\n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "np.save('your_faourite_filename.npy',trans_runs)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
