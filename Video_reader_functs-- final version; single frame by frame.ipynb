{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This is video reader with all operations inside fnctions, so they can be called on \\n    each frame out of a set of frames, and each video out of a set of videos\\n    '"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"This is video reader with all operations inside fnctions, so they can be called on \n",
    "    each frame out of a set of frames, and each video out of a set of videos\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Imports\"\"\"\n",
    "import matplotlib.pyplot as plt #for maknig plots inside the notebook\n",
    "import skimage\n",
    "import skvideo.io\n",
    "from skvideo.io import vreader, ffprobe\n",
    "from skimage import measure\n",
    "from skimage.filters import threshold_yen, threshold_isodata\n",
    "from operator import attrgetter\n",
    "import numpy as np\n",
    "import math\n",
    "from itertools import chain\n",
    "#from functools import partial, update_wrapper\n",
    "from scipy import ndimage \n",
    "from pims import pipeline, Video\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "#import antigravity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Functions\"\"\"\n",
    "# apply total thresholding to each of a list of frames; filter slides with wrong number\n",
    "def total_threshold_filter(frame, frame_no, transition_threshold, \n",
    "                           broken_count, last_class, last_whole, filtrate_len, \n",
    "                           sides, classes, transitions): \n",
    "    m_lab = measure.label\n",
    "    m_rop = measure.regionprops\n",
    "    # returns a new list, different from the orginal\n",
    "    thresh_img = frame > threshold_yen(frame) # binary image\n",
    "    img_labelled = m_lab(thresh_img) # contains connected regions\n",
    "    properties_list = m_rop(img_labelled, coordinates = 'rc') # data about regions, for each connected region\n",
    "\n",
    "    #----------getting maximum connected region----------\n",
    "    biggest_r = max(properties_list, key = attrgetter('area'))\n",
    "    \"\"\" for k in range(len(properties_list)):\n",
    "        if areas[k] > biggest_area:\n",
    "            biggest_r = properties_list[k]\n",
    "        else:\n",
    "            pass\"\"\"\n",
    "\n",
    "    #----------------------filter------------------------- can use actual filter\n",
    "    test = (biggest_r.filled_area > area_threshold and   # must have enough particles\n",
    "        biggest_r.minor_axis_length > minor_thresholds[0] # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "        and biggest_r.minor_axis_length < minor_thresholds[1]  # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "        and biggest_r.convex_area > convex_thresholds[0]  # convex hull area (> 2500 filtered)  # particles must be in parallelogram\n",
    "        and biggest_r.convex_area < convex_thresholds[1]  # convex hull area (> 2500 filtered)  # particles must be in parallelogram\n",
    "        and biggest_r.major_axis_length > major_thresholds[0]  # major_axis length (< filterd) # particles must be in parallelogram\n",
    "        and biggest_r.major_axis_length < major_thresholds[1])  # major_axis length (< filterd) # particles must be in parallelogram\n",
    "    if test: # keep frames that have enough paricles, and are not transitions\n",
    "        i_threshed = frame > threshold_isodata(frame)\n",
    "        img2_labelled = m_lab(i_threshed)\n",
    "        properties2_list = m_rop(img2_labelled, coordinates = 'rc')\n",
    "        biggest_r2 = max(properties2_list, key = attrgetter('area'))\n",
    "        #-----------------------------classify pt 1---------------------------------------\n",
    "        coprod = coord_prod(thresh_img, i_threshed)\n",
    "        side = sideify(biggest_r2)\n",
    "        clas = classify(side, -coprod)\n",
    "        sides[side].append(frame_no)\n",
    "        classes[clas].append(frame_no)\n",
    "        if broken_count >= transition_threshold and side != 'ucf': #if previous n frames were broken, and a transition between identifiableclasses ocurred\n",
    "            transitions[\"->\" + clas].append((last_whole, frame_no))\n",
    "        broken_count = 0\n",
    "        last_class = clas\n",
    "        last_whole = frame_no\n",
    "        filtrate_len += 1\n",
    "    else:\n",
    "        broken_count += 1\n",
    "\n",
    "    return [broken_count, last_class, last_whole, filtrate_len]\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "# take largest isodata image region, and return aclassification\n",
    "def sideify(idir):\n",
    "    iner = idir.inertia_tensor[0, 0] + idir.inertia_tensor[1, 1]\n",
    "    maal = idir.major_axis_length\n",
    "    mial = idir.minor_axis_length\n",
    "    sol = idir.solidity \n",
    "    ecc = idir.eccentricity\n",
    "    cva = idir.convex_area\n",
    "    if sol <= 0.725 or (iner> 405 and mial > 43.5): # sol <.72\n",
    "        return \"bm\"\n",
    "    elif ecc > 0.8 or maal > 65: # or (mial < 41 and maal > 65): # it's on top #ec >.82\n",
    "        return \"t\"\n",
    "    elif ecc < 0.75 or maal < 64.5: #or mial > 42  #and cva > 2200 and iner < 325: #or (maal < 64 and iner < 360): # it's on bottom\n",
    "        return \"b\"\n",
    "    else:\n",
    "        return \"ucf\"\n",
    "\n",
    "def classify(side, coprod):\n",
    "    if side == \"t\":\n",
    "        if coprod > 0:\n",
    "            return \"tl\"\n",
    "        else:\n",
    "            return \"tr\"\n",
    "    elif side == \"b\": \n",
    "        if coprod > 0:\n",
    "            return \"br\"\n",
    "        else:\n",
    "            return \"bl\"\n",
    "    elif side == \"bm\":\n",
    "        return \"bm\"\n",
    "    elif side == \"ucf\":\n",
    "        return \"ucf\"\n",
    "    else:\n",
    "        return \"newt\"\n",
    "\n",
    "\n",
    "def coord_prod(thresh_y, thresh_i):\n",
    "    m_rop = measure.regionprops\n",
    "    for i in range(0, 1):#len(fl):\n",
    "        full = largest_region_extractor(measure.label(thresh_y))\n",
    "        four = largest_region_extractor(measure.label(thresh_i))\n",
    "        full_or = m_rop(full.astype(int), coordinates = 'rc')[0].orientation\n",
    "        one_and_some = full^four\n",
    "        one = largest_region_extractor(measure.label(one_and_some))\n",
    "        \n",
    "          \n",
    "        #Begin finding substitue for major and minor axes herre\n",
    "        # use min and maax x and  values to find the geometric center\n",
    "        # or use those to substitue for eigenvectors \n",
    "        rotated_one = ndimage.rotate(one, math.degrees(-full_or), reshape = False)\n",
    "        rotated_full = ndimage.rotate(full, math.degrees(-full_or), reshape = False)\n",
    "        geo_cent = m_rop(rotated_full.astype(int), coordinates = 'rc')[0].bbox\n",
    "        #print(geo_cent)\n",
    "        ave = np.average\n",
    "        cent_x = ave([geo_cent[1], geo_cent[3]]) \n",
    "        cent_y = ave([geo_cent[0], geo_cent[2]])\n",
    "        #print(cent_x, cent_y)\n",
    "        \n",
    "        raw_coords = (m_rop(rotated_full.astype(int), coordinates = 'rc')[0].coords).T\n",
    "        ys = raw_coords[0]\n",
    "        xs = raw_coords[1]\n",
    "        x = xs - cent_x\n",
    "        y = ys - cent_y      \n",
    "        \n",
    "        one_com = m_rop(rotated_one.astype(int))[0].centroid\n",
    "        \n",
    "        rel_com_one = (one_com[1] - cent_x, one_com[0] - cent_y)\n",
    "        product = np.prod(rel_com_one)\n",
    "        return product\n",
    "        \n",
    "def rotate_point(point, angle):\n",
    "    x0 = point[0]\n",
    "    y0 = point[1]\n",
    "    x1 = x0*np.cos(angle) - y0*np.sin(angle)\n",
    "    y1 = x0*np.sin(angle) + y0*np.cos(angle)\n",
    "    return (x1, y1)\n",
    " \n",
    "def region_selector(labeled_image, label):\n",
    "    #print(label)\n",
    "    x = labeled_image == label\n",
    "    #plt.imshow(x)\n",
    "    return x\n",
    "\n",
    "# make a function that takes a set of labeled regions, and then  returns a boolean array containing only the largest\n",
    "def largest_region_extractor(labeled_regions_set):\n",
    "    props_lists = measure.regionprops(labeled_regions_set)\n",
    "    #print(len(labeled_regions_set), len(props_lists))\n",
    "    biggest_r_p = props_lists[0]\n",
    "    biggest_r_label = props_lists[0].label\n",
    "    for i in range(0, len(props_lists)):\n",
    "        pli = props_lists[i]\n",
    "        if pli.area > biggest_r_p.area:\n",
    "            biggest_r_p = pli\n",
    "            biggest_r_label = pli.label\n",
    "        else:\n",
    "            pass\n",
    "    return region_selector(labeled_regions_set, biggest_r_label)    \n",
    "#from pair of labelled, thresholded images, return an image category (of three)\n",
    "\n",
    "#from pair of labelled,thresholded images, return the x/y sign or x/y magnitude for the transparent dot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./tchakamau/New_setup\\\\45621_10Vpp_22.avi', './tchakamau/New_setup\\\\45621_10Vpp_23.avi', './tchakamau/New_setup\\\\45681_10Vpp_24.avi', './tchakamau/New_setup\\\\45681_10Vpp_25.avi', './tchakamau/New_setup\\\\45681_10Vpp_26.avi', './tchakamau/New_setup\\\\45681_10Vpp_27.avi', './tchakamau/New_setup\\\\45701_10Vpp_18.avi', './tchakamau/New_setup\\\\45701_10Vpp_19.avi', './tchakamau/New_setup\\\\45701_10Vpp_20.avi', './tchakamau/New_setup\\\\45701_10Vpp_21.avi']\n",
      "Number files:  10\n",
      "Processing vid 0\n",
      "finished vid 0\n",
      "Processing vid 1\n",
      "finished vid 1\n",
      "Processing vid 2\n",
      "finished vid 2\n",
      "Processing vid 3\n",
      "finished vid 3\n",
      "Processing vid 4\n",
      "finished vid 4\n",
      "Processing vid 5\n",
      "finished vid 5\n",
      "Processing vid 6\n",
      "finished vid 6\n",
      "Processing vid 7\n",
      "finished vid 7\n",
      "Processing vid 8\n",
      "finished vid 8\n",
      "Processing vid 9\n",
      "finished vid 9\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Pipeline for lists of frames\"\"\"\n",
    "\"\"\"\"\"\"\n",
    "\"\"\"Pipeline for videos:\"\"\"\n",
    "# initialize frame lists\n",
    "filenames = glob(\"./tchakamau/New_setup/*[0-9].avi\")#[\"./tchakamau/New_setup/45681_10Vpp_25.avi\", \"./tchakamau/New_setup/45701_10Vpp_20.avi\"]#glob(\"./tchakamau/New_setup/*.avi\")#  #filenames = \n",
    "print(filenames)\n",
    "num_top_keys = 4\n",
    "num_full_keys = 7\n",
    "num_tran_keys = 5\n",
    "Top_bottoms = np.zeros((len(filenames), num_top_keys))\n",
    "Full_classif = np.zeros((len(filenames), num_full_keys))\n",
    "N_transitions = np.zeros((len(filenames), num_tran_keys))\n",
    "trans_fil = 10\n",
    "\n",
    "ave = np.average\n",
    "num_total_frames = 0 \n",
    "area_threshold = 1800   # must have enough particles\n",
    "convex_thresholds = (2000, 2800)   # convex hull area (> 2500 filtered)  # particles must be in parallelogram\n",
    "minor_thresholds = (38, 48) # minor_axis length (< filterd) # particles must be in parallelogram\n",
    "major_thresholds = (59, 76)\n",
    "\n",
    "print(\"Number files: \", len(filenames))\n",
    "\n",
    "for vidnum in range(len(filenames)):\n",
    "    print(\"Processing vid %s\" %vidnum)\n",
    "    #meta = ffprobe(filenames[vidnum])\n",
    "    #print(meta)#['@nb_frames'])\n",
    "    #print(5)\n",
    "    frames = vreader(filenames[vidnum])\n",
    "    #frame_vid = frames[:, :, :, 2]# making videos ino a frame list\n",
    "    #print(frames)\n",
    "    \n",
    "    \n",
    "    \n",
    "    sides = {\"bm\":[], \"b\":[], \"t\":[], \"ucf\":[]}\n",
    "    classes = {\"bm\":[], \"br\":[], \"bl\":[], \"tr\":[], \"tl\":[], \"ucf\":[], \"newt\":[]}\n",
    "    transitions = {\"->bm\" :[], \"->br\":[], \"->bl\":[], \"->tr\":[], \"->tl\":[]}\n",
    "    broken_count = 0\n",
    "    last_class = ''\n",
    "    last_whole = 0\n",
    "    filtrate_len = 0\n",
    "    for fr in frames:\n",
    "        frame = fr[:, :, 2]\n",
    "        #print(fr.shape, frame.shape)\n",
    "        #print(frame)\n",
    "        num_total_frames += 1\n",
    "        #print(broken_count, last_class, last_whole, filtrate_len, num_total_frames)\n",
    "        org = total_threshold_filter(frame, num_total_frames, trans_fil,\n",
    "                                     broken_count, last_class, last_whole, filtrate_len, \n",
    "                                     sides, classes, transitions)\n",
    "        broken_count, last_class, last_whole, filtrate_len = org\n",
    "    filtered_len = filtrate_len\n",
    "    #----------------------------------------------------------------\n",
    "    trans_len = len([y for x in transitions.values() for y in x])\n",
    "    skeys = list(sides.keys())\n",
    "    ckeys = list(classes.keys())\n",
    "    tkeys = list(transitions.keys())\n",
    "    slcs = [len(sides[x]) for x in skeys]\n",
    "    clcs = [len(classes[x]) for x in ckeys]\n",
    "    trans = [len(transitions[x]) for x in tkeys]\n",
    "    ucf = len(sides[\"ucf\"])\n",
    "    newtucf = len(classes[\"newt\"]) + ucf\n",
    "\n",
    "\n",
    "\n",
    "    Top_bottoms[vidnum,:] = [slcs[i] for i in range(len(skeys))]\n",
    "    Full_classif[vidnum,:] = [clcs[i] for i in range(len(ckeys))]\n",
    "    N_transitions[vidnum,:] = [trans[i] for i in range(len(tkeys))]\n",
    "    print(\"finished vid %s\" %vidnum)\n",
    "\n",
    "\n",
    "    \n",
    "#-----------------------------------------------------------------------\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[70883.0, 120079.0, 176777.0, 1855.0] [70883.0, 78820.0, 41259.0, 86994.0, 89783.0, 1855.0, 0.0] [241.0, 204.0, 249.0, 187.0, 184.0]\n",
      "\n",
      " Number of frames obbserved:  493015\n",
      "\n",
      "sums in broad classifications\n",
      "bm sum 70883\n",
      "b sum 120079\n",
      "t sum 176777\n",
      "ucf sum 1855\n",
      "Total:  369594.0\n",
      "\n",
      "sums in narrow classifications\n",
      "bm sum 70883\n",
      "br sum 78820\n",
      "bl sum 41259\n",
      "tr sum 86994\n",
      "tl sum 89783\n",
      "ucf sum 1855\n",
      "newt sum 0\n",
      "Total:  369594.0\n",
      "\n",
      "sums of transitions\n",
      "->bm sum 241\n",
      "->br sum 204\n",
      "->bl sum 249\n",
      "->tr sum 187\n",
      "->tl sum 184\n",
      "Total:  1065.0\n",
      "\n",
      "%s in broad classifications\n",
      "bm  19%\n",
      "b  32%\n",
      "t  48%\n",
      "ucf  1%\n",
      "\n",
      "%s in narrow classifications\n",
      "bm  19%\n",
      "br  21%\n",
      "bl  11%\n",
      "tr  24%\n",
      "tl  24%\n",
      "ucf  1%\n",
      "newt  0%\n",
      "\n",
      "%s of transitions broad\n",
      "bm  23% \n",
      " b  43% \n",
      " t  35%\n",
      "\n",
      "%s of transitions narrow\n",
      "->bm  23%\n",
      "->br  19%\n",
      "->bl  23%\n",
      "->tr  18%\n",
      "->tl  17%\n",
      "\n",
      "ratio of # transitions to time in state (normalized using bm value)\n",
      "bm  1 \n",
      " b  1.11 \n",
      " t  0.62\n",
      "\n",
      "ratio of # transitions to time in state (normalized using bm value)\n",
      "bm  1 \n",
      " br  0.76 \n",
      " bl  1.78 \n",
      " tr  0.63 \n",
      " tl  0.60\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'print(\"\\nvariance in %s in broad classifications\")\\n[print(skeys[i], \"var %.f%%\" %Tb_vars[i]) for i in range(len(skeys))]\\nprint(\"\\nvariance in %s in narrow classifications\")\\n[print(ckeys[i], \"var %.f%%\" %Fc_vars[i]) for i in range(len(ckeys))]\\nprint(\"\\nvariance in %s of transitions\")\\n[print(tkeys[i], \"var %.f%%\" %Nt_vars[i]) for i in range(len(tkeys))]'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Print average values (wuth column labels from slcs, clcs, trans) for rows of the array\"\"\"\n",
    "var = np.var\n",
    "sums = np.sum\n",
    "Tb_sums = [sums(Top_bottoms[:, c]) for c in range(num_top_keys)]\n",
    "Fc_sums = [sums(Full_classif[:, c]) for c in range(num_full_keys)]\n",
    "Nt_sums = [sums(N_transitions[:, c]) for c in range(num_tran_keys)]\n",
    "print(Tb_sums, Fc_sums, Nt_sums)\n",
    "\n",
    "print(\"\\n Number of frames obbserved: \", num_total_frames)\n",
    "\n",
    "Tb_percs = [Tb_sums[c] *100 /sum(Tb_sums) for c in range(num_top_keys)]\n",
    "Fc_percs = [Fc_sums[c] *100/sum(Fc_sums) for c in range(num_full_keys)]\n",
    "Nt_percs = [Nt_sums[c] *100/sum(Nt_sums) for c in range(num_tran_keys)]\n",
    "\n",
    "\"\"\"Tb_vars = [var(Top_bottoms[:, c]) for c in range(num_top_keys)]\n",
    "Fc_vars = [var(Full_classif[:, c]) for c in range(num_full_keys)]\n",
    "Nt_vars = [var(N_transitions[:, c]) for c in range(num_tran_keys)]\n",
    "print(Nt_vars)\"\"\"\n",
    "\n",
    "print(\"\\nsums in broad classifications\")\n",
    "[print(skeys[i], \"sum %.f\" %Tb_sums[i]) for i in range(len(skeys))]\n",
    "print(\"Total: \", sum(Tb_sums) )\n",
    "print(\"\\nsums in narrow classifications\")\n",
    "[print(ckeys[i], \"sum %.f\" %Fc_sums[i]) for i in range(len(ckeys))]\n",
    "print(\"Total: \", sum(Fc_sums ) )\n",
    "print(\"\\nsums of transitions\")\n",
    "[print(tkeys[i], \"sum %.f\" %Nt_sums[i]) for i in range(len(tkeys))]\n",
    "print(\"Total: \", sum(Nt_sums) )\n",
    "\n",
    "\n",
    "print(\"\\n%s in broad classifications\")\n",
    "[print(skeys[i], \" %.f%%\" %Tb_percs[i]) for i in range(len(skeys))]\n",
    "print(\"\\n%s in narrow classifications\")\n",
    "[print(ckeys[i], \" %.f%%\" %Fc_percs[i]) for i in range(len(ckeys))]\n",
    "print(\"\\n%s of transitions broad\")\n",
    "print(skeys[0], \" %.f%%\" %Nt_percs[0],\"\\n\",\n",
    "       skeys[1], \" %.f%%\" %(Nt_percs[1] + Nt_percs[2]),\"\\n\",\n",
    "       skeys[2], \" %.f%%\" %(Nt_percs[3] + Nt_percs[4]))\n",
    "print(\"\\n%s of transitions narrow\")\n",
    "[print(tkeys[i], \" %.f%%\" %Nt_percs[i]) for i in range(len(tkeys))]\n",
    "\n",
    "\n",
    "\n",
    "print(\"\\nratio of # transitions to time in state (normalized using bm value)\")\n",
    "print(skeys[0], \" %.f\" %((Nt_sums[0]/Tb_sums[0]) / (Nt_sums[0]/Tb_sums[0])),\"\\n\",\n",
    "       skeys[1], \" %.2f\" %((Nt_sums[1] + Nt_sums[2])*Tb_sums[0]/(Nt_sums[0] * Tb_sums[1])),\"\\n\",\n",
    "       skeys[2], \" %.2f\" %((Nt_sums[3] + Nt_sums[4]) *Tb_sums[0]/(Nt_sums[0] * Tb_sums[2])))\n",
    "\n",
    "print(\"\\nratio of # transitions to time in state (normalized using bm value)\")\n",
    "print(ckeys[0], \" %.f\" %((Nt_sums[0]/Fc_sums[0]) / (Nt_sums[0]/Fc_sums[0])),\"\\n\",\n",
    "       ckeys[1], \" %.2f\" %(Nt_sums[1]*Fc_sums[0]/(Nt_sums[0] * Fc_sums[1])),\"\\n\",\n",
    "       ckeys[2], \" %.2f\" %(Nt_sums[2]*Fc_sums[0]/(Nt_sums[0] * Fc_sums[2])),\"\\n\",\n",
    "       ckeys[3], \" %.2f\" %(Nt_sums[3]*Fc_sums[0]/(Nt_sums[0] * Fc_sums[3])),\"\\n\",\n",
    "       ckeys[4], \" %.2f\" %(Nt_sums[4]*Fc_sums[0]/(Nt_sums[0] * Fc_sums[4])))\n",
    "\"\"\"print(\"\\nvariance in %s in broad classifications\")\n",
    "[print(skeys[i], \"var %.f%%\" %Tb_vars[i]) for i in range(len(skeys))]\n",
    "print(\"\\nvariance in %s in narrow classifications\")\n",
    "[print(ckeys[i], \"var %.f%%\" %Fc_vars[i]) for i in range(len(ckeys))]\n",
    "print(\"\\nvariance in %s of transitions\")\n",
    "[print(tkeys[i], \"var %.f%%\" %Nt_vars[i]) for i in range(len(tkeys))]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
